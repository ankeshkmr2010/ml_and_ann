{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankeshkmr2010/ml_and_ann/blob/main/01_ANN_vs_LogisticsRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r360IjZOeC2t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sU1_NRLweC2u"
      },
      "outputs": [],
      "source": [
        "# MNIST dataset parameters.\n",
        "num_classes = 10 # total classes (0-9 digits).\n",
        "num_features = 784 # data features (img shape: 28*28).\n",
        "\n",
        "# Training parameters.\n",
        "learning_rate = 0.1\n",
        "training_steps = 2000\n",
        "batch_size = 256\n",
        "display_step = 100\n",
        "epochs = 20\n",
        "\n",
        "# Network parameters.\n",
        "n_hidden_1 = 128 # 1st layer number of neurons.\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ7OAvKFeC2v",
        "outputId": "5cf6ec64-69b5-46f3-d275-bc9a533a01a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Train -  (60000, 28, 28)\n",
            "Test -  (10000, 28, 28)\n",
            "Flatten Train -  (60000, 784)\n",
            "Flatten Test -  (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "# Prepare MNIST data.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Train - ',x_train.shape)\n",
        "print('Test - ',x_test.shape)\n",
        "# Convert to float32.\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "# Flatten images to 1-D vector of 784 features (28*28).\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "# Normalize images value from [0, 255] to [0, 1].\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "print('Flatten Train - ',x_train.shape)\n",
        "print('Flatten Test - ',x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIajOXY9eC2w",
        "outputId": "201d9c7f-016f-4df3-ed09-ba077f2186a7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label for each of the above image: [5 0 4 1 9 2 1 3 1 4]\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(x_train[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "print('label for each of the above image: %s' % (y_train[0:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH-j3tdieC2w",
        "outputId": "6103adcd-b3ce-4d8e-d056-d17c95647f37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9ai9VeRweC2x"
      },
      "outputs": [],
      "source": [
        "y_train_ohe = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test_ohe = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYgAik8qeC2x",
        "outputId": "406354c8-36a2-419e-8514-acd2094c3712"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vyheJPGeC2x"
      },
      "source": [
        "# Logistics Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc4gspMmeC2y",
        "outputId": "fcc93639-443b-4c68-84a5-011d319fbefe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sandipan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c (10,)\n",
            "m (10, 784)\n",
            "Train Score r2 =  0.9106\n",
            "Test Score r2 =  0.913\n",
            "Total Number of W nd B =  7840\n"
          ]
        }
      ],
      "source": [
        "#Build the logistic regression model\n",
        "logreg = LogisticRegression(max_iter=epochs)\n",
        "logreg.fit(x_train,y_train)# fit the model\n",
        "print('c',logreg.intercept_.shape) # see the intercept\n",
        "print('m',logreg.coef_.shape)# see the betas\n",
        "print('Train Score r2 = ',logreg.score(x_train, y_train))\n",
        "print('Test Score r2 = ',logreg.score(x_test, y_test))\n",
        "\n",
        "print('Total Number of W nd B = ', logreg.intercept_.shape[0] * logreg.coef_.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk5GFJcOeC20",
        "outputId": "e17856ed-c051-4c19-9c2f-1970e89909e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 4\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 9\n"
          ]
        }
      ],
      "source": [
        "# Predict 5 images from validation set.\n",
        "n_images = 5\n",
        "test_images = x_train[:n_images]\n",
        "predictions = logreg.predict(test_images)\n",
        "print(predictions)\n",
        "\n",
        "# Display image and model prediction.\n",
        "for i in range(n_images):\n",
        "    pyplot.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
        "    pyplot.show()\n",
        "    print(\"Model prediction: %i\" % predictions[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p6pUE3teC20"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l73Gf2tbeC21",
        "outputId": "05d6ca52-09a6-454b-cb89-b31142d4b7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# build NN model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "IQGmrLoveC21"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "59kM63lPeC22"
      },
      "outputs": [],
      "source": [
        "# Training parameters.\n",
        "learning_rate = 0.1\n",
        "batch_size = 256\n",
        "display_step = 100\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kh00AkxeC22",
        "outputId": "f9ba6d96-3bf2-4d39-ccc6-aa2e01e34f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "235/235 [==============================] - 9s 33ms/step - loss: 0.3133 - accuracy: 0.9044 - val_loss: 0.1376 - val_accuracy: 0.9564\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.1184 - accuracy: 0.9629 - val_loss: 0.0813 - val_accuracy: 0.9736\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0824 - accuracy: 0.9742 - val_loss: 0.0916 - val_accuracy: 0.9711\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 0.0751 - val_accuracy: 0.9763\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0493 - accuracy: 0.9843 - val_loss: 0.0666 - val_accuracy: 0.9791\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 0.0577 - val_accuracy: 0.9822\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.0636 - val_accuracy: 0.9817\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0583 - val_accuracy: 0.9825\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0580 - val_accuracy: 0.9828\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0610 - val_accuracy: 0.9831\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0611 - val_accuracy: 0.9846\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0637 - val_accuracy: 0.9821\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.0664 - val_accuracy: 0.9832\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0667 - val_accuracy: 0.9835\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0629 - val_accuracy: 0.9839\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0695 - val_accuracy: 0.9839\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0726 - val_accuracy: 0.9831\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0679 - val_accuracy: 0.9853\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0672 - val_accuracy: 0.9849\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0723 - val_accuracy: 0.9853\n",
            "Test loss: 0.07234889268875122\n",
            "Test accuracy: 0.9853000044822693\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train_ohe,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test_ohe))\n",
        "# Model Eval\n",
        "score = model.evaluate(x_test, y_test_ohe, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wng9STjIeC22",
        "outputId": "aa7978a4-5e87-4340-fc8a-3a3f873576a4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 7\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prediction: 4\n"
          ]
        }
      ],
      "source": [
        "# Predict 5 images from validation set.\n",
        "n_images = 5\n",
        "test_images = x_test[:n_images]\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Display image and model prediction.\n",
        "for i in range(n_images):\n",
        "    pyplot.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
        "    pyplot.show()\n",
        "    print(\"Model prediction: %i\" % np.argmax(predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oavp2FvheC22",
        "outputId": "8f4bcbcb-5c6f-44fb-9f4c-309c44809bc8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "0XeeQRGieC23"
      },
      "outputs": [],
      "source": [
        "dat = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA7fQwX-eZRv",
        "outputId": "1576500b-4120-45e8-8831-dbe57b341ac8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
              "          3.96900e+02, 1.87200e+01],\n",
              "         [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
              "          3.95380e+02, 3.11000e+00],\n",
              "         [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "          3.75520e+02, 3.26000e+00],\n",
              "         ...,\n",
              "         [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
              "          3.62250e+02, 7.83000e+00],\n",
              "         [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "          2.61950e+02, 1.57900e+01],\n",
              "         [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
              "          3.76700e+02, 4.38000e+00]]),\n",
              "  array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "         17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "         32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "         23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "         12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "         22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "         15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "         14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "         14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "         28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "         19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "         18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "         31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "         19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "         22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "         27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "          8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "         19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "         23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "         21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "         17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "         16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "         24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "         13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "         22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "         23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "          7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "          8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "         19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "         19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "         23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "         19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "         23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "         33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "         28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "         24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "         11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])),\n",
              " (array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "          2.72500e+01, 2.90500e+01],\n",
              "         [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
              "          3.94950e+02, 1.62100e+01],\n",
              "         [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
              "          3.96900e+02, 9.74000e+00],\n",
              "         ...,\n",
              "         [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "          3.89610e+02, 1.92000e+00],\n",
              "         [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
              "          3.91700e+02, 9.71000e+00],\n",
              "         [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "          2.40160e+02, 9.81000e+00]]),\n",
              "  array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
              "         14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
              "         20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
              "         23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
              "         32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
              "         26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
              "         13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
              "         28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
              "         22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
              "         50. , 26.7, 25. ])))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "2stSaipNeZXo"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeAZrNGbfCEz",
        "outputId": "20263a00-2558-4671-82ec-5629f4d860d2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
              "        3.96900e+02, 1.87200e+01],\n",
              "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
              "        3.95380e+02, 3.11000e+00],\n",
              "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "        3.75520e+02, 3.26000e+00],\n",
              "       ...,\n",
              "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
              "        3.62250e+02, 7.83000e+00],\n",
              "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "        2.61950e+02, 1.57900e+01],\n",
              "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
              "        3.76700e+02, 4.38000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdsIdmwfCG4",
        "outputId": "971fd701-532f-47b2-80e1-932c6dfbf500"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "        2.72500e+01, 2.90500e+01],\n",
              "       [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
              "        3.94950e+02, 1.62100e+01],\n",
              "       [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
              "        3.96900e+02, 9.74000e+00],\n",
              "       ...,\n",
              "       [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "        3.89610e+02, 1.92000e+00],\n",
              "       [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
              "        3.91700e+02, 9.71000e+00],\n",
              "       [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "        2.40160e+02, 9.81000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"bh1\",)\n",
        "# l1\n",
        "model.add(Dense( 64, activation='relu', input_shape=(13,)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# l2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# out\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiS1iBO0fHPp",
        "outputId": "bc4ba5ba-195c-4456-cdae-29e59860c11c"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bh1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_151 (Dense)           (None, 64)                896       \n",
            "                                                                 \n",
            " batch_normalization_55 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,633\n",
            "Trainable params: 5,377\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer='sgd',\n",
        "    metrics=['mae','mse']\n",
        "    )"
      ],
      "metadata": {
        "id": "MWU64qmwfHUK"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnv2BEbCfHYz",
        "outputId": "7dd45a0e-37fd-47f6-de14-77aab53141c9"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters.\n",
        "learning_rate = 0.1\n",
        "batch_size = 50\n",
        "display_step = 5\n",
        "epochs = 600"
      ],
      "metadata": {
        "id": "2a3shIpLfHeI"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n",
        "# Model Eval\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "for i in range(len(score)):\n",
        "    print(f'{model.metrics_names[i]} — -> {score[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC9aWOQFfHgp",
        "outputId": "f9174c3a-7214-4109-88c2-d77b7fde7d8b"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 60.3851 - mae: 5.4693 - mse: 60.3851 - val_loss: 109.0204 - val_mae: 8.9081 - val_mse: 109.0204\n",
            "Epoch 2/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 57.0326 - mae: 5.0176 - mse: 57.0326 - val_loss: 133.4082 - val_mae: 10.0909 - val_mse: 133.4082\n",
            "Epoch 3/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 55.5975 - mae: 4.9359 - mse: 55.5975 - val_loss: 92.5814 - val_mae: 7.9298 - val_mse: 92.5814\n",
            "Epoch 4/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 57.4658 - mae: 5.0402 - mse: 57.4658 - val_loss: 188.0556 - val_mae: 12.3955 - val_mse: 188.0556\n",
            "Epoch 5/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 54.6860 - mae: 5.0151 - mse: 54.6860 - val_loss: 303.0385 - val_mae: 15.4241 - val_mse: 303.0385\n",
            "Epoch 6/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 57.7855 - mae: 5.3228 - mse: 57.7855 - val_loss: 87.7547 - val_mae: 7.3203 - val_mse: 87.7547\n",
            "Epoch 7/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 57.4820 - mae: 4.9223 - mse: 57.4820 - val_loss: 193.2092 - val_mae: 12.3173 - val_mse: 193.2092\n",
            "Epoch 8/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 53.5428 - mae: 5.0736 - mse: 53.5428 - val_loss: 154.3187 - val_mae: 10.4675 - val_mse: 154.3187\n",
            "Epoch 9/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 51.9342 - mae: 4.8591 - mse: 51.9342 - val_loss: 199.1315 - val_mae: 12.2016 - val_mse: 199.1315\n",
            "Epoch 10/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 49.1316 - mae: 4.7561 - mse: 49.1316 - val_loss: 214.8226 - val_mae: 12.9005 - val_mse: 214.8226\n",
            "Epoch 11/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 47.2321 - mae: 4.7252 - mse: 47.2321 - val_loss: 123.4382 - val_mae: 9.5648 - val_mse: 123.4382\n",
            "Epoch 12/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 50.9584 - mae: 5.2099 - mse: 50.9584 - val_loss: 56.7226 - val_mae: 5.9273 - val_mse: 56.7226\n",
            "Epoch 13/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 58.4794 - mae: 5.4192 - mse: 58.4794 - val_loss: 53.8864 - val_mae: 5.4687 - val_mse: 53.8864\n",
            "Epoch 14/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 57.3147 - mae: 5.2832 - mse: 57.3147 - val_loss: 80.5370 - val_mae: 7.4876 - val_mse: 80.5370\n",
            "Epoch 15/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 56.1910 - mae: 5.3362 - mse: 56.1910 - val_loss: 82.9165 - val_mae: 7.3688 - val_mse: 82.9165\n",
            "Epoch 16/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 47.0620 - mae: 4.7927 - mse: 47.0620 - val_loss: 177.7224 - val_mae: 12.2030 - val_mse: 177.7224\n",
            "Epoch 17/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45.4250 - mae: 4.7385 - mse: 45.4250 - val_loss: 163.0807 - val_mae: 10.9428 - val_mse: 163.0807\n",
            "Epoch 18/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 46.6219 - mae: 4.7120 - mse: 46.6219 - val_loss: 279.7626 - val_mae: 15.7398 - val_mse: 279.7626\n",
            "Epoch 19/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 54.4980 - mae: 5.5286 - mse: 54.4980 - val_loss: 87.0488 - val_mae: 7.9310 - val_mse: 87.0488\n",
            "Epoch 20/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 49.0609 - mae: 4.9409 - mse: 49.0609 - val_loss: 390.4410 - val_mae: 18.4292 - val_mse: 390.4410\n",
            "Epoch 21/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 49.7940 - mae: 4.9279 - mse: 49.7940 - val_loss: 345.8352 - val_mae: 14.4394 - val_mse: 345.8352\n",
            "Epoch 22/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.0316 - mae: 5.7406 - mse: 65.0316 - val_loss: 85.8979 - val_mae: 6.8500 - val_mse: 85.8979\n",
            "Epoch 23/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41.5147 - mae: 4.4958 - mse: 41.5147 - val_loss: 58.4057 - val_mae: 5.6659 - val_mse: 58.4057\n",
            "Epoch 24/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43.7271 - mae: 4.6327 - mse: 43.7271 - val_loss: 369.2702 - val_mae: 17.0249 - val_mse: 369.2702\n",
            "Epoch 25/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 53.4424 - mae: 5.1541 - mse: 53.4424 - val_loss: 413.6869 - val_mae: 18.0754 - val_mse: 413.6869\n",
            "Epoch 26/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 54.8287 - mae: 5.3208 - mse: 54.8287 - val_loss: 66.7846 - val_mae: 6.3357 - val_mse: 66.7846\n",
            "Epoch 27/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43.1686 - mae: 4.8534 - mse: 43.1686 - val_loss: 45.8705 - val_mae: 4.9355 - val_mse: 45.8705\n",
            "Epoch 28/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 41.7883 - mae: 4.4489 - mse: 41.7883 - val_loss: 169.2843 - val_mae: 11.4769 - val_mse: 169.2843\n",
            "Epoch 29/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 48.6502 - mae: 5.0813 - mse: 48.6502 - val_loss: 76.1682 - val_mae: 7.3669 - val_mse: 76.1682\n",
            "Epoch 30/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45.6410 - mae: 4.7566 - mse: 45.6410 - val_loss: 206.4172 - val_mae: 12.3727 - val_mse: 206.4172\n",
            "Epoch 31/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 42.5092 - mae: 4.7264 - mse: 42.5092 - val_loss: 160.8577 - val_mae: 11.3244 - val_mse: 160.8577\n",
            "Epoch 32/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41.0394 - mae: 4.5145 - mse: 41.0394 - val_loss: 83.8177 - val_mae: 7.3088 - val_mse: 83.8177\n",
            "Epoch 33/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42.6817 - mae: 4.5267 - mse: 42.6817 - val_loss: 1160.1377 - val_mae: 29.7232 - val_mse: 1160.1377\n",
            "Epoch 34/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 98.5245 - mae: 7.1472 - mse: 98.5245 - val_loss: 313.1338 - val_mae: 15.8016 - val_mse: 313.1338\n",
            "Epoch 35/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 73.7750 - mae: 6.2528 - mse: 73.7750 - val_loss: 161.1897 - val_mae: 11.0050 - val_mse: 161.1897\n",
            "Epoch 36/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.8972 - mae: 5.7950 - mse: 68.8972 - val_loss: 261.7788 - val_mae: 14.4284 - val_mse: 261.7788\n",
            "Epoch 37/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 69.2016 - mae: 6.0493 - mse: 69.2016 - val_loss: 205.2359 - val_mae: 12.9564 - val_mse: 205.2359\n",
            "Epoch 38/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 68.4145 - mae: 5.8524 - mse: 68.4145 - val_loss: 182.1854 - val_mae: 12.0401 - val_mse: 182.1854\n",
            "Epoch 39/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.2267 - mae: 5.9592 - mse: 68.2267 - val_loss: 122.7300 - val_mae: 9.6529 - val_mse: 122.7300\n",
            "Epoch 40/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 71.6035 - mae: 5.9936 - mse: 71.6035 - val_loss: 89.2501 - val_mae: 7.6600 - val_mse: 89.2501\n",
            "Epoch 41/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 69.9945 - mae: 5.7692 - mse: 69.9945 - val_loss: 123.4073 - val_mae: 9.6671 - val_mse: 123.4073\n",
            "Epoch 42/600\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 65.1244 - mae: 5.7950 - mse: 65.1244 - val_loss: 145.0649 - val_mae: 10.6114 - val_mse: 145.0649\n",
            "Epoch 43/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.1657 - mae: 5.8135 - mse: 66.1657 - val_loss: 82.7893 - val_mae: 7.2477 - val_mse: 82.7893\n",
            "Epoch 44/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.2915 - mae: 5.6370 - mse: 67.2915 - val_loss: 109.8414 - val_mae: 8.7486 - val_mse: 109.8414\n",
            "Epoch 45/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.7251 - mae: 5.6564 - mse: 65.7251 - val_loss: 92.8374 - val_mae: 8.1325 - val_mse: 92.8374\n",
            "Epoch 46/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.6850 - mae: 5.7740 - mse: 67.6850 - val_loss: 162.5533 - val_mae: 11.2822 - val_mse: 162.5533\n",
            "Epoch 47/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 70.2996 - mae: 6.2287 - mse: 70.2996 - val_loss: 235.4185 - val_mae: 14.2475 - val_mse: 235.4185\n",
            "Epoch 48/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 73.3289 - mae: 6.2529 - mse: 73.3289 - val_loss: 76.9629 - val_mae: 6.9087 - val_mse: 76.9629\n",
            "Epoch 49/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 67.9516 - mae: 5.8766 - mse: 67.9516 - val_loss: 87.1816 - val_mae: 7.0733 - val_mse: 87.1816\n",
            "Epoch 50/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 68.6253 - mae: 5.8368 - mse: 68.6253 - val_loss: 60.9593 - val_mae: 5.7644 - val_mse: 60.9593\n",
            "Epoch 51/600\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 68.5436 - mae: 5.6450 - mse: 68.5436 - val_loss: 130.5340 - val_mae: 9.4675 - val_mse: 130.5340\n",
            "Epoch 52/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 73.7879 - mae: 6.1772 - mse: 73.7879 - val_loss: 167.6668 - val_mae: 11.5614 - val_mse: 167.6668\n",
            "Epoch 53/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 69.8040 - mae: 6.0737 - mse: 69.8040 - val_loss: 100.9358 - val_mae: 8.6641 - val_mse: 100.9358\n",
            "Epoch 54/600\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 67.8119 - mae: 5.9751 - mse: 67.8119 - val_loss: 61.3840 - val_mae: 5.9346 - val_mse: 61.3840\n",
            "Epoch 55/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 65.5622 - mae: 5.6834 - mse: 65.5622 - val_loss: 65.6033 - val_mae: 5.8120 - val_mse: 65.6033\n",
            "Epoch 56/600\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 66.3819 - mae: 5.5979 - mse: 66.3819 - val_loss: 67.9190 - val_mae: 6.0842 - val_mse: 67.9190\n",
            "Epoch 57/600\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 67.3877 - mae: 5.6832 - mse: 67.3877 - val_loss: 120.8916 - val_mae: 9.2982 - val_mse: 120.8916\n",
            "Epoch 58/600\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 72.4417 - mae: 6.2599 - mse: 72.4417 - val_loss: 68.7117 - val_mae: 6.4909 - val_mse: 68.7117\n",
            "Epoch 59/600\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 66.0513 - mae: 5.7415 - mse: 66.0513 - val_loss: 60.8303 - val_mae: 6.3571 - val_mse: 60.8303\n",
            "Epoch 60/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 66.9222 - mae: 5.7410 - mse: 66.9222 - val_loss: 58.5409 - val_mae: 5.8892 - val_mse: 58.5409\n",
            "Epoch 61/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 66.0954 - mae: 5.5992 - mse: 66.0954 - val_loss: 57.8017 - val_mae: 6.0544 - val_mse: 57.8017\n",
            "Epoch 62/600\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 67.1868 - mae: 5.7082 - mse: 67.1868 - val_loss: 59.6018 - val_mae: 5.7148 - val_mse: 59.6018\n",
            "Epoch 63/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 69.0103 - mae: 5.7541 - mse: 69.0103 - val_loss: 64.2338 - val_mae: 5.8057 - val_mse: 64.2338\n",
            "Epoch 64/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 66.2268 - mae: 5.4699 - mse: 66.2268 - val_loss: 68.5170 - val_mae: 6.4714 - val_mse: 68.5170\n",
            "Epoch 65/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 68.6067 - mae: 5.9849 - mse: 68.6067 - val_loss: 64.0950 - val_mae: 6.0376 - val_mse: 64.0950\n",
            "Epoch 66/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 66.4026 - mae: 5.6429 - mse: 66.4026 - val_loss: 59.1027 - val_mae: 5.7809 - val_mse: 59.1027\n",
            "Epoch 67/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.6286 - mae: 5.6001 - mse: 65.6286 - val_loss: 59.9020 - val_mae: 5.6748 - val_mse: 59.9020\n",
            "Epoch 68/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 66.3045 - mae: 5.5774 - mse: 66.3045 - val_loss: 70.9163 - val_mae: 6.0038 - val_mse: 70.9163\n",
            "Epoch 69/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.7879 - mae: 5.6311 - mse: 66.7879 - val_loss: 421.4679 - val_mae: 19.2841 - val_mse: 421.4679\n",
            "Epoch 70/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 75.8332 - mae: 6.4115 - mse: 75.8332 - val_loss: 208.2563 - val_mae: 13.2692 - val_mse: 208.2563\n",
            "Epoch 71/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.8708 - mae: 6.0064 - mse: 66.8708 - val_loss: 61.1716 - val_mae: 5.9435 - val_mse: 61.1716\n",
            "Epoch 72/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 69.9395 - mae: 5.6404 - mse: 69.9395 - val_loss: 192.1247 - val_mae: 12.6725 - val_mse: 192.1247\n",
            "Epoch 73/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.1971 - mae: 5.8815 - mse: 66.1971 - val_loss: 86.0770 - val_mae: 7.7747 - val_mse: 86.0770\n",
            "Epoch 74/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 65.8633 - mae: 5.5077 - mse: 65.8633 - val_loss: 123.3777 - val_mae: 9.7503 - val_mse: 123.3777\n",
            "Epoch 75/600\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 69.8148 - mae: 5.9415 - mse: 69.8148 - val_loss: 127.2223 - val_mae: 10.0648 - val_mse: 127.2223\n",
            "Epoch 76/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 65.6785 - mae: 5.6502 - mse: 65.6785 - val_loss: 87.2140 - val_mae: 7.8155 - val_mse: 87.2140\n",
            "Epoch 77/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.9586 - mae: 5.5606 - mse: 63.9586 - val_loss: 59.1032 - val_mae: 6.1303 - val_mse: 59.1032\n",
            "Epoch 78/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.6245 - mae: 5.9215 - mse: 67.6245 - val_loss: 59.4068 - val_mae: 6.1788 - val_mse: 59.4068\n",
            "Epoch 79/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.2051 - mae: 5.5278 - mse: 67.2051 - val_loss: 75.7629 - val_mae: 7.2915 - val_mse: 75.7629\n",
            "Epoch 80/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.5509 - mae: 5.8213 - mse: 67.5509 - val_loss: 64.8926 - val_mae: 6.6270 - val_mse: 64.8926\n",
            "Epoch 81/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.5574 - mae: 5.7094 - mse: 63.5574 - val_loss: 64.8812 - val_mae: 6.2923 - val_mse: 64.8812\n",
            "Epoch 82/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.6274 - mae: 5.7875 - mse: 68.6274 - val_loss: 63.0308 - val_mae: 5.7428 - val_mse: 63.0308\n",
            "Epoch 83/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.7881 - mae: 5.5636 - mse: 65.7881 - val_loss: 74.8308 - val_mae: 6.1450 - val_mse: 74.8308\n",
            "Epoch 84/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.2134 - mae: 5.8534 - mse: 68.2134 - val_loss: 57.6572 - val_mae: 5.6872 - val_mse: 57.6572\n",
            "Epoch 85/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.3227 - mae: 5.6900 - mse: 65.3227 - val_loss: 57.8553 - val_mae: 5.6751 - val_mse: 57.8553\n",
            "Epoch 86/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.4125 - mae: 5.5259 - mse: 63.4125 - val_loss: 73.6672 - val_mae: 6.0523 - val_mse: 73.6672\n",
            "Epoch 87/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 66.6070 - mae: 5.8289 - mse: 66.6070 - val_loss: 58.2886 - val_mae: 5.7233 - val_mse: 58.2886\n",
            "Epoch 88/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.7716 - mae: 5.6399 - mse: 64.7716 - val_loss: 63.8028 - val_mae: 5.9108 - val_mse: 63.8028\n",
            "Epoch 89/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.5688 - mae: 5.7015 - mse: 64.5688 - val_loss: 81.4997 - val_mae: 6.4318 - val_mse: 81.4997\n",
            "Epoch 90/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 69.3592 - mae: 5.5755 - mse: 69.3592 - val_loss: 258.5352 - val_mae: 14.0549 - val_mse: 258.5352\n",
            "Epoch 91/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 72.3777 - mae: 6.2973 - mse: 72.3777 - val_loss: 93.1200 - val_mae: 8.4034 - val_mse: 93.1200\n",
            "Epoch 92/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.2776 - mae: 5.5112 - mse: 64.2776 - val_loss: 106.8359 - val_mae: 8.9120 - val_mse: 106.8359\n",
            "Epoch 93/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.3891 - mae: 6.1617 - mse: 67.3891 - val_loss: 65.3292 - val_mae: 5.8413 - val_mse: 65.3292\n",
            "Epoch 94/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.2698 - mae: 5.5399 - mse: 67.2698 - val_loss: 56.9989 - val_mae: 5.7642 - val_mse: 56.9989\n",
            "Epoch 95/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.2642 - mae: 5.6069 - mse: 65.2642 - val_loss: 63.8530 - val_mae: 6.0708 - val_mse: 63.8530\n",
            "Epoch 96/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.0723 - mae: 5.6087 - mse: 65.0723 - val_loss: 78.8299 - val_mae: 7.5263 - val_mse: 78.8299\n",
            "Epoch 97/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.4758 - mae: 5.9725 - mse: 67.4758 - val_loss: 56.1556 - val_mae: 5.7974 - val_mse: 56.1556\n",
            "Epoch 98/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.3888 - mae: 5.5459 - mse: 66.3888 - val_loss: 57.3591 - val_mae: 5.7432 - val_mse: 57.3591\n",
            "Epoch 99/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7213 - mae: 5.6190 - mse: 63.7213 - val_loss: 101.0018 - val_mae: 8.2744 - val_mse: 101.0018\n",
            "Epoch 100/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.1207 - mae: 5.8591 - mse: 67.1207 - val_loss: 107.7418 - val_mae: 8.4077 - val_mse: 107.7418\n",
            "Epoch 101/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 71.1923 - mae: 6.0906 - mse: 71.1923 - val_loss: 85.6479 - val_mae: 7.7686 - val_mse: 85.6479\n",
            "Epoch 102/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.3260 - mae: 5.8996 - mse: 65.3260 - val_loss: 68.5824 - val_mae: 6.6833 - val_mse: 68.5824\n",
            "Epoch 103/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.7287 - mae: 5.8240 - mse: 64.7287 - val_loss: 66.5157 - val_mae: 6.4464 - val_mse: 66.5157\n",
            "Epoch 104/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.9272 - mae: 5.6891 - mse: 63.9272 - val_loss: 57.8554 - val_mae: 5.8366 - val_mse: 57.8554\n",
            "Epoch 105/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7854 - mae: 5.5380 - mse: 63.7854 - val_loss: 70.6390 - val_mae: 6.8441 - val_mse: 70.6390\n",
            "Epoch 106/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.1490 - mae: 5.9627 - mse: 67.1490 - val_loss: 102.4586 - val_mae: 8.7325 - val_mse: 102.4586\n",
            "Epoch 107/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 73.0829 - mae: 6.2809 - mse: 73.0829 - val_loss: 88.5668 - val_mae: 6.8865 - val_mse: 88.5668\n",
            "Epoch 108/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.5049 - mae: 5.7684 - mse: 67.5049 - val_loss: 76.8229 - val_mae: 6.2571 - val_mse: 76.8229\n",
            "Epoch 109/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.6407 - mae: 5.5547 - mse: 62.6407 - val_loss: 71.5469 - val_mae: 6.1531 - val_mse: 71.5469\n",
            "Epoch 110/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 66.8527 - mae: 5.7601 - mse: 66.8527 - val_loss: 59.2448 - val_mae: 5.6663 - val_mse: 59.2448\n",
            "Epoch 111/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.0435 - mae: 5.6230 - mse: 63.0435 - val_loss: 79.7533 - val_mae: 6.3471 - val_mse: 79.7533\n",
            "Epoch 112/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.8960 - mae: 5.4843 - mse: 64.8960 - val_loss: 82.5012 - val_mae: 6.5001 - val_mse: 82.5012\n",
            "Epoch 113/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.5308 - mae: 5.5715 - mse: 65.5308 - val_loss: 67.3993 - val_mae: 5.8548 - val_mse: 67.3993\n",
            "Epoch 114/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.6767 - mae: 5.7212 - mse: 68.6767 - val_loss: 68.6875 - val_mae: 6.9594 - val_mse: 68.6875\n",
            "Epoch 115/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.0597 - mae: 6.0214 - mse: 67.0597 - val_loss: 56.4140 - val_mae: 5.7607 - val_mse: 56.4140\n",
            "Epoch 116/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.6413 - mae: 5.7577 - mse: 66.6413 - val_loss: 65.1007 - val_mae: 6.0543 - val_mse: 65.1007\n",
            "Epoch 117/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.9523 - mae: 5.8443 - mse: 63.9523 - val_loss: 69.8375 - val_mae: 7.0536 - val_mse: 69.8375\n",
            "Epoch 118/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 68.2494 - mae: 5.9490 - mse: 68.2494 - val_loss: 57.2367 - val_mae: 5.6506 - val_mse: 57.2367\n",
            "Epoch 119/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.2251 - mae: 5.7308 - mse: 66.2251 - val_loss: 60.6196 - val_mae: 5.9566 - val_mse: 60.6196\n",
            "Epoch 120/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.7043 - mae: 5.9391 - mse: 67.7043 - val_loss: 97.8043 - val_mae: 7.2163 - val_mse: 97.8043\n",
            "Epoch 121/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 68.0515 - mae: 5.6017 - mse: 68.0515 - val_loss: 93.2189 - val_mae: 7.4800 - val_mse: 93.2189\n",
            "Epoch 122/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 68.4570 - mae: 5.9430 - mse: 68.4570 - val_loss: 70.7007 - val_mae: 5.9239 - val_mse: 70.7007\n",
            "Epoch 123/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.2709 - mae: 5.3922 - mse: 63.2709 - val_loss: 59.7238 - val_mae: 6.2272 - val_mse: 59.7238\n",
            "Epoch 124/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.8644 - mae: 5.9778 - mse: 66.8644 - val_loss: 109.3640 - val_mae: 7.7071 - val_mse: 109.3640\n",
            "Epoch 125/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 68.1130 - mae: 5.9027 - mse: 68.1130 - val_loss: 69.6306 - val_mae: 6.5072 - val_mse: 69.6306\n",
            "Epoch 126/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.2675 - mae: 5.6722 - mse: 65.2675 - val_loss: 81.7383 - val_mae: 7.2991 - val_mse: 81.7383\n",
            "Epoch 127/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.4693 - mae: 6.0265 - mse: 67.4693 - val_loss: 60.8476 - val_mae: 5.7472 - val_mse: 60.8476\n",
            "Epoch 128/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.7831 - mae: 5.6031 - mse: 65.7831 - val_loss: 67.3834 - val_mae: 6.1523 - val_mse: 67.3834\n",
            "Epoch 129/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.3241 - mae: 5.6349 - mse: 64.3241 - val_loss: 65.0839 - val_mae: 6.6367 - val_mse: 65.0839\n",
            "Epoch 130/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 68.5919 - mae: 6.0009 - mse: 68.5919 - val_loss: 58.5480 - val_mae: 5.8067 - val_mse: 58.5480\n",
            "Epoch 131/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 66.9904 - mae: 5.7907 - mse: 66.9904 - val_loss: 80.9349 - val_mae: 7.2476 - val_mse: 80.9349\n",
            "Epoch 132/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 65.6610 - mae: 5.8332 - mse: 65.6610 - val_loss: 75.7268 - val_mae: 6.2119 - val_mse: 75.7268\n",
            "Epoch 133/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.6466 - mae: 5.5974 - mse: 64.6466 - val_loss: 103.8434 - val_mae: 7.5802 - val_mse: 103.8434\n",
            "Epoch 134/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.4611 - mae: 5.4717 - mse: 65.4611 - val_loss: 59.3817 - val_mae: 5.8599 - val_mse: 59.3817\n",
            "Epoch 135/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.2595 - mae: 5.4875 - mse: 66.2595 - val_loss: 142.2716 - val_mae: 9.8803 - val_mse: 142.2716\n",
            "Epoch 136/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 76.0996 - mae: 6.3802 - mse: 76.0996 - val_loss: 77.7036 - val_mae: 6.3516 - val_mse: 77.7036\n",
            "Epoch 137/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 73.5525 - mae: 5.8240 - mse: 73.5525 - val_loss: 56.1906 - val_mae: 5.6969 - val_mse: 56.1906\n",
            "Epoch 138/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 67.5050 - mae: 5.7119 - mse: 67.5050 - val_loss: 60.3990 - val_mae: 6.2039 - val_mse: 60.3990\n",
            "Epoch 139/600\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 65.6787 - mae: 5.8418 - mse: 65.6787 - val_loss: 73.5513 - val_mae: 6.7228 - val_mse: 73.5513\n",
            "Epoch 140/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 65.9866 - mae: 5.7707 - mse: 65.9866 - val_loss: 62.0569 - val_mae: 6.3558 - val_mse: 62.0569\n",
            "Epoch 141/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 63.5437 - mae: 5.7353 - mse: 63.5437 - val_loss: 113.7398 - val_mae: 8.5639 - val_mse: 113.7398\n",
            "Epoch 142/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 70.9575 - mae: 5.9437 - mse: 70.9575 - val_loss: 59.3455 - val_mae: 5.6161 - val_mse: 59.3455\n",
            "Epoch 143/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.3447 - mae: 5.6205 - mse: 64.3447 - val_loss: 62.9084 - val_mae: 5.7190 - val_mse: 62.9084\n",
            "Epoch 144/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.6640 - mae: 5.5500 - mse: 64.6640 - val_loss: 64.5027 - val_mae: 5.7849 - val_mse: 64.5027\n",
            "Epoch 145/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 72.6026 - mae: 6.2237 - mse: 72.6026 - val_loss: 76.2425 - val_mae: 6.2479 - val_mse: 76.2425\n",
            "Epoch 146/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 63.5333 - mae: 5.5446 - mse: 63.5333 - val_loss: 57.5286 - val_mae: 5.7040 - val_mse: 57.5286\n",
            "Epoch 147/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 66.4514 - mae: 5.8590 - mse: 66.4514 - val_loss: 135.5396 - val_mae: 9.1186 - val_mse: 135.5396\n",
            "Epoch 148/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.8752 - mae: 5.8273 - mse: 64.8752 - val_loss: 73.2960 - val_mae: 6.0587 - val_mse: 73.2960\n",
            "Epoch 149/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 64.8924 - mae: 5.6394 - mse: 64.8924 - val_loss: 86.6255 - val_mae: 6.6511 - val_mse: 86.6255\n",
            "Epoch 150/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 68.1477 - mae: 5.8046 - mse: 68.1477 - val_loss: 210.2694 - val_mae: 12.0924 - val_mse: 210.2694\n",
            "Epoch 151/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.4051 - mae: 5.6625 - mse: 68.4051 - val_loss: 210.2042 - val_mae: 12.1473 - val_mse: 210.2042\n",
            "Epoch 152/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.8729 - mae: 5.6386 - mse: 67.8729 - val_loss: 127.4667 - val_mae: 8.7662 - val_mse: 127.4667\n",
            "Epoch 153/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.3072 - mae: 5.8733 - mse: 66.3072 - val_loss: 150.9335 - val_mae: 9.8394 - val_mse: 150.9335\n",
            "Epoch 154/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.2156 - mae: 5.5493 - mse: 65.2156 - val_loss: 156.8970 - val_mae: 10.1251 - val_mse: 156.8970\n",
            "Epoch 155/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.4179 - mae: 5.6818 - mse: 65.4179 - val_loss: 175.8428 - val_mae: 10.9508 - val_mse: 175.8428\n",
            "Epoch 156/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.4899 - mae: 5.5868 - mse: 66.4899 - val_loss: 259.1476 - val_mae: 14.0521 - val_mse: 259.1476\n",
            "Epoch 157/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.5345 - mae: 5.6488 - mse: 66.5345 - val_loss: 271.4012 - val_mae: 14.6645 - val_mse: 271.4012\n",
            "Epoch 158/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.5152 - mae: 5.5401 - mse: 67.5152 - val_loss: 247.5409 - val_mae: 13.6839 - val_mse: 247.5409\n",
            "Epoch 159/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.9982 - mae: 5.6742 - mse: 64.9982 - val_loss: 274.8616 - val_mae: 14.6716 - val_mse: 274.8616\n",
            "Epoch 160/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.3702 - mae: 5.5633 - mse: 67.3702 - val_loss: 282.0970 - val_mae: 15.0077 - val_mse: 282.0970\n",
            "Epoch 161/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.5227 - mae: 5.5438 - mse: 66.5227 - val_loss: 251.5215 - val_mae: 13.9534 - val_mse: 251.5214\n",
            "Epoch 162/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.7239 - mae: 5.5524 - mse: 65.7239 - val_loss: 140.4340 - val_mae: 9.1242 - val_mse: 140.4340\n",
            "Epoch 163/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.5638 - mae: 5.8917 - mse: 67.5638 - val_loss: 148.7125 - val_mae: 9.5544 - val_mse: 148.7125\n",
            "Epoch 164/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 72.2601 - mae: 6.0806 - mse: 72.2601 - val_loss: 224.1092 - val_mae: 12.9149 - val_mse: 224.1092\n",
            "Epoch 165/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.1874 - mae: 5.5751 - mse: 64.1874 - val_loss: 345.5655 - val_mae: 16.9335 - val_mse: 345.5655\n",
            "Epoch 166/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.3222 - mae: 5.6081 - mse: 67.3222 - val_loss: 93.4060 - val_mae: 7.0488 - val_mse: 93.4060\n",
            "Epoch 167/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.8456 - mae: 5.9423 - mse: 65.8456 - val_loss: 135.5737 - val_mae: 9.1571 - val_mse: 135.5737\n",
            "Epoch 168/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.7007 - mae: 5.5817 - mse: 64.7007 - val_loss: 117.9695 - val_mae: 8.3089 - val_mse: 117.9695\n",
            "Epoch 169/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.3323 - mae: 5.7639 - mse: 66.3323 - val_loss: 112.6504 - val_mae: 7.7545 - val_mse: 112.6504\n",
            "Epoch 170/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.8516 - mae: 5.8991 - mse: 66.8516 - val_loss: 140.7418 - val_mae: 9.2687 - val_mse: 140.7418\n",
            "Epoch 171/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.9878 - mae: 5.6256 - mse: 65.9878 - val_loss: 83.2098 - val_mae: 6.4842 - val_mse: 83.2098\n",
            "Epoch 172/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.1672 - mae: 5.6585 - mse: 64.1672 - val_loss: 119.1941 - val_mae: 8.3082 - val_mse: 119.1941\n",
            "Epoch 173/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.7981 - mae: 5.3273 - mse: 62.7981 - val_loss: 173.6850 - val_mae: 10.7361 - val_mse: 173.6850\n",
            "Epoch 174/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.3200 - mae: 5.6075 - mse: 64.3200 - val_loss: 120.3445 - val_mae: 8.3803 - val_mse: 120.3445\n",
            "Epoch 175/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.7526 - mae: 5.6160 - mse: 65.7526 - val_loss: 91.6059 - val_mae: 6.9455 - val_mse: 91.6059\n",
            "Epoch 176/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.1281 - mae: 5.5152 - mse: 63.1281 - val_loss: 96.5821 - val_mae: 7.1574 - val_mse: 96.5821\n",
            "Epoch 177/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.7215 - mae: 5.7447 - mse: 64.7215 - val_loss: 155.8080 - val_mae: 10.0415 - val_mse: 155.8080\n",
            "Epoch 178/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.0199 - mae: 5.5062 - mse: 65.0199 - val_loss: 127.0544 - val_mae: 8.4971 - val_mse: 127.0544\n",
            "Epoch 179/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.8220 - mae: 6.2289 - mse: 70.8220 - val_loss: 97.2085 - val_mae: 7.2196 - val_mse: 97.2085\n",
            "Epoch 180/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.1200 - mae: 5.4810 - mse: 63.1200 - val_loss: 110.1621 - val_mae: 7.8672 - val_mse: 110.1621\n",
            "Epoch 181/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.3024 - mae: 5.4834 - mse: 64.3024 - val_loss: 161.8411 - val_mae: 9.9130 - val_mse: 161.8411\n",
            "Epoch 182/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.4997 - mae: 5.6643 - mse: 67.4997 - val_loss: 78.2069 - val_mae: 6.2813 - val_mse: 78.2069\n",
            "Epoch 183/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.9681 - mae: 5.9920 - mse: 67.9681 - val_loss: 98.9631 - val_mae: 7.2620 - val_mse: 98.9631\n",
            "Epoch 184/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.6391 - mae: 5.7110 - mse: 64.6391 - val_loss: 195.5006 - val_mae: 11.7070 - val_mse: 195.5006\n",
            "Epoch 185/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.6412 - mae: 5.3874 - mse: 64.6412 - val_loss: 101.5392 - val_mae: 7.6132 - val_mse: 101.5392\n",
            "Epoch 186/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 77.8990 - mae: 6.6186 - mse: 77.8990 - val_loss: 86.8659 - val_mae: 6.9552 - val_mse: 86.8659\n",
            "Epoch 187/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 66.2785 - mae: 5.7907 - mse: 66.2785 - val_loss: 64.2146 - val_mae: 5.8317 - val_mse: 64.2146\n",
            "Epoch 188/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.4780 - mae: 5.6548 - mse: 65.4780 - val_loss: 112.8721 - val_mae: 7.9669 - val_mse: 112.8721\n",
            "Epoch 189/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.0773 - mae: 5.5215 - mse: 65.0773 - val_loss: 104.9397 - val_mae: 7.8916 - val_mse: 104.9397\n",
            "Epoch 190/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.4734 - mae: 5.9966 - mse: 67.4734 - val_loss: 67.4287 - val_mae: 5.9777 - val_mse: 67.4287\n",
            "Epoch 191/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.2939 - mae: 5.7732 - mse: 64.2939 - val_loss: 89.6027 - val_mae: 6.7506 - val_mse: 89.6027\n",
            "Epoch 192/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.7426 - mae: 5.6080 - mse: 63.7426 - val_loss: 95.9711 - val_mae: 7.0402 - val_mse: 95.9711\n",
            "Epoch 193/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.8848 - mae: 5.3907 - mse: 63.8848 - val_loss: 71.2371 - val_mae: 6.0405 - val_mse: 71.2371\n",
            "Epoch 194/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.4986 - mae: 5.7763 - mse: 64.4986 - val_loss: 96.1527 - val_mae: 7.2779 - val_mse: 96.1527\n",
            "Epoch 195/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.7115 - mae: 5.8717 - mse: 67.7115 - val_loss: 68.7488 - val_mae: 5.8630 - val_mse: 68.7488\n",
            "Epoch 196/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.7938 - mae: 5.7736 - mse: 65.7938 - val_loss: 65.9058 - val_mae: 6.3544 - val_mse: 65.9058\n",
            "Epoch 197/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.5857 - mae: 5.4286 - mse: 64.5857 - val_loss: 75.6663 - val_mae: 6.1509 - val_mse: 75.6663\n",
            "Epoch 198/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.8086 - mae: 5.6044 - mse: 64.8086 - val_loss: 57.0240 - val_mae: 5.8135 - val_mse: 57.0240\n",
            "Epoch 199/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.1225 - mae: 5.8475 - mse: 67.1225 - val_loss: 58.4122 - val_mae: 5.6748 - val_mse: 58.4122\n",
            "Epoch 200/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.5124 - mae: 5.6732 - mse: 63.5124 - val_loss: 74.9512 - val_mae: 6.1903 - val_mse: 74.9512\n",
            "Epoch 201/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.6761 - mae: 5.7586 - mse: 62.6761 - val_loss: 87.0131 - val_mae: 6.6493 - val_mse: 87.0130\n",
            "Epoch 202/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.6643 - mae: 5.3801 - mse: 62.6643 - val_loss: 65.5395 - val_mae: 5.8518 - val_mse: 65.5395\n",
            "Epoch 203/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.4484 - mae: 6.0496 - mse: 68.4484 - val_loss: 68.3660 - val_mae: 5.8550 - val_mse: 68.3660\n",
            "Epoch 204/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 62.7291 - mae: 5.6056 - mse: 62.7291 - val_loss: 92.3979 - val_mae: 6.8646 - val_mse: 92.3979\n",
            "Epoch 205/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.7198 - mae: 5.4374 - mse: 65.7198 - val_loss: 83.0154 - val_mae: 6.3538 - val_mse: 83.0154\n",
            "Epoch 206/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.7568 - mae: 5.5903 - mse: 65.7568 - val_loss: 59.5580 - val_mae: 5.6574 - val_mse: 59.5580\n",
            "Epoch 207/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.5510 - mae: 5.6266 - mse: 63.5510 - val_loss: 69.7123 - val_mae: 5.9065 - val_mse: 69.7123\n",
            "Epoch 208/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.1324 - mae: 5.5924 - mse: 64.1324 - val_loss: 74.7386 - val_mae: 6.5661 - val_mse: 74.7386\n",
            "Epoch 209/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.6584 - mae: 5.6991 - mse: 63.6584 - val_loss: 68.4417 - val_mae: 5.8618 - val_mse: 68.4417\n",
            "Epoch 210/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.5693 - mae: 5.5081 - mse: 63.5693 - val_loss: 75.3861 - val_mae: 6.0807 - val_mse: 75.3861\n",
            "Epoch 211/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.3543 - mae: 5.4482 - mse: 63.3543 - val_loss: 114.3344 - val_mae: 8.1422 - val_mse: 114.3344\n",
            "Epoch 212/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 66.4749 - mae: 5.5853 - mse: 66.4749 - val_loss: 66.6762 - val_mae: 5.8539 - val_mse: 66.6762\n",
            "Epoch 213/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.8817 - mae: 5.5417 - mse: 63.8817 - val_loss: 57.9845 - val_mae: 5.7622 - val_mse: 57.9845\n",
            "Epoch 214/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.5167 - mae: 5.9533 - mse: 64.5167 - val_loss: 98.1888 - val_mae: 7.2390 - val_mse: 98.1888\n",
            "Epoch 215/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.5052 - mae: 5.3928 - mse: 64.5052 - val_loss: 75.5640 - val_mae: 6.0198 - val_mse: 75.5640\n",
            "Epoch 216/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.9889 - mae: 5.6441 - mse: 64.9889 - val_loss: 72.6589 - val_mae: 5.9161 - val_mse: 72.6589\n",
            "Epoch 217/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.1374 - mae: 5.6382 - mse: 63.1374 - val_loss: 62.6506 - val_mae: 5.7616 - val_mse: 62.6506\n",
            "Epoch 218/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.4286 - mae: 5.5216 - mse: 63.4286 - val_loss: 66.1834 - val_mae: 5.7977 - val_mse: 66.1834\n",
            "Epoch 219/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.4948 - mae: 5.6298 - mse: 64.4948 - val_loss: 95.5118 - val_mae: 7.1373 - val_mse: 95.5118\n",
            "Epoch 220/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.1704 - mae: 5.6442 - mse: 67.1704 - val_loss: 61.8842 - val_mae: 5.7661 - val_mse: 61.8842\n",
            "Epoch 221/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.5080 - mae: 5.5406 - mse: 62.5080 - val_loss: 73.4690 - val_mae: 6.0155 - val_mse: 73.4690\n",
            "Epoch 222/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6684 - mae: 5.4628 - mse: 63.6684 - val_loss: 102.5426 - val_mae: 7.5868 - val_mse: 102.5426\n",
            "Epoch 223/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.5016 - mae: 5.9517 - mse: 70.5016 - val_loss: 70.2434 - val_mae: 6.1807 - val_mse: 70.2434\n",
            "Epoch 224/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.3549 - mae: 5.4401 - mse: 62.3549 - val_loss: 814.2673 - val_mae: 25.5393 - val_mse: 814.2673\n",
            "Epoch 225/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 79.1905 - mae: 6.4638 - mse: 79.1905 - val_loss: 87.0603 - val_mae: 6.8953 - val_mse: 87.0603\n",
            "Epoch 226/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.7478 - mae: 5.7670 - mse: 68.7478 - val_loss: 68.7586 - val_mae: 6.0975 - val_mse: 68.7586\n",
            "Epoch 227/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.8094 - mae: 5.7234 - mse: 68.8094 - val_loss: 70.2286 - val_mae: 6.2309 - val_mse: 70.2286\n",
            "Epoch 228/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.1009 - mae: 5.8318 - mse: 67.1009 - val_loss: 69.5776 - val_mae: 6.1196 - val_mse: 69.5776\n",
            "Epoch 229/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.4493 - mae: 5.6862 - mse: 66.4493 - val_loss: 108.0109 - val_mae: 8.6132 - val_mse: 108.0109\n",
            "Epoch 230/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 71.9712 - mae: 6.3197 - mse: 71.9712 - val_loss: 73.0380 - val_mae: 6.0115 - val_mse: 73.0380\n",
            "Epoch 231/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.6014 - mae: 5.7591 - mse: 70.6014 - val_loss: 65.6632 - val_mae: 5.9490 - val_mse: 65.6632\n",
            "Epoch 232/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.1479 - mae: 5.7755 - mse: 67.1479 - val_loss: 66.8938 - val_mae: 5.8430 - val_mse: 66.8938\n",
            "Epoch 233/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.4669 - mae: 5.7551 - mse: 66.4669 - val_loss: 70.3093 - val_mae: 5.8903 - val_mse: 70.3093\n",
            "Epoch 234/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.4598 - mae: 5.5872 - mse: 66.4598 - val_loss: 65.6561 - val_mae: 5.7972 - val_mse: 65.6561\n",
            "Epoch 235/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.0080 - mae: 5.6931 - mse: 67.0080 - val_loss: 63.5850 - val_mae: 6.3222 - val_mse: 63.5850\n",
            "Epoch 236/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.4644 - mae: 5.8177 - mse: 65.4644 - val_loss: 61.5979 - val_mae: 5.7152 - val_mse: 61.5979\n",
            "Epoch 237/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 67.7276 - mae: 5.8886 - mse: 67.7276 - val_loss: 62.7154 - val_mae: 6.3039 - val_mse: 62.7154\n",
            "Epoch 238/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.8504 - mae: 5.8524 - mse: 66.8504 - val_loss: 68.1943 - val_mae: 5.9309 - val_mse: 68.1943\n",
            "Epoch 239/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.4048 - mae: 5.6355 - mse: 67.4048 - val_loss: 67.5056 - val_mae: 5.7705 - val_mse: 67.5056\n",
            "Epoch 240/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.3723 - mae: 5.6532 - mse: 66.3723 - val_loss: 73.3870 - val_mae: 6.0641 - val_mse: 73.3870\n",
            "Epoch 241/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.8309 - mae: 5.5929 - mse: 66.8309 - val_loss: 59.1032 - val_mae: 5.8800 - val_mse: 59.1032\n",
            "Epoch 242/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.4669 - mae: 5.8144 - mse: 64.4669 - val_loss: 58.0797 - val_mae: 5.6362 - val_mse: 58.0797\n",
            "Epoch 243/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.1269 - mae: 5.7333 - mse: 64.1269 - val_loss: 65.5966 - val_mae: 6.0706 - val_mse: 65.5966\n",
            "Epoch 244/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.6131 - mae: 5.9901 - mse: 66.6131 - val_loss: 68.2833 - val_mae: 5.8788 - val_mse: 68.2833\n",
            "Epoch 245/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.8319 - mae: 5.7990 - mse: 64.8319 - val_loss: 70.5978 - val_mae: 5.8660 - val_mse: 70.5978\n",
            "Epoch 246/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.9935 - mae: 5.6306 - mse: 64.9935 - val_loss: 75.2319 - val_mae: 6.0827 - val_mse: 75.2319\n",
            "Epoch 247/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.5583 - mae: 5.4107 - mse: 64.5583 - val_loss: 64.9804 - val_mae: 5.7779 - val_mse: 64.9804\n",
            "Epoch 248/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.3925 - mae: 5.4969 - mse: 63.3925 - val_loss: 87.9379 - val_mae: 6.7254 - val_mse: 87.9379\n",
            "Epoch 249/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.8534 - mae: 5.5369 - mse: 67.8534 - val_loss: 75.1351 - val_mae: 5.9827 - val_mse: 75.1351\n",
            "Epoch 250/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.9001 - mae: 5.4659 - mse: 64.9001 - val_loss: 65.2762 - val_mae: 6.2176 - val_mse: 65.2762\n",
            "Epoch 251/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.9381 - mae: 6.1155 - mse: 67.9381 - val_loss: 77.5656 - val_mae: 6.1091 - val_mse: 77.5656\n",
            "Epoch 252/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.2396 - mae: 5.4927 - mse: 64.2396 - val_loss: 80.0164 - val_mae: 6.2123 - val_mse: 80.0164\n",
            "Epoch 253/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.3880 - mae: 5.3735 - mse: 64.3880 - val_loss: 79.7614 - val_mae: 6.1960 - val_mse: 79.7614\n",
            "Epoch 254/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.4662 - mae: 5.4381 - mse: 63.4662 - val_loss: 73.1489 - val_mae: 5.9338 - val_mse: 73.1489\n",
            "Epoch 255/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.6053 - mae: 5.7084 - mse: 64.6053 - val_loss: 153.2491 - val_mae: 8.7248 - val_mse: 153.2491\n",
            "Epoch 256/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.4236 - mae: 5.5088 - mse: 66.4236 - val_loss: 124.2307 - val_mae: 8.4480 - val_mse: 124.2307\n",
            "Epoch 257/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 74.1665 - mae: 6.4636 - mse: 74.1665 - val_loss: 78.1822 - val_mae: 6.1275 - val_mse: 78.1822\n",
            "Epoch 258/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.7293 - mae: 5.7935 - mse: 65.7293 - val_loss: 73.3586 - val_mae: 5.9903 - val_mse: 73.3586\n",
            "Epoch 259/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.6306 - mae: 5.6231 - mse: 64.6306 - val_loss: 89.2585 - val_mae: 6.7978 - val_mse: 89.2585\n",
            "Epoch 260/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.8567 - mae: 5.5509 - mse: 64.8567 - val_loss: 82.8953 - val_mae: 6.4800 - val_mse: 82.8953\n",
            "Epoch 261/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.9904 - mae: 5.5387 - mse: 63.9904 - val_loss: 61.3884 - val_mae: 6.1692 - val_mse: 61.3884\n",
            "Epoch 262/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 69.9367 - mae: 6.0298 - mse: 69.9367 - val_loss: 66.8379 - val_mae: 5.8797 - val_mse: 66.8379\n",
            "Epoch 263/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.2155 - mae: 5.6130 - mse: 65.2155 - val_loss: 58.6850 - val_mae: 5.6967 - val_mse: 58.6850\n",
            "Epoch 264/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.9354 - mae: 5.7930 - mse: 67.9354 - val_loss: 57.1966 - val_mae: 5.7154 - val_mse: 57.1966\n",
            "Epoch 265/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7624 - mae: 5.7502 - mse: 63.7624 - val_loss: 79.4197 - val_mae: 6.4371 - val_mse: 79.4197\n",
            "Epoch 266/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.6606 - mae: 5.6967 - mse: 68.6606 - val_loss: 76.3001 - val_mae: 6.1793 - val_mse: 76.3001\n",
            "Epoch 267/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.2488 - mae: 5.6281 - mse: 67.2488 - val_loss: 60.0113 - val_mae: 5.7080 - val_mse: 60.0113\n",
            "Epoch 268/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.6769 - mae: 5.6087 - mse: 64.6769 - val_loss: 67.1139 - val_mae: 5.8610 - val_mse: 67.1139\n",
            "Epoch 269/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.1042 - mae: 5.6062 - mse: 67.1042 - val_loss: 113.5185 - val_mae: 8.4869 - val_mse: 113.5185\n",
            "Epoch 270/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.0324 - mae: 5.9921 - mse: 67.0324 - val_loss: 65.5629 - val_mae: 5.9397 - val_mse: 65.5629\n",
            "Epoch 271/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.7681 - mae: 5.6200 - mse: 63.7681 - val_loss: 91.1873 - val_mae: 6.9052 - val_mse: 91.1873\n",
            "Epoch 272/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.0858 - mae: 5.6801 - mse: 66.0858 - val_loss: 67.7561 - val_mae: 5.9732 - val_mse: 67.7561\n",
            "Epoch 273/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.5095 - mae: 5.5600 - mse: 63.5095 - val_loss: 68.5541 - val_mae: 5.9145 - val_mse: 68.5541\n",
            "Epoch 274/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 64.3910 - mae: 5.4608 - mse: 64.3910 - val_loss: 77.7927 - val_mae: 6.4020 - val_mse: 77.7927\n",
            "Epoch 275/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.5424 - mae: 5.5850 - mse: 63.5424 - val_loss: 73.6676 - val_mae: 6.1185 - val_mse: 73.6676\n",
            "Epoch 276/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.4577 - mae: 5.5450 - mse: 64.4577 - val_loss: 70.8906 - val_mae: 6.1985 - val_mse: 70.8906\n",
            "Epoch 277/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.7467 - mae: 5.6490 - mse: 63.7467 - val_loss: 64.2646 - val_mae: 5.8562 - val_mse: 64.2646\n",
            "Epoch 278/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.6550 - mae: 5.4797 - mse: 63.6550 - val_loss: 65.6454 - val_mae: 6.0903 - val_mse: 65.6454\n",
            "Epoch 279/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.6621 - mae: 5.7175 - mse: 63.6621 - val_loss: 83.5008 - val_mae: 6.4867 - val_mse: 83.5008\n",
            "Epoch 280/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.8694 - mae: 5.4054 - mse: 64.8694 - val_loss: 68.5375 - val_mae: 5.8540 - val_mse: 68.5375\n",
            "Epoch 281/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.0039 - mae: 5.2909 - mse: 62.0039 - val_loss: 61.0309 - val_mae: 5.7904 - val_mse: 61.0309\n",
            "Epoch 282/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.3783 - mae: 5.6084 - mse: 63.3783 - val_loss: 92.1391 - val_mae: 6.9634 - val_mse: 92.1391\n",
            "Epoch 283/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.6921 - mae: 5.3602 - mse: 64.6921 - val_loss: 63.2034 - val_mae: 5.8593 - val_mse: 63.2034\n",
            "Epoch 284/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 61.7950 - mae: 5.5347 - mse: 61.7950 - val_loss: 74.5099 - val_mae: 6.3023 - val_mse: 74.5099\n",
            "Epoch 285/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.9682 - mae: 5.6901 - mse: 63.9682 - val_loss: 95.7671 - val_mae: 7.1326 - val_mse: 95.7671\n",
            "Epoch 286/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.7893 - mae: 5.4334 - mse: 65.7893 - val_loss: 81.4659 - val_mae: 6.3886 - val_mse: 81.4659\n",
            "Epoch 287/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 67.4065 - mae: 5.5557 - mse: 67.4065 - val_loss: 76.1445 - val_mae: 6.1812 - val_mse: 76.1445\n",
            "Epoch 288/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.8374 - mae: 5.5145 - mse: 63.8374 - val_loss: 66.4239 - val_mae: 5.9691 - val_mse: 66.4239\n",
            "Epoch 289/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 64.3032 - mae: 5.6488 - mse: 64.3032 - val_loss: 67.1820 - val_mae: 5.8215 - val_mse: 67.1820\n",
            "Epoch 290/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 62.4002 - mae: 5.3997 - mse: 62.4002 - val_loss: 62.7413 - val_mae: 5.7125 - val_mse: 62.7413\n",
            "Epoch 291/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.0923 - mae: 5.4380 - mse: 62.0923 - val_loss: 325.5703 - val_mae: 14.0214 - val_mse: 325.5703\n",
            "Epoch 292/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 91.7682 - mae: 6.7441 - mse: 91.7682 - val_loss: 92.1082 - val_mae: 7.9827 - val_mse: 92.1082\n",
            "Epoch 293/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 69.3157 - mae: 6.0308 - mse: 69.3157 - val_loss: 60.8178 - val_mae: 5.7604 - val_mse: 60.8178\n",
            "Epoch 294/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 64.4582 - mae: 5.5778 - mse: 64.4582 - val_loss: 100.0174 - val_mae: 8.7508 - val_mse: 100.0174\n",
            "Epoch 295/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 71.7555 - mae: 6.2082 - mse: 71.7555 - val_loss: 58.3422 - val_mae: 5.6367 - val_mse: 58.3422\n",
            "Epoch 296/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.9476 - mae: 5.4786 - mse: 63.9476 - val_loss: 64.0711 - val_mae: 6.3781 - val_mse: 64.0711\n",
            "Epoch 297/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 65.9037 - mae: 5.9642 - mse: 65.9037 - val_loss: 71.4147 - val_mae: 5.9635 - val_mse: 71.4147\n",
            "Epoch 298/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.8771 - mae: 5.4996 - mse: 65.8771 - val_loss: 81.0198 - val_mae: 6.3798 - val_mse: 81.0198\n",
            "Epoch 299/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 66.5554 - mae: 5.4152 - mse: 66.5554 - val_loss: 60.7213 - val_mae: 5.6853 - val_mse: 60.7213\n",
            "Epoch 300/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 61.8287 - mae: 5.5110 - mse: 61.8287 - val_loss: 71.7471 - val_mae: 6.2071 - val_mse: 71.7471\n",
            "Epoch 301/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 64.2327 - mae: 5.6481 - mse: 64.2327 - val_loss: 65.4447 - val_mae: 6.0248 - val_mse: 65.4447\n",
            "Epoch 302/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6337 - mae: 5.7623 - mse: 63.6337 - val_loss: 69.7934 - val_mae: 5.9009 - val_mse: 69.7934\n",
            "Epoch 303/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.1121 - mae: 5.4570 - mse: 63.1121 - val_loss: 58.0680 - val_mae: 5.8508 - val_mse: 58.0680\n",
            "Epoch 304/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.6666 - mae: 5.9525 - mse: 66.6666 - val_loss: 89.6742 - val_mae: 6.8202 - val_mse: 89.6742\n",
            "Epoch 305/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.9098 - mae: 5.2985 - mse: 64.9098 - val_loss: 93.8558 - val_mae: 7.5268 - val_mse: 93.8558\n",
            "Epoch 306/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.2142 - mae: 5.8569 - mse: 67.2142 - val_loss: 66.0013 - val_mae: 5.7724 - val_mse: 66.0013\n",
            "Epoch 307/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.9153 - mae: 5.4521 - mse: 62.9153 - val_loss: 62.7415 - val_mae: 5.7202 - val_mse: 62.7415\n",
            "Epoch 308/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.7314 - mae: 5.6020 - mse: 62.7314 - val_loss: 82.4999 - val_mae: 6.4847 - val_mse: 82.4999\n",
            "Epoch 309/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.6439 - mae: 5.6402 - mse: 66.6439 - val_loss: 62.7540 - val_mae: 5.7180 - val_mse: 62.7540\n",
            "Epoch 310/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.4581 - mae: 5.5984 - mse: 63.4581 - val_loss: 69.5195 - val_mae: 5.8651 - val_mse: 69.5195\n",
            "Epoch 311/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7678 - mae: 5.4272 - mse: 63.7678 - val_loss: 80.9161 - val_mae: 7.0381 - val_mse: 80.9161\n",
            "Epoch 312/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.1136 - mae: 5.8044 - mse: 64.1136 - val_loss: 90.8924 - val_mae: 7.0161 - val_mse: 90.8924\n",
            "Epoch 313/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.3941 - mae: 5.9121 - mse: 66.3940 - val_loss: 58.3257 - val_mae: 5.7514 - val_mse: 58.3257\n",
            "Epoch 314/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6689 - mae: 5.6646 - mse: 63.6689 - val_loss: 68.4550 - val_mae: 5.8769 - val_mse: 68.4550\n",
            "Epoch 315/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.8412 - mae: 5.5035 - mse: 62.8412 - val_loss: 101.1763 - val_mae: 7.6167 - val_mse: 101.1763\n",
            "Epoch 316/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.5014 - mae: 5.5503 - mse: 66.5014 - val_loss: 74.8612 - val_mae: 6.4879 - val_mse: 74.8612\n",
            "Epoch 317/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.5956 - mae: 5.3959 - mse: 63.5956 - val_loss: 56.6042 - val_mae: 5.7438 - val_mse: 56.6042\n",
            "Epoch 318/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.5733 - mae: 5.6705 - mse: 63.5733 - val_loss: 78.8796 - val_mae: 6.3587 - val_mse: 78.8796\n",
            "Epoch 319/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.6565 - mae: 5.4435 - mse: 67.6565 - val_loss: 81.2363 - val_mae: 7.4406 - val_mse: 81.2363\n",
            "Epoch 320/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 70.1107 - mae: 6.1555 - mse: 70.1107 - val_loss: 82.7502 - val_mae: 6.4680 - val_mse: 82.7502\n",
            "Epoch 321/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 66.7806 - mae: 5.4188 - mse: 66.7806 - val_loss: 59.0524 - val_mae: 5.9141 - val_mse: 59.0524\n",
            "Epoch 322/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.7277 - mae: 5.6445 - mse: 64.7277 - val_loss: 64.0707 - val_mae: 5.8613 - val_mse: 64.0707\n",
            "Epoch 323/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 64.7654 - mae: 5.7101 - mse: 64.7654 - val_loss: 89.5762 - val_mae: 6.7330 - val_mse: 89.5762\n",
            "Epoch 324/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 69.8371 - mae: 5.6382 - mse: 69.8371 - val_loss: 60.3324 - val_mae: 5.7316 - val_mse: 60.3324\n",
            "Epoch 325/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.7198 - mae: 5.4487 - mse: 62.7198 - val_loss: 96.5946 - val_mae: 7.1462 - val_mse: 96.5946\n",
            "Epoch 326/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.7795 - mae: 5.5314 - mse: 66.7795 - val_loss: 136.0628 - val_mae: 8.7785 - val_mse: 136.0628\n",
            "Epoch 327/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.3270 - mae: 5.5891 - mse: 64.3270 - val_loss: 94.3984 - val_mae: 7.0371 - val_mse: 94.3984\n",
            "Epoch 328/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6761 - mae: 5.3901 - mse: 63.6761 - val_loss: 87.7434 - val_mae: 6.7407 - val_mse: 87.7434\n",
            "Epoch 329/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.1474 - mae: 5.5371 - mse: 66.1474 - val_loss: 57.0134 - val_mae: 5.6770 - val_mse: 57.0134\n",
            "Epoch 330/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.7896 - mae: 5.7522 - mse: 65.7896 - val_loss: 129.4769 - val_mae: 9.0714 - val_mse: 129.4769\n",
            "Epoch 331/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 74.6810 - mae: 6.2701 - mse: 74.6810 - val_loss: 65.4247 - val_mae: 5.7768 - val_mse: 65.4247\n",
            "Epoch 332/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.1403 - mae: 5.4818 - mse: 64.1403 - val_loss: 96.3815 - val_mae: 7.4138 - val_mse: 96.3815\n",
            "Epoch 333/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.1920 - mae: 5.8441 - mse: 68.1920 - val_loss: 71.2830 - val_mae: 5.9063 - val_mse: 71.2830\n",
            "Epoch 334/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.2968 - mae: 5.4330 - mse: 64.2968 - val_loss: 73.2605 - val_mae: 6.9159 - val_mse: 73.2605\n",
            "Epoch 335/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.1288 - mae: 6.0144 - mse: 66.1288 - val_loss: 74.9848 - val_mae: 6.0784 - val_mse: 74.9848\n",
            "Epoch 336/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.3394 - mae: 5.4640 - mse: 63.3394 - val_loss: 83.9328 - val_mae: 6.3694 - val_mse: 83.9328\n",
            "Epoch 337/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.8644 - mae: 5.4996 - mse: 63.8644 - val_loss: 59.1940 - val_mae: 5.7952 - val_mse: 59.1940\n",
            "Epoch 338/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.5728 - mae: 5.5571 - mse: 63.5728 - val_loss: 71.0856 - val_mae: 5.9635 - val_mse: 71.0856\n",
            "Epoch 339/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.6046 - mae: 5.4706 - mse: 65.6046 - val_loss: 79.8784 - val_mae: 6.4715 - val_mse: 79.8784\n",
            "Epoch 340/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.0397 - mae: 5.5252 - mse: 65.0397 - val_loss: 59.3632 - val_mae: 6.1529 - val_mse: 59.3631\n",
            "Epoch 341/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.1868 - mae: 5.8004 - mse: 64.1868 - val_loss: 68.7563 - val_mae: 5.8729 - val_mse: 68.7563\n",
            "Epoch 342/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.1236 - mae: 5.3865 - mse: 64.1236 - val_loss: 62.3615 - val_mae: 6.3958 - val_mse: 62.3615\n",
            "Epoch 343/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.2587 - mae: 5.8717 - mse: 66.2587 - val_loss: 58.5215 - val_mae: 5.6318 - val_mse: 58.5215\n",
            "Epoch 344/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.1436 - mae: 5.6518 - mse: 65.1436 - val_loss: 55.8467 - val_mae: 5.6835 - val_mse: 55.8467\n",
            "Epoch 345/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.8414 - mae: 5.5220 - mse: 63.8414 - val_loss: 77.2216 - val_mae: 7.2055 - val_mse: 77.2216\n",
            "Epoch 346/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.0747 - mae: 6.1437 - mse: 67.0747 - val_loss: 56.3893 - val_mae: 5.6769 - val_mse: 56.3893\n",
            "Epoch 347/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.2548 - mae: 5.5377 - mse: 62.2548 - val_loss: 77.1132 - val_mae: 6.1120 - val_mse: 77.1132\n",
            "Epoch 348/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.8780 - mae: 5.2491 - mse: 63.8780 - val_loss: 57.7685 - val_mae: 5.7253 - val_mse: 57.7685\n",
            "Epoch 349/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.7199 - mae: 5.5561 - mse: 63.7199 - val_loss: 67.6510 - val_mae: 5.8121 - val_mse: 67.6510\n",
            "Epoch 350/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.4183 - mae: 5.3388 - mse: 62.4183 - val_loss: 56.7693 - val_mae: 5.6336 - val_mse: 56.7693\n",
            "Epoch 351/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.4214 - mae: 5.4525 - mse: 62.4214 - val_loss: 68.0924 - val_mae: 5.8182 - val_mse: 68.0924\n",
            "Epoch 352/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.5372 - mae: 5.5232 - mse: 63.5372 - val_loss: 87.4326 - val_mae: 6.7329 - val_mse: 87.4326\n",
            "Epoch 353/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.6027 - mae: 5.1770 - mse: 64.6027 - val_loss: 56.5772 - val_mae: 5.7393 - val_mse: 56.5772\n",
            "Epoch 354/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.8607 - mae: 5.4655 - mse: 62.8607 - val_loss: 71.7429 - val_mae: 5.9960 - val_mse: 71.7429\n",
            "Epoch 355/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.0962 - mae: 5.2542 - mse: 63.0962 - val_loss: 65.5604 - val_mae: 5.7219 - val_mse: 65.5604\n",
            "Epoch 356/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 61.4682 - mae: 5.2637 - mse: 61.4682 - val_loss: 61.3292 - val_mae: 5.6553 - val_mse: 61.3292\n",
            "Epoch 357/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.1789 - mae: 5.3197 - mse: 63.1789 - val_loss: 57.0763 - val_mae: 5.6177 - val_mse: 57.0763\n",
            "Epoch 358/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.7827 - mae: 5.5775 - mse: 63.7827 - val_loss: 75.7440 - val_mae: 6.1279 - val_mse: 75.7440\n",
            "Epoch 359/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.0755 - mae: 5.3001 - mse: 64.0755 - val_loss: 85.3084 - val_mae: 6.5214 - val_mse: 85.3084\n",
            "Epoch 360/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.0710 - mae: 5.3336 - mse: 65.0710 - val_loss: 61.6292 - val_mae: 5.6570 - val_mse: 61.6292\n",
            "Epoch 361/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.6670 - mae: 5.2496 - mse: 61.6670 - val_loss: 62.6006 - val_mae: 6.3467 - val_mse: 62.6006\n",
            "Epoch 362/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 67.1174 - mae: 5.7901 - mse: 67.1174 - val_loss: 61.5264 - val_mae: 6.1766 - val_mse: 61.5264\n",
            "Epoch 363/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.8906 - mae: 5.8517 - mse: 64.8906 - val_loss: 95.8039 - val_mae: 7.5458 - val_mse: 95.8039\n",
            "Epoch 364/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.9327 - mae: 5.8001 - mse: 65.9327 - val_loss: 67.7716 - val_mae: 6.5689 - val_mse: 67.7716\n",
            "Epoch 365/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.7666 - mae: 5.7378 - mse: 65.7666 - val_loss: 58.2468 - val_mae: 5.8013 - val_mse: 58.2468\n",
            "Epoch 366/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.1207 - mae: 5.5269 - mse: 63.1207 - val_loss: 72.3312 - val_mae: 6.3666 - val_mse: 72.3312\n",
            "Epoch 367/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.4184 - mae: 5.5336 - mse: 67.4184 - val_loss: 67.8400 - val_mae: 5.8234 - val_mse: 67.8400\n",
            "Epoch 368/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.9437 - mae: 5.4217 - mse: 63.9437 - val_loss: 70.7149 - val_mae: 6.1105 - val_mse: 70.7149\n",
            "Epoch 369/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.8222 - mae: 5.6315 - mse: 65.8222 - val_loss: 97.1873 - val_mae: 8.4342 - val_mse: 97.1873\n",
            "Epoch 370/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.3077 - mae: 5.9178 - mse: 68.3077 - val_loss: 82.3524 - val_mae: 6.3779 - val_mse: 82.3524\n",
            "Epoch 371/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.0467 - mae: 5.3892 - mse: 66.0467 - val_loss: 64.9490 - val_mae: 6.4383 - val_mse: 64.9490\n",
            "Epoch 372/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.4888 - mae: 5.8162 - mse: 65.4888 - val_loss: 65.0253 - val_mae: 5.7298 - val_mse: 65.0253\n",
            "Epoch 373/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.5416 - mae: 5.5182 - mse: 63.5416 - val_loss: 98.2493 - val_mae: 7.2614 - val_mse: 98.2493\n",
            "Epoch 374/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.8805 - mae: 5.6893 - mse: 70.8805 - val_loss: 60.5105 - val_mae: 5.6841 - val_mse: 60.5105\n",
            "Epoch 375/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.3658 - mae: 5.3520 - mse: 63.3658 - val_loss: 65.9333 - val_mae: 5.7803 - val_mse: 65.9333\n",
            "Epoch 376/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.8088 - mae: 5.3114 - mse: 62.8088 - val_loss: 63.7540 - val_mae: 6.0621 - val_mse: 63.7540\n",
            "Epoch 377/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.1423 - mae: 5.6862 - mse: 62.1423 - val_loss: 68.7192 - val_mae: 5.8076 - val_mse: 68.7192\n",
            "Epoch 378/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.5349 - mae: 5.4494 - mse: 64.5349 - val_loss: 62.4034 - val_mae: 5.6754 - val_mse: 62.4034\n",
            "Epoch 379/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.6803 - mae: 5.4308 - mse: 63.6803 - val_loss: 62.5062 - val_mae: 5.6815 - val_mse: 62.5062\n",
            "Epoch 380/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.9868 - mae: 5.4575 - mse: 63.9868 - val_loss: 65.6105 - val_mae: 5.7892 - val_mse: 65.6105\n",
            "Epoch 381/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6094 - mae: 5.4012 - mse: 63.6094 - val_loss: 65.8468 - val_mae: 5.7330 - val_mse: 65.8468\n",
            "Epoch 382/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.8887 - mae: 5.4749 - mse: 64.8887 - val_loss: 60.7671 - val_mae: 6.0566 - val_mse: 60.7671\n",
            "Epoch 383/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.6763 - mae: 5.7528 - mse: 62.6763 - val_loss: 70.5589 - val_mae: 5.9161 - val_mse: 70.5589\n",
            "Epoch 384/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.2961 - mae: 5.4413 - mse: 64.2961 - val_loss: 70.5154 - val_mae: 5.9109 - val_mse: 70.5154\n",
            "Epoch 385/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.5986 - mae: 5.4702 - mse: 62.5986 - val_loss: 76.4141 - val_mae: 6.2295 - val_mse: 76.4141\n",
            "Epoch 386/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.2210 - mae: 5.3430 - mse: 64.2210 - val_loss: 59.6505 - val_mae: 5.6257 - val_mse: 59.6505\n",
            "Epoch 387/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.1268 - mae: 5.5184 - mse: 64.1268 - val_loss: 77.9725 - val_mae: 7.1142 - val_mse: 77.9725\n",
            "Epoch 388/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 69.1071 - mae: 6.1600 - mse: 69.1071 - val_loss: 63.1442 - val_mae: 5.7228 - val_mse: 63.1442\n",
            "Epoch 389/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.5202 - mae: 5.3914 - mse: 63.5202 - val_loss: 74.3904 - val_mae: 6.8081 - val_mse: 74.3904\n",
            "Epoch 390/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.8522 - mae: 5.7553 - mse: 63.8522 - val_loss: 61.3656 - val_mae: 5.7037 - val_mse: 61.3656\n",
            "Epoch 391/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.5075 - mae: 5.3903 - mse: 64.5075 - val_loss: 57.1598 - val_mae: 5.9346 - val_mse: 57.1598\n",
            "Epoch 392/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.1317 - mae: 5.7385 - mse: 64.1317 - val_loss: 64.8239 - val_mae: 5.7889 - val_mse: 64.8239\n",
            "Epoch 393/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.7191 - mae: 5.3041 - mse: 64.7191 - val_loss: 60.6066 - val_mae: 5.6958 - val_mse: 60.6066\n",
            "Epoch 394/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.4548 - mae: 5.4048 - mse: 62.4548 - val_loss: 65.3301 - val_mae: 5.9395 - val_mse: 65.3301\n",
            "Epoch 395/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.8680 - mae: 5.8687 - mse: 65.8680 - val_loss: 61.3155 - val_mae: 5.7411 - val_mse: 61.3155\n",
            "Epoch 396/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.2996 - mae: 5.4488 - mse: 64.2996 - val_loss: 66.6518 - val_mae: 5.8235 - val_mse: 66.6518\n",
            "Epoch 397/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 61.6182 - mae: 5.4105 - mse: 61.6182 - val_loss: 115.3392 - val_mae: 8.1504 - val_mse: 115.3392\n",
            "Epoch 398/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.6876 - mae: 5.5304 - mse: 62.6876 - val_loss: 98.2755 - val_mae: 7.1467 - val_mse: 98.2755\n",
            "Epoch 399/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.4157 - mae: 5.4795 - mse: 63.4157 - val_loss: 95.4533 - val_mae: 6.9469 - val_mse: 95.4533\n",
            "Epoch 400/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.8625 - mae: 5.4248 - mse: 64.8625 - val_loss: 79.9961 - val_mae: 6.4057 - val_mse: 79.9961\n",
            "Epoch 401/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.2669 - mae: 5.5121 - mse: 63.2669 - val_loss: 58.4967 - val_mae: 5.6540 - val_mse: 58.4967\n",
            "Epoch 402/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.6666 - mae: 5.4444 - mse: 61.6666 - val_loss: 77.7786 - val_mae: 6.1371 - val_mse: 77.7786\n",
            "Epoch 403/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.8583 - mae: 5.5222 - mse: 63.8583 - val_loss: 64.6206 - val_mae: 6.1036 - val_mse: 64.6206\n",
            "Epoch 404/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.1976 - mae: 5.7272 - mse: 65.1976 - val_loss: 58.9724 - val_mae: 5.7603 - val_mse: 58.9724\n",
            "Epoch 405/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.2002 - mae: 5.5584 - mse: 63.2002 - val_loss: 110.4107 - val_mae: 7.9814 - val_mse: 110.4107\n",
            "Epoch 406/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 67.6130 - mae: 5.7250 - mse: 67.6130 - val_loss: 56.6096 - val_mae: 5.6729 - val_mse: 56.6095\n",
            "Epoch 407/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.0108 - mae: 5.4487 - mse: 63.0108 - val_loss: 65.5443 - val_mae: 6.3388 - val_mse: 65.5443\n",
            "Epoch 408/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.2246 - mae: 5.6183 - mse: 61.2246 - val_loss: 163.3872 - val_mae: 10.2934 - val_mse: 163.3872\n",
            "Epoch 409/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 73.1611 - mae: 6.2438 - mse: 73.1611 - val_loss: 60.6377 - val_mae: 6.0397 - val_mse: 60.6377\n",
            "Epoch 410/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.9015 - mae: 5.6167 - mse: 61.9015 - val_loss: 56.1509 - val_mae: 5.6869 - val_mse: 56.1509\n",
            "Epoch 411/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.1186 - mae: 5.5494 - mse: 63.1186 - val_loss: 59.6360 - val_mae: 5.6661 - val_mse: 59.6360\n",
            "Epoch 412/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.6164 - mae: 5.4259 - mse: 62.6164 - val_loss: 75.5933 - val_mae: 6.1619 - val_mse: 75.5933\n",
            "Epoch 413/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.0487 - mae: 5.4900 - mse: 65.0487 - val_loss: 75.6852 - val_mae: 6.1196 - val_mse: 75.6852\n",
            "Epoch 414/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.5870 - mae: 5.5352 - mse: 66.5870 - val_loss: 67.9579 - val_mae: 5.8608 - val_mse: 67.9579\n",
            "Epoch 415/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.6934 - mae: 5.4519 - mse: 64.6934 - val_loss: 60.1755 - val_mae: 5.6481 - val_mse: 60.1755\n",
            "Epoch 416/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.0829 - mae: 5.5571 - mse: 63.0829 - val_loss: 68.8633 - val_mae: 5.8647 - val_mse: 68.8633\n",
            "Epoch 417/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 66.1350 - mae: 5.5118 - mse: 66.1350 - val_loss: 72.4378 - val_mae: 6.0555 - val_mse: 72.4378\n",
            "Epoch 418/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.6693 - mae: 5.4739 - mse: 63.6693 - val_loss: 66.9459 - val_mae: 5.8822 - val_mse: 66.9459\n",
            "Epoch 419/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.3171 - mae: 5.3853 - mse: 64.3171 - val_loss: 66.5853 - val_mae: 5.8694 - val_mse: 66.5853\n",
            "Epoch 420/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.6061 - mae: 5.3992 - mse: 64.6061 - val_loss: 66.7610 - val_mae: 5.8371 - val_mse: 66.7610\n",
            "Epoch 421/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.8728 - mae: 5.3348 - mse: 62.8728 - val_loss: 65.8220 - val_mae: 6.5001 - val_mse: 65.8220\n",
            "Epoch 422/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.5521 - mae: 5.7261 - mse: 64.5521 - val_loss: 84.5844 - val_mae: 6.4008 - val_mse: 84.5844\n",
            "Epoch 423/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 64.0434 - mae: 5.4569 - mse: 64.0434 - val_loss: 63.3377 - val_mae: 5.7364 - val_mse: 63.3377\n",
            "Epoch 424/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.5237 - mae: 5.4291 - mse: 62.5237 - val_loss: 60.2291 - val_mae: 5.7514 - val_mse: 60.2291\n",
            "Epoch 425/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.7183 - mae: 5.4345 - mse: 62.7183 - val_loss: 58.1842 - val_mae: 5.6724 - val_mse: 58.1842\n",
            "Epoch 426/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.2373 - mae: 5.5205 - mse: 63.2373 - val_loss: 61.9004 - val_mae: 5.7275 - val_mse: 61.9004\n",
            "Epoch 427/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 66.6573 - mae: 5.6099 - mse: 66.6573 - val_loss: 66.5995 - val_mae: 6.4832 - val_mse: 66.5995\n",
            "Epoch 428/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 65.3080 - mae: 5.8818 - mse: 65.3080 - val_loss: 57.4375 - val_mae: 5.6789 - val_mse: 57.4375\n",
            "Epoch 429/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 61.8026 - mae: 5.4042 - mse: 61.8026 - val_loss: 66.9989 - val_mae: 5.8447 - val_mse: 66.9989\n",
            "Epoch 430/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 63.6985 - mae: 5.4836 - mse: 63.6985 - val_loss: 60.8786 - val_mae: 6.0439 - val_mse: 60.8786\n",
            "Epoch 431/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.0328 - mae: 5.6661 - mse: 62.0328 - val_loss: 68.6967 - val_mae: 5.8323 - val_mse: 68.6967\n",
            "Epoch 432/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.5686 - mae: 5.4400 - mse: 62.5686 - val_loss: 96.5218 - val_mae: 7.3123 - val_mse: 96.5218\n",
            "Epoch 433/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 66.7427 - mae: 5.8506 - mse: 66.7427 - val_loss: 57.3487 - val_mae: 5.6971 - val_mse: 57.3487\n",
            "Epoch 434/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.7485 - mae: 5.5490 - mse: 61.7485 - val_loss: 72.7317 - val_mae: 6.1263 - val_mse: 72.7317\n",
            "Epoch 435/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.7977 - mae: 5.2878 - mse: 62.7977 - val_loss: 72.0000 - val_mae: 5.9536 - val_mse: 72.0000\n",
            "Epoch 436/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 62.2548 - mae: 5.3106 - mse: 62.2548 - val_loss: 62.7445 - val_mae: 5.8529 - val_mse: 62.7445\n",
            "Epoch 437/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 62.1579 - mae: 5.4591 - mse: 62.1579 - val_loss: 82.0409 - val_mae: 7.5411 - val_mse: 82.0409\n",
            "Epoch 438/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 64.6600 - mae: 5.9050 - mse: 64.6600 - val_loss: 64.0808 - val_mae: 5.8349 - val_mse: 64.0808\n",
            "Epoch 439/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.0990 - mae: 5.3128 - mse: 62.0990 - val_loss: 73.6336 - val_mae: 5.9790 - val_mse: 73.6336\n",
            "Epoch 440/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 62.9704 - mae: 5.2959 - mse: 62.9704 - val_loss: 64.6568 - val_mae: 6.0805 - val_mse: 64.6568\n",
            "Epoch 441/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 61.4489 - mae: 5.5739 - mse: 61.4489 - val_loss: 76.2151 - val_mae: 6.2681 - val_mse: 76.2151\n",
            "Epoch 442/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 62.6932 - mae: 5.2877 - mse: 62.6932 - val_loss: 65.1985 - val_mae: 6.1821 - val_mse: 65.1985\n",
            "Epoch 443/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.6004 - mae: 5.6632 - mse: 62.6004 - val_loss: 74.3193 - val_mae: 5.9185 - val_mse: 74.3193\n",
            "Epoch 444/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.5476 - mae: 5.4241 - mse: 63.5476 - val_loss: 71.1259 - val_mae: 5.9239 - val_mse: 71.1259\n",
            "Epoch 445/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.8676 - mae: 5.4436 - mse: 62.8676 - val_loss: 62.3113 - val_mae: 6.0755 - val_mse: 62.3113\n",
            "Epoch 446/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 64.4592 - mae: 5.6246 - mse: 64.4592 - val_loss: 73.1023 - val_mae: 5.9937 - val_mse: 73.1023\n",
            "Epoch 447/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.8359 - mae: 5.3533 - mse: 62.8359 - val_loss: 67.9088 - val_mae: 5.9082 - val_mse: 67.9088\n",
            "Epoch 448/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.2595 - mae: 5.4636 - mse: 62.2595 - val_loss: 80.2960 - val_mae: 6.1535 - val_mse: 80.2960\n",
            "Epoch 449/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.1973 - mae: 5.3559 - mse: 62.1973 - val_loss: 77.0596 - val_mae: 6.0823 - val_mse: 77.0596\n",
            "Epoch 450/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.1640 - mae: 5.4037 - mse: 62.1640 - val_loss: 96.5837 - val_mae: 8.2456 - val_mse: 96.5837\n",
            "Epoch 451/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 65.4128 - mae: 5.9388 - mse: 65.4128 - val_loss: 90.2386 - val_mae: 6.2870 - val_mse: 90.2386\n",
            "Epoch 452/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.9877 - mae: 5.2460 - mse: 61.9877 - val_loss: 78.4465 - val_mae: 6.3255 - val_mse: 78.4465\n",
            "Epoch 453/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.3542 - mae: 5.5386 - mse: 62.3542 - val_loss: 86.3854 - val_mae: 6.2947 - val_mse: 86.3854\n",
            "Epoch 454/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.3584 - mae: 5.4212 - mse: 63.3584 - val_loss: 86.2511 - val_mae: 6.4202 - val_mse: 86.2511\n",
            "Epoch 455/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.9029 - mae: 5.5467 - mse: 63.9029 - val_loss: 71.6434 - val_mae: 5.9933 - val_mse: 71.6434\n",
            "Epoch 456/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.6774 - mae: 5.5016 - mse: 61.6774 - val_loss: 85.3725 - val_mae: 7.4353 - val_mse: 85.3725\n",
            "Epoch 457/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 65.6727 - mae: 5.8921 - mse: 65.6727 - val_loss: 70.4332 - val_mae: 6.2826 - val_mse: 70.4332\n",
            "Epoch 458/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.2045 - mae: 5.7136 - mse: 62.2045 - val_loss: 78.4288 - val_mae: 6.0866 - val_mse: 78.4288\n",
            "Epoch 459/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.3474 - mae: 5.2549 - mse: 62.3474 - val_loss: 74.8233 - val_mae: 5.9475 - val_mse: 74.8233\n",
            "Epoch 460/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.3983 - mae: 5.2050 - mse: 62.3983 - val_loss: 74.3627 - val_mae: 6.1325 - val_mse: 74.3627\n",
            "Epoch 461/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.4830 - mae: 5.6077 - mse: 63.4830 - val_loss: 88.3465 - val_mae: 6.1799 - val_mse: 88.3465\n",
            "Epoch 462/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.8502 - mae: 5.3529 - mse: 64.8502 - val_loss: 73.9870 - val_mae: 6.2799 - val_mse: 73.9870\n",
            "Epoch 463/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.9819 - mae: 5.6738 - mse: 63.9819 - val_loss: 72.6178 - val_mae: 6.0119 - val_mse: 72.6178\n",
            "Epoch 464/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.7271 - mae: 5.5006 - mse: 61.7271 - val_loss: 79.8616 - val_mae: 6.0758 - val_mse: 79.8616\n",
            "Epoch 465/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 62.7714 - mae: 5.3455 - mse: 62.7714 - val_loss: 70.1418 - val_mae: 6.4169 - val_mse: 70.1418\n",
            "Epoch 466/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.3685 - mae: 5.8085 - mse: 65.3685 - val_loss: 92.1885 - val_mae: 8.0709 - val_mse: 92.1885\n",
            "Epoch 467/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 67.5860 - mae: 5.9720 - mse: 67.5860 - val_loss: 75.3666 - val_mae: 6.3156 - val_mse: 75.3666\n",
            "Epoch 468/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 65.6201 - mae: 5.6875 - mse: 65.6201 - val_loss: 73.8804 - val_mae: 6.1396 - val_mse: 73.8804\n",
            "Epoch 469/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.9649 - mae: 5.5595 - mse: 62.9649 - val_loss: 86.2888 - val_mae: 6.3225 - val_mse: 86.2888\n",
            "Epoch 470/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.4647 - mae: 5.5212 - mse: 63.4647 - val_loss: 157.9002 - val_mae: 8.2722 - val_mse: 157.9002\n",
            "Epoch 471/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.1129 - mae: 5.6266 - mse: 66.1129 - val_loss: 135.2140 - val_mae: 6.8446 - val_mse: 135.2140\n",
            "Epoch 472/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.8747 - mae: 5.3885 - mse: 64.8747 - val_loss: 153.3447 - val_mae: 7.4762 - val_mse: 153.3447\n",
            "Epoch 473/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.8655 - mae: 5.4944 - mse: 62.8655 - val_loss: 161.1053 - val_mae: 8.0884 - val_mse: 161.1053\n",
            "Epoch 474/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.4074 - mae: 5.6488 - mse: 64.4074 - val_loss: 111.2085 - val_mae: 6.3150 - val_mse: 111.2085\n",
            "Epoch 475/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.4857 - mae: 5.4582 - mse: 62.4857 - val_loss: 146.2191 - val_mae: 8.4724 - val_mse: 146.2191\n",
            "Epoch 476/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 71.7990 - mae: 6.0197 - mse: 71.7990 - val_loss: 108.8095 - val_mae: 7.3777 - val_mse: 108.8095\n",
            "Epoch 477/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 67.5105 - mae: 6.0144 - mse: 67.5105 - val_loss: 89.9934 - val_mae: 6.2020 - val_mse: 89.9934\n",
            "Epoch 478/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.9254 - mae: 5.5297 - mse: 62.9254 - val_loss: 87.9028 - val_mae: 6.4703 - val_mse: 87.9028\n",
            "Epoch 479/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.8085 - mae: 5.6237 - mse: 63.8085 - val_loss: 97.0581 - val_mae: 6.2607 - val_mse: 97.0581\n",
            "Epoch 480/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.5383 - mae: 5.2987 - mse: 62.5383 - val_loss: 114.6431 - val_mae: 7.4311 - val_mse: 114.6431\n",
            "Epoch 481/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 68.7620 - mae: 6.1250 - mse: 68.7620 - val_loss: 99.8678 - val_mae: 6.2497 - val_mse: 99.8678\n",
            "Epoch 482/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.7875 - mae: 5.4172 - mse: 62.7875 - val_loss: 106.6277 - val_mae: 6.9391 - val_mse: 106.6277\n",
            "Epoch 483/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.1773 - mae: 5.7519 - mse: 64.1773 - val_loss: 58.9804 - val_mae: 5.6917 - val_mse: 58.9804\n",
            "Epoch 484/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 60.8382 - mae: 5.3940 - mse: 60.8382 - val_loss: 106.2721 - val_mae: 7.6445 - val_mse: 106.2721\n",
            "Epoch 485/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 67.8016 - mae: 5.8377 - mse: 67.8016 - val_loss: 58.5438 - val_mae: 5.9410 - val_mse: 58.5438\n",
            "Epoch 486/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.0209 - mae: 5.6963 - mse: 64.0209 - val_loss: 56.4885 - val_mae: 5.7530 - val_mse: 56.4885\n",
            "Epoch 487/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 63.8225 - mae: 5.5599 - mse: 63.8225 - val_loss: 69.3884 - val_mae: 5.8449 - val_mse: 69.3884\n",
            "Epoch 488/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.6623 - mae: 5.3293 - mse: 61.6623 - val_loss: 63.6575 - val_mae: 5.7262 - val_mse: 63.6575\n",
            "Epoch 489/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.2421 - mae: 5.4086 - mse: 61.2421 - val_loss: 57.5914 - val_mae: 5.8212 - val_mse: 57.5914\n",
            "Epoch 490/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.3073 - mae: 5.6075 - mse: 61.3073 - val_loss: 64.4503 - val_mae: 5.7983 - val_mse: 64.4503\n",
            "Epoch 491/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.2738 - mae: 5.2759 - mse: 61.2738 - val_loss: 63.4102 - val_mae: 5.7987 - val_mse: 63.4102\n",
            "Epoch 492/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.8591 - mae: 5.4680 - mse: 61.8591 - val_loss: 72.5872 - val_mae: 6.0619 - val_mse: 72.5872\n",
            "Epoch 493/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.2629 - mae: 5.3121 - mse: 63.2629 - val_loss: 68.4081 - val_mae: 5.8975 - val_mse: 68.4081\n",
            "Epoch 494/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.0772 - mae: 5.2445 - mse: 62.0772 - val_loss: 58.7123 - val_mae: 5.8367 - val_mse: 58.7123\n",
            "Epoch 495/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.7790 - mae: 5.3868 - mse: 61.7790 - val_loss: 60.5602 - val_mae: 5.7376 - val_mse: 60.5602\n",
            "Epoch 496/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.3736 - mae: 5.4408 - mse: 62.3736 - val_loss: 57.4053 - val_mae: 5.6316 - val_mse: 57.4053\n",
            "Epoch 497/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.4300 - mae: 5.5189 - mse: 63.4300 - val_loss: 69.7430 - val_mae: 6.3033 - val_mse: 69.7430\n",
            "Epoch 498/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.5515 - mae: 5.6710 - mse: 63.5515 - val_loss: 58.4417 - val_mae: 5.8686 - val_mse: 58.4417\n",
            "Epoch 499/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.2120 - mae: 5.4752 - mse: 61.2120 - val_loss: 59.0400 - val_mae: 5.7514 - val_mse: 59.0400\n",
            "Epoch 500/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.6351 - mae: 5.3217 - mse: 61.6351 - val_loss: 58.3940 - val_mae: 5.6654 - val_mse: 58.3940\n",
            "Epoch 501/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.7480 - mae: 5.2971 - mse: 60.7480 - val_loss: 58.6195 - val_mae: 5.6532 - val_mse: 58.6195\n",
            "Epoch 502/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 61.1068 - mae: 5.3820 - mse: 61.1068 - val_loss: 61.3628 - val_mae: 6.2740 - val_mse: 61.3628\n",
            "Epoch 503/600\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 65.7010 - mae: 5.6847 - mse: 65.7010 - val_loss: 56.8770 - val_mae: 5.7180 - val_mse: 56.8770\n",
            "Epoch 504/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 59.9264 - mae: 5.3563 - mse: 59.9264 - val_loss: 75.3589 - val_mae: 6.2696 - val_mse: 75.3589\n",
            "Epoch 505/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.9105 - mae: 5.4351 - mse: 64.9105 - val_loss: 67.1139 - val_mae: 5.7944 - val_mse: 67.1139\n",
            "Epoch 506/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.0281 - mae: 5.1027 - mse: 61.0281 - val_loss: 66.6809 - val_mae: 6.1645 - val_mse: 66.6809\n",
            "Epoch 507/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.0233 - mae: 5.6208 - mse: 63.0233 - val_loss: 60.4086 - val_mae: 5.6857 - val_mse: 60.4086\n",
            "Epoch 508/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.1871 - mae: 5.2497 - mse: 62.1871 - val_loss: 59.2951 - val_mae: 5.6660 - val_mse: 59.2951\n",
            "Epoch 509/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.3456 - mae: 5.3671 - mse: 61.3456 - val_loss: 64.7466 - val_mae: 5.9920 - val_mse: 64.7466\n",
            "Epoch 510/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.6393 - mae: 5.3314 - mse: 61.6393 - val_loss: 63.1403 - val_mae: 5.7600 - val_mse: 63.1403\n",
            "Epoch 511/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.7801 - mae: 5.2090 - mse: 62.7801 - val_loss: 77.8920 - val_mae: 6.3390 - val_mse: 77.8920\n",
            "Epoch 512/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.0261 - mae: 5.3179 - mse: 66.0261 - val_loss: 136.8228 - val_mae: 9.0607 - val_mse: 136.8228\n",
            "Epoch 513/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 68.6697 - mae: 5.8277 - mse: 68.6697 - val_loss: 58.1136 - val_mae: 5.9043 - val_mse: 58.1136\n",
            "Epoch 514/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.7730 - mae: 5.6519 - mse: 64.7730 - val_loss: 60.6926 - val_mae: 6.0198 - val_mse: 60.6926\n",
            "Epoch 515/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 64.0206 - mae: 5.7073 - mse: 64.0206 - val_loss: 55.9053 - val_mae: 5.7318 - val_mse: 55.9053\n",
            "Epoch 516/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.6792 - mae: 5.5455 - mse: 62.6792 - val_loss: 57.2210 - val_mae: 5.6597 - val_mse: 57.2210\n",
            "Epoch 517/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.1997 - mae: 5.3529 - mse: 61.1997 - val_loss: 79.0470 - val_mae: 6.5168 - val_mse: 79.0470\n",
            "Epoch 518/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.8224 - mae: 5.4700 - mse: 62.8224 - val_loss: 57.1995 - val_mae: 5.6823 - val_mse: 57.1995\n",
            "Epoch 519/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.0946 - mae: 5.5178 - mse: 61.0946 - val_loss: 60.1504 - val_mae: 6.0072 - val_mse: 60.1504\n",
            "Epoch 520/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 66.1322 - mae: 5.8921 - mse: 66.1322 - val_loss: 66.5282 - val_mae: 5.8286 - val_mse: 66.5282\n",
            "Epoch 521/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.9419 - mae: 5.3442 - mse: 61.9419 - val_loss: 56.4526 - val_mae: 5.7750 - val_mse: 56.4526\n",
            "Epoch 522/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.9604 - mae: 5.4894 - mse: 61.9604 - val_loss: 66.3217 - val_mae: 5.7535 - val_mse: 66.3217\n",
            "Epoch 523/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.0332 - mae: 5.3689 - mse: 62.0332 - val_loss: 152.4478 - val_mae: 9.8263 - val_mse: 152.4478\n",
            "Epoch 524/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 70.0229 - mae: 6.1962 - mse: 70.0229 - val_loss: 68.8184 - val_mae: 5.9221 - val_mse: 68.8184\n",
            "Epoch 525/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.0741 - mae: 5.2788 - mse: 63.0741 - val_loss: 64.0752 - val_mae: 5.6919 - val_mse: 64.0752\n",
            "Epoch 526/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.5415 - mae: 5.2867 - mse: 60.5415 - val_loss: 70.1777 - val_mae: 5.8408 - val_mse: 70.1777\n",
            "Epoch 527/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.9328 - mae: 5.3358 - mse: 61.9328 - val_loss: 65.2760 - val_mae: 5.7422 - val_mse: 65.2760\n",
            "Epoch 528/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.7258 - mae: 5.3493 - mse: 62.7258 - val_loss: 92.5203 - val_mae: 8.2318 - val_mse: 92.5203\n",
            "Epoch 529/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.8632 - mae: 5.8221 - mse: 65.8632 - val_loss: 64.5177 - val_mae: 5.8391 - val_mse: 64.5177\n",
            "Epoch 530/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.7503 - mae: 5.2727 - mse: 62.7503 - val_loss: 68.0048 - val_mae: 5.8573 - val_mse: 68.0048\n",
            "Epoch 531/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.3732 - mae: 5.2333 - mse: 62.3732 - val_loss: 59.4395 - val_mae: 5.7525 - val_mse: 59.4395\n",
            "Epoch 532/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.3112 - mae: 5.3890 - mse: 61.3112 - val_loss: 67.5068 - val_mae: 5.8546 - val_mse: 67.5068\n",
            "Epoch 533/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.5686 - mae: 5.2717 - mse: 61.5686 - val_loss: 67.2515 - val_mae: 6.0747 - val_mse: 67.2515\n",
            "Epoch 534/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.4813 - mae: 5.3576 - mse: 62.4813 - val_loss: 65.8256 - val_mae: 6.5903 - val_mse: 65.8256\n",
            "Epoch 535/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.4002 - mae: 5.8721 - mse: 65.4002 - val_loss: 61.1008 - val_mae: 6.0178 - val_mse: 61.1008\n",
            "Epoch 536/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.7848 - mae: 5.5476 - mse: 62.7848 - val_loss: 65.1446 - val_mae: 5.8712 - val_mse: 65.1446\n",
            "Epoch 537/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.3148 - mae: 5.6103 - mse: 63.3148 - val_loss: 71.9470 - val_mae: 6.0178 - val_mse: 71.9470\n",
            "Epoch 538/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.9520 - mae: 5.1988 - mse: 61.9520 - val_loss: 101.7170 - val_mae: 7.7737 - val_mse: 101.7170\n",
            "Epoch 539/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 66.5261 - mae: 5.9229 - mse: 66.5261 - val_loss: 61.0290 - val_mae: 5.8826 - val_mse: 61.0290\n",
            "Epoch 540/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.2241 - mae: 5.4101 - mse: 60.2241 - val_loss: 66.1423 - val_mae: 5.8784 - val_mse: 66.1423\n",
            "Epoch 541/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.5703 - mae: 5.3037 - mse: 62.5703 - val_loss: 66.4382 - val_mae: 6.0941 - val_mse: 66.4382\n",
            "Epoch 542/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 61.7985 - mae: 5.3231 - mse: 61.7985 - val_loss: 62.9644 - val_mae: 5.8079 - val_mse: 62.9644\n",
            "Epoch 543/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.2228 - mae: 5.5144 - mse: 61.2228 - val_loss: 62.9940 - val_mae: 5.8657 - val_mse: 62.9940\n",
            "Epoch 544/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.7982 - mae: 5.5288 - mse: 61.7982 - val_loss: 76.9922 - val_mae: 6.3080 - val_mse: 76.9922\n",
            "Epoch 545/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.1022 - mae: 5.0913 - mse: 62.1022 - val_loss: 63.2827 - val_mae: 6.3423 - val_mse: 63.2827\n",
            "Epoch 546/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.4845 - mae: 5.7784 - mse: 63.4845 - val_loss: 61.6185 - val_mae: 5.6933 - val_mse: 61.6185\n",
            "Epoch 547/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.2057 - mae: 5.3947 - mse: 62.2057 - val_loss: 56.1205 - val_mae: 5.6436 - val_mse: 56.1205\n",
            "Epoch 548/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 63.4107 - mae: 5.6021 - mse: 63.4107 - val_loss: 55.7403 - val_mae: 5.8374 - val_mse: 55.7403\n",
            "Epoch 549/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.2957 - mae: 5.5906 - mse: 62.2957 - val_loss: 75.6003 - val_mae: 6.1306 - val_mse: 75.6003\n",
            "Epoch 550/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 62.6968 - mae: 5.4869 - mse: 62.6968 - val_loss: 55.9575 - val_mae: 5.8943 - val_mse: 55.9575\n",
            "Epoch 551/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.3960 - mae: 5.7424 - mse: 64.3960 - val_loss: 67.5339 - val_mae: 6.1938 - val_mse: 67.5339\n",
            "Epoch 552/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.5579 - mae: 5.6892 - mse: 62.5579 - val_loss: 62.8414 - val_mae: 5.7320 - val_mse: 62.8414\n",
            "Epoch 553/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.7849 - mae: 5.2654 - mse: 60.7849 - val_loss: 72.6489 - val_mae: 6.6976 - val_mse: 72.6489\n",
            "Epoch 554/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.2770 - mae: 5.5982 - mse: 62.2770 - val_loss: 66.5488 - val_mae: 6.4793 - val_mse: 66.5488\n",
            "Epoch 555/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.7090 - mae: 5.8359 - mse: 65.7090 - val_loss: 62.7280 - val_mae: 5.6793 - val_mse: 62.7280\n",
            "Epoch 556/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 61.4498 - mae: 5.1931 - mse: 61.4498 - val_loss: 57.9152 - val_mae: 6.0486 - val_mse: 57.9152\n",
            "Epoch 557/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.2067 - mae: 5.6010 - mse: 62.2067 - val_loss: 59.8710 - val_mae: 5.6370 - val_mse: 59.8710\n",
            "Epoch 558/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 60.2698 - mae: 5.3177 - mse: 60.2698 - val_loss: 63.2155 - val_mae: 5.6768 - val_mse: 63.2155\n",
            "Epoch 559/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 64.0843 - mae: 5.4088 - mse: 64.0843 - val_loss: 58.9173 - val_mae: 5.6235 - val_mse: 58.9173\n",
            "Epoch 560/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 60.6012 - mae: 5.3064 - mse: 60.6012 - val_loss: 69.5005 - val_mae: 5.9117 - val_mse: 69.5005\n",
            "Epoch 561/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.8404 - mae: 5.0763 - mse: 60.8404 - val_loss: 58.4399 - val_mae: 5.6988 - val_mse: 58.4399\n",
            "Epoch 562/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 60.6888 - mae: 5.2151 - mse: 60.6888 - val_loss: 63.5521 - val_mae: 5.7241 - val_mse: 63.5521\n",
            "Epoch 563/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 61.0400 - mae: 5.2876 - mse: 61.0400 - val_loss: 58.2348 - val_mae: 5.6748 - val_mse: 58.2348\n",
            "Epoch 564/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 62.1784 - mae: 5.2466 - mse: 62.1784 - val_loss: 65.3857 - val_mae: 5.8415 - val_mse: 65.3857\n",
            "Epoch 565/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.4743 - mae: 5.1891 - mse: 62.4743 - val_loss: 1369.9191 - val_mae: 35.6821 - val_mse: 1369.9191\n",
            "Epoch 566/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 61.0564 - mae: 5.4454 - mse: 61.0564 - val_loss: 299.2602 - val_mae: 15.4133 - val_mse: 299.2602\n",
            "Epoch 567/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.0736 - mae: 5.5225 - mse: 62.0736 - val_loss: 237.6572 - val_mae: 13.0482 - val_mse: 237.6572\n",
            "Epoch 568/600\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 64.6880 - mae: 5.5206 - mse: 64.6880 - val_loss: 239.5750 - val_mae: 13.1463 - val_mse: 239.5750\n",
            "Epoch 569/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 63.8582 - mae: 5.2125 - mse: 63.8582 - val_loss: 98.6908 - val_mae: 7.2935 - val_mse: 98.6908\n",
            "Epoch 570/600\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 60.4343 - mae: 5.3629 - mse: 60.4343 - val_loss: 168.6773 - val_mae: 10.0953 - val_mse: 168.6773\n",
            "Epoch 571/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 68.1622 - mae: 5.7448 - mse: 68.1622 - val_loss: 98.8621 - val_mae: 7.1991 - val_mse: 98.8621\n",
            "Epoch 572/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.8778 - mae: 5.3876 - mse: 62.8778 - val_loss: 80.6847 - val_mae: 6.3123 - val_mse: 80.6847\n",
            "Epoch 573/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.5051 - mae: 5.4267 - mse: 62.5051 - val_loss: 120.1621 - val_mae: 8.2687 - val_mse: 120.1621\n",
            "Epoch 574/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 65.7335 - mae: 5.8795 - mse: 65.7335 - val_loss: 68.7850 - val_mae: 5.8842 - val_mse: 68.7850\n",
            "Epoch 575/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.1726 - mae: 5.6984 - mse: 64.1726 - val_loss: 113.1765 - val_mae: 7.7310 - val_mse: 113.1765\n",
            "Epoch 576/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 64.0550 - mae: 5.5975 - mse: 64.0550 - val_loss: 71.5506 - val_mae: 6.0068 - val_mse: 71.5506\n",
            "Epoch 577/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 62.0830 - mae: 5.2580 - mse: 62.0830 - val_loss: 181.6100 - val_mae: 10.4328 - val_mse: 181.6100\n",
            "Epoch 578/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 72.3020 - mae: 6.0227 - mse: 72.3020 - val_loss: 73.7086 - val_mae: 6.0326 - val_mse: 73.7086\n",
            "Epoch 579/600\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 61.8774 - mae: 5.3578 - mse: 61.8774 - val_loss: 73.4753 - val_mae: 6.0017 - val_mse: 73.4753\n",
            "Epoch 580/600\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 63.7302 - mae: 5.3858 - mse: 63.7302 - val_loss: 60.2353 - val_mae: 5.7031 - val_mse: 60.2353\n",
            "Epoch 581/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 63.2703 - mae: 5.4550 - mse: 63.2703 - val_loss: 71.5734 - val_mae: 5.9826 - val_mse: 71.5734\n",
            "Epoch 582/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.8825 - mae: 5.2681 - mse: 61.8825 - val_loss: 67.2503 - val_mae: 5.7888 - val_mse: 67.2503\n",
            "Epoch 583/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 60.5807 - mae: 5.1945 - mse: 60.5807 - val_loss: 58.6270 - val_mae: 5.7510 - val_mse: 58.6270\n",
            "Epoch 584/600\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 61.3980 - mae: 5.4693 - mse: 61.3980 - val_loss: 65.2901 - val_mae: 5.7295 - val_mse: 65.2901\n",
            "Epoch 585/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.5398 - mae: 5.5416 - mse: 61.5398 - val_loss: 70.3137 - val_mae: 5.9658 - val_mse: 70.3137\n",
            "Epoch 586/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 63.6907 - mae: 5.3186 - mse: 63.6907 - val_loss: 59.0464 - val_mae: 5.6869 - val_mse: 59.0464\n",
            "Epoch 587/600\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 60.4515 - mae: 5.3914 - mse: 60.4515 - val_loss: 74.7974 - val_mae: 6.4328 - val_mse: 74.7974\n",
            "Epoch 588/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 62.2196 - mae: 5.6486 - mse: 62.2196 - val_loss: 67.0715 - val_mae: 5.8508 - val_mse: 67.0715\n",
            "Epoch 589/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 62.0063 - mae: 5.1746 - mse: 62.0063 - val_loss: 66.0281 - val_mae: 5.9844 - val_mse: 66.0281\n",
            "Epoch 590/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.7494 - mae: 5.4954 - mse: 61.7494 - val_loss: 65.9885 - val_mae: 5.7891 - val_mse: 65.9885\n",
            "Epoch 591/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 62.5327 - mae: 5.2667 - mse: 62.5327 - val_loss: 78.3470 - val_mae: 7.1873 - val_mse: 78.3470\n",
            "Epoch 592/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.8306 - mae: 5.6368 - mse: 63.8306 - val_loss: 66.1593 - val_mae: 5.7834 - val_mse: 66.1593\n",
            "Epoch 593/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 60.6095 - mae: 5.3201 - mse: 60.6095 - val_loss: 62.0636 - val_mae: 5.7503 - val_mse: 62.0636\n",
            "Epoch 594/600\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 61.8251 - mae: 5.3308 - mse: 61.8251 - val_loss: 71.3407 - val_mae: 6.0853 - val_mse: 71.3407\n",
            "Epoch 595/600\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 62.6307 - mae: 5.3046 - mse: 62.6307 - val_loss: 68.1972 - val_mae: 5.8804 - val_mse: 68.1972\n",
            "Epoch 596/600\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 60.8628 - mae: 5.3586 - mse: 60.8628 - val_loss: 59.7037 - val_mae: 5.7965 - val_mse: 59.7037\n",
            "Epoch 597/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 61.9509 - mae: 5.4125 - mse: 61.9509 - val_loss: 65.4946 - val_mae: 5.8931 - val_mse: 65.4946\n",
            "Epoch 598/600\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 61.1799 - mae: 5.4060 - mse: 61.1799 - val_loss: 76.6413 - val_mae: 6.0431 - val_mse: 76.6413\n",
            "Epoch 599/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 61.6986 - mae: 5.3661 - mse: 61.6986 - val_loss: 79.3357 - val_mae: 6.3100 - val_mse: 79.3357\n",
            "Epoch 600/600\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 63.4773 - mae: 5.2539 - mse: 63.4773 - val_loss: 78.9175 - val_mae: 6.3962 - val_mse: 78.9175\n",
            "loss — -> 78.91754150390625\n",
            "mae — -> 6.396216869354248\n",
            "mse — -> 78.91754150390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(score)):\n",
        "    print(f'{model.metrics_names[i]} — -> {score[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e640lfLffHi7",
        "outputId": "9961e5bb-ac15-4437-afad-dd4c2a60eac3"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss — -> 84.02705383300781\n",
            "mae — -> 6.521311283111572\n",
            "mse — -> 84.02705383300781\n",
            "accuracy — -> 0.0\n",
            "root_mean_squared_error — -> 0.0\n",
            "root_mean_squared_error — -> 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"bh1\",)\n",
        "# l1\n",
        "model.add(Dense( 26, activation='relu', input_shape=(13,)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# l2\n",
        "model.add(Dense(26, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# out\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=RMSprop(),\n",
        "    metrics=['mae','mse']\n",
        "    )\n",
        "\n",
        "learning_rate = 0.1\n",
        "batch_size = 50\n",
        "display_step = 5\n",
        "epochs = 900\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n",
        "# Model Eval\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "for i in range(len(score)):\n",
        "    print(f'{model.metrics_names[i]} — -> {score[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X6QXIw4lfFq",
        "outputId": "f357c84d-bb4a-4436-db8e-26466082fc39"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bh1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_169 (Dense)           (None, 26)                364       \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 26)               104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 26)                702       \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 26)               104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 1)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301\n",
            "Trainable params: 1,197\n",
            "Non-trainable params: 104\n",
            "_________________________________________________________________\n",
            "Epoch 1/900\n",
            "9/9 [==============================] - 2s 47ms/step - loss: 571.5356 - mae: 22.3377 - mse: 571.5356 - val_loss: 1174.1783 - val_mae: 33.3230 - val_mse: 1174.1783\n",
            "Epoch 2/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 561.6064 - mae: 22.2410 - mse: 561.6064 - val_loss: 963.0378 - val_mae: 29.9940 - val_mse: 963.0378\n",
            "Epoch 3/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 556.6957 - mae: 22.1650 - mse: 556.6957 - val_loss: 874.7836 - val_mae: 28.4362 - val_mse: 874.7836\n",
            "Epoch 4/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 550.6758 - mae: 22.0937 - mse: 550.6758 - val_loss: 799.8735 - val_mae: 27.0943 - val_mse: 799.8735\n",
            "Epoch 5/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 545.3541 - mae: 22.0174 - mse: 545.3541 - val_loss: 761.3096 - val_mae: 26.3806 - val_mse: 761.3096\n",
            "Epoch 6/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 540.8175 - mae: 21.9355 - mse: 540.8174 - val_loss: 738.5303 - val_mae: 25.9653 - val_mse: 738.5303\n",
            "Epoch 7/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 536.1230 - mae: 21.8517 - mse: 536.1230 - val_loss: 720.9819 - val_mae: 25.6510 - val_mse: 720.9819\n",
            "Epoch 8/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 531.6353 - mae: 21.7660 - mse: 531.6353 - val_loss: 689.6827 - val_mae: 25.0292 - val_mse: 689.6827\n",
            "Epoch 9/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 524.8092 - mae: 21.6754 - mse: 524.8092 - val_loss: 670.6743 - val_mae: 24.6506 - val_mse: 670.6743\n",
            "Epoch 10/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 519.1369 - mae: 21.5748 - mse: 519.1369 - val_loss: 656.9949 - val_mae: 24.3757 - val_mse: 656.9949\n",
            "Epoch 11/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 513.9017 - mae: 21.4759 - mse: 513.9017 - val_loss: 635.6459 - val_mae: 23.9735 - val_mse: 635.6459\n",
            "Epoch 12/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 507.7283 - mae: 21.3701 - mse: 507.7283 - val_loss: 623.9678 - val_mae: 23.7458 - val_mse: 623.9678\n",
            "Epoch 13/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 501.9783 - mae: 21.2586 - mse: 501.9783 - val_loss: 585.3567 - val_mae: 22.9263 - val_mse: 585.3567\n",
            "Epoch 14/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 496.1995 - mae: 21.1460 - mse: 496.1995 - val_loss: 595.7314 - val_mae: 23.1633 - val_mse: 595.7314\n",
            "Epoch 15/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 488.6156 - mae: 21.0288 - mse: 488.6156 - val_loss: 598.7358 - val_mae: 23.2849 - val_mse: 598.7358\n",
            "Epoch 16/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 481.9838 - mae: 20.9026 - mse: 481.9838 - val_loss: 563.2519 - val_mae: 22.5251 - val_mse: 563.2519\n",
            "Epoch 17/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 474.7399 - mae: 20.7789 - mse: 474.7399 - val_loss: 561.8360 - val_mae: 22.5175 - val_mse: 561.8361\n",
            "Epoch 18/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 468.7323 - mae: 20.6490 - mse: 468.7323 - val_loss: 554.0069 - val_mae: 22.3683 - val_mse: 554.0069\n",
            "Epoch 19/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 461.1939 - mae: 20.5162 - mse: 461.1938 - val_loss: 549.9261 - val_mae: 22.3031 - val_mse: 549.9261\n",
            "Epoch 20/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 454.1405 - mae: 20.3744 - mse: 454.1405 - val_loss: 564.3929 - val_mae: 22.6862 - val_mse: 564.3929\n",
            "Epoch 21/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 446.3716 - mae: 20.2281 - mse: 446.3716 - val_loss: 510.7682 - val_mae: 21.5018 - val_mse: 510.7682\n",
            "Epoch 22/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 438.3993 - mae: 20.0849 - mse: 438.3993 - val_loss: 519.8756 - val_mae: 21.7385 - val_mse: 519.8756\n",
            "Epoch 23/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 431.0955 - mae: 19.9357 - mse: 431.0955 - val_loss: 491.7491 - val_mae: 21.0738 - val_mse: 491.7491\n",
            "Epoch 24/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 424.0946 - mae: 19.7804 - mse: 424.0946 - val_loss: 523.2834 - val_mae: 21.8728 - val_mse: 523.2834\n",
            "Epoch 25/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 415.0276 - mae: 19.6197 - mse: 415.0276 - val_loss: 474.4565 - val_mae: 20.7419 - val_mse: 474.4565\n",
            "Epoch 26/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 407.8213 - mae: 19.4531 - mse: 407.8213 - val_loss: 468.5564 - val_mae: 20.6189 - val_mse: 468.5564\n",
            "Epoch 27/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 403.6156 - mae: 19.2913 - mse: 403.6156 - val_loss: 427.8262 - val_mae: 19.6642 - val_mse: 427.8262\n",
            "Epoch 28/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 393.8314 - mae: 19.1136 - mse: 393.8314 - val_loss: 449.9555 - val_mae: 20.2799 - val_mse: 449.9555\n",
            "Epoch 29/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 385.6711 - mae: 18.9389 - mse: 385.6711 - val_loss: 433.4923 - val_mae: 19.9092 - val_mse: 433.4923\n",
            "Epoch 30/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 376.7387 - mae: 18.7543 - mse: 376.7387 - val_loss: 449.2407 - val_mae: 20.3187 - val_mse: 449.2407\n",
            "Epoch 31/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 371.4604 - mae: 18.5763 - mse: 371.4604 - val_loss: 442.6460 - val_mae: 20.1814 - val_mse: 442.6460\n",
            "Epoch 32/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 364.3253 - mae: 18.3825 - mse: 364.3253 - val_loss: 480.5192 - val_mae: 21.1140 - val_mse: 480.5192\n",
            "Epoch 33/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 359.3209 - mae: 18.1828 - mse: 359.3209 - val_loss: 415.9030 - val_mae: 19.5128 - val_mse: 415.9030\n",
            "Epoch 34/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 347.9834 - mae: 18.0023 - mse: 347.9834 - val_loss: 418.3309 - val_mae: 19.5568 - val_mse: 418.3309\n",
            "Epoch 35/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 339.7288 - mae: 17.8075 - mse: 339.7288 - val_loss: 398.7869 - val_mae: 19.0312 - val_mse: 398.7869\n",
            "Epoch 36/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 330.9832 - mae: 17.5993 - mse: 330.9832 - val_loss: 378.3867 - val_mae: 18.5746 - val_mse: 378.3867\n",
            "Epoch 37/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 323.6161 - mae: 17.3887 - mse: 323.6161 - val_loss: 397.7076 - val_mae: 19.1955 - val_mse: 397.7076\n",
            "Epoch 38/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 318.4199 - mae: 17.1815 - mse: 318.4199 - val_loss: 326.1068 - val_mae: 17.2015 - val_mse: 326.1068\n",
            "Epoch 39/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 308.0546 - mae: 16.9745 - mse: 308.0546 - val_loss: 399.4837 - val_mae: 19.2325 - val_mse: 399.4837\n",
            "Epoch 40/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 301.6494 - mae: 16.7441 - mse: 301.6494 - val_loss: 362.6433 - val_mae: 18.2313 - val_mse: 362.6433\n",
            "Epoch 41/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 292.8040 - mae: 16.5184 - mse: 292.8040 - val_loss: 351.8377 - val_mae: 18.0180 - val_mse: 351.8377\n",
            "Epoch 42/900\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 283.4037 - mae: 16.2886 - mse: 283.4037 - val_loss: 310.5526 - val_mae: 16.8258 - val_mse: 310.5526\n",
            "Epoch 43/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 277.8351 - mae: 16.0674 - mse: 277.8351 - val_loss: 267.9112 - val_mae: 15.5639 - val_mse: 267.9112\n",
            "Epoch 44/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 271.3143 - mae: 15.8245 - mse: 271.3143 - val_loss: 289.5052 - val_mae: 16.2269 - val_mse: 289.5052\n",
            "Epoch 45/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 262.0963 - mae: 15.5737 - mse: 262.0963 - val_loss: 287.8637 - val_mae: 16.1340 - val_mse: 287.8637\n",
            "Epoch 46/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 254.1511 - mae: 15.3403 - mse: 254.1511 - val_loss: 307.5380 - val_mae: 16.8688 - val_mse: 307.5380\n",
            "Epoch 47/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 245.7071 - mae: 15.0986 - mse: 245.7071 - val_loss: 315.9817 - val_mae: 17.1166 - val_mse: 315.9817\n",
            "Epoch 48/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 239.8591 - mae: 14.8547 - mse: 239.8591 - val_loss: 312.7654 - val_mae: 17.0238 - val_mse: 312.7654\n",
            "Epoch 49/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 228.7680 - mae: 14.5884 - mse: 228.7680 - val_loss: 302.6497 - val_mae: 16.6768 - val_mse: 302.6497\n",
            "Epoch 50/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 222.8850 - mae: 14.3318 - mse: 222.8850 - val_loss: 229.3423 - val_mae: 13.7355 - val_mse: 229.3423\n",
            "Epoch 51/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 217.1934 - mae: 14.0782 - mse: 217.1934 - val_loss: 206.1436 - val_mae: 13.5805 - val_mse: 206.1436\n",
            "Epoch 52/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 206.9266 - mae: 13.8128 - mse: 206.9266 - val_loss: 260.8514 - val_mae: 15.4630 - val_mse: 260.8514\n",
            "Epoch 53/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 202.3475 - mae: 13.5357 - mse: 202.3475 - val_loss: 280.5356 - val_mae: 16.0866 - val_mse: 280.5356\n",
            "Epoch 54/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 191.7470 - mae: 13.2575 - mse: 191.7470 - val_loss: 210.7164 - val_mae: 13.6888 - val_mse: 210.7164\n",
            "Epoch 55/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 185.6042 - mae: 12.9913 - mse: 185.6042 - val_loss: 225.4755 - val_mae: 14.2226 - val_mse: 225.4755\n",
            "Epoch 56/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 180.8239 - mae: 12.7005 - mse: 180.8239 - val_loss: 248.6830 - val_mae: 14.9516 - val_mse: 248.6830\n",
            "Epoch 57/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 172.0470 - mae: 12.4286 - mse: 172.0470 - val_loss: 270.8143 - val_mae: 15.6971 - val_mse: 270.8143\n",
            "Epoch 58/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 164.8617 - mae: 12.1749 - mse: 164.8617 - val_loss: 240.6188 - val_mae: 14.6277 - val_mse: 240.6188\n",
            "Epoch 59/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 157.3079 - mae: 11.8629 - mse: 157.3079 - val_loss: 173.7509 - val_mae: 12.1458 - val_mse: 173.7509\n",
            "Epoch 60/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 150.5240 - mae: 11.5825 - mse: 150.5240 - val_loss: 191.2617 - val_mae: 12.9419 - val_mse: 191.2617\n",
            "Epoch 61/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 143.5629 - mae: 11.2637 - mse: 143.5629 - val_loss: 205.4838 - val_mae: 13.5367 - val_mse: 205.4838\n",
            "Epoch 62/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 139.5909 - mae: 10.9599 - mse: 139.5909 - val_loss: 156.1995 - val_mae: 11.5101 - val_mse: 156.1995\n",
            "Epoch 63/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 129.5598 - mae: 10.6902 - mse: 129.5598 - val_loss: 124.1765 - val_mae: 10.1695 - val_mse: 124.1765\n",
            "Epoch 64/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 124.0382 - mae: 10.3684 - mse: 124.0382 - val_loss: 126.0397 - val_mae: 10.3652 - val_mse: 126.0397\n",
            "Epoch 65/900\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 117.7243 - mae: 10.0824 - mse: 117.7243 - val_loss: 107.9758 - val_mae: 9.3834 - val_mse: 107.9758\n",
            "Epoch 66/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 112.2420 - mae: 9.7421 - mse: 112.2420 - val_loss: 137.2909 - val_mae: 10.9317 - val_mse: 137.2909\n",
            "Epoch 67/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 103.8025 - mae: 9.4284 - mse: 103.8025 - val_loss: 146.1434 - val_mae: 11.2625 - val_mse: 146.1434\n",
            "Epoch 68/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 100.9871 - mae: 9.1001 - mse: 100.9871 - val_loss: 131.2307 - val_mae: 10.5469 - val_mse: 131.2307\n",
            "Epoch 69/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 91.0699 - mae: 8.7874 - mse: 91.0699 - val_loss: 171.3471 - val_mae: 12.1741 - val_mse: 171.3471\n",
            "Epoch 70/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 87.6622 - mae: 8.5700 - mse: 87.6622 - val_loss: 85.8668 - val_mae: 8.2165 - val_mse: 85.8668\n",
            "Epoch 71/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 83.9613 - mae: 8.2328 - mse: 83.9613 - val_loss: 123.3370 - val_mae: 10.2423 - val_mse: 123.3370\n",
            "Epoch 72/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 76.4873 - mae: 7.8880 - mse: 76.4873 - val_loss: 98.2900 - val_mae: 8.6762 - val_mse: 98.2900\n",
            "Epoch 73/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 70.9471 - mae: 7.5596 - mse: 70.9471 - val_loss: 101.7712 - val_mae: 9.0143 - val_mse: 101.7712\n",
            "Epoch 74/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.4896 - mae: 7.3149 - mse: 68.4896 - val_loss: 90.0605 - val_mae: 8.4333 - val_mse: 90.0605\n",
            "Epoch 75/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 63.6712 - mae: 6.9951 - mse: 63.6712 - val_loss: 79.9517 - val_mae: 7.5282 - val_mse: 79.9517\n",
            "Epoch 76/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 60.7032 - mae: 6.6941 - mse: 60.7032 - val_loss: 79.5817 - val_mae: 7.7926 - val_mse: 79.5817\n",
            "Epoch 77/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 55.1275 - mae: 6.3718 - mse: 55.1275 - val_loss: 100.0925 - val_mae: 8.9430 - val_mse: 100.0925\n",
            "Epoch 78/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 49.4366 - mae: 6.0721 - mse: 49.4366 - val_loss: 103.3734 - val_mae: 8.8744 - val_mse: 103.3734\n",
            "Epoch 79/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45.4919 - mae: 5.7815 - mse: 45.4919 - val_loss: 112.0093 - val_mae: 9.5737 - val_mse: 112.0093\n",
            "Epoch 80/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 41.6881 - mae: 5.4219 - mse: 41.6881 - val_loss: 70.0251 - val_mae: 7.1797 - val_mse: 70.0251\n",
            "Epoch 81/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 38.4984 - mae: 5.1322 - mse: 38.4984 - val_loss: 60.1030 - val_mae: 6.4493 - val_mse: 60.1030\n",
            "Epoch 82/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 34.6234 - mae: 4.8561 - mse: 34.6234 - val_loss: 68.4207 - val_mae: 6.6879 - val_mse: 68.4207\n",
            "Epoch 83/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 32.0009 - mae: 4.6075 - mse: 32.0009 - val_loss: 57.4296 - val_mae: 5.5150 - val_mse: 57.4296\n",
            "Epoch 84/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31.1366 - mae: 4.4072 - mse: 31.1366 - val_loss: 42.8444 - val_mae: 4.7987 - val_mse: 42.8444\n",
            "Epoch 85/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 29.6841 - mae: 4.2065 - mse: 29.6841 - val_loss: 42.1587 - val_mae: 4.9318 - val_mse: 42.1587\n",
            "Epoch 86/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 24.3132 - mae: 3.8152 - mse: 24.3132 - val_loss: 56.3357 - val_mae: 5.9842 - val_mse: 56.3357\n",
            "Epoch 87/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 22.6634 - mae: 3.6404 - mse: 22.6634 - val_loss: 47.0227 - val_mae: 5.2833 - val_mse: 47.0227\n",
            "Epoch 88/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 20.0031 - mae: 3.4751 - mse: 20.0031 - val_loss: 43.0013 - val_mae: 4.9150 - val_mse: 43.0013\n",
            "Epoch 89/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.8430 - mae: 3.6260 - mse: 22.8430 - val_loss: 32.9189 - val_mae: 3.8404 - val_mse: 32.9189\n",
            "Epoch 90/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.1801 - mae: 3.1110 - mse: 17.1801 - val_loss: 34.4933 - val_mae: 4.2546 - val_mse: 34.4933\n",
            "Epoch 91/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 20.8903 - mae: 3.3109 - mse: 20.8903 - val_loss: 52.2920 - val_mae: 4.8670 - val_mse: 52.2920\n",
            "Epoch 92/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 19.4510 - mae: 3.1510 - mse: 19.4510 - val_loss: 44.6245 - val_mae: 4.6200 - val_mse: 44.6245\n",
            "Epoch 93/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.2958 - mae: 2.9071 - mse: 15.2958 - val_loss: 24.5883 - val_mae: 3.5198 - val_mse: 24.5883\n",
            "Epoch 94/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 16.9140 - mae: 2.9726 - mse: 16.9140 - val_loss: 32.4083 - val_mae: 3.9426 - val_mse: 32.4083\n",
            "Epoch 95/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.0619 - mae: 2.9677 - mse: 15.0619 - val_loss: 25.9804 - val_mae: 3.7784 - val_mse: 25.9804\n",
            "Epoch 96/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.4863 - mae: 2.7230 - mse: 14.4863 - val_loss: 51.6984 - val_mae: 5.0829 - val_mse: 51.6984\n",
            "Epoch 97/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7602 - mae: 2.6289 - mse: 12.7602 - val_loss: 22.3802 - val_mae: 3.4845 - val_mse: 22.3802\n",
            "Epoch 98/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.8602 - mae: 2.8235 - mse: 16.8602 - val_loss: 22.6367 - val_mae: 3.3863 - val_mse: 22.6367\n",
            "Epoch 99/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.6231 - mae: 2.8306 - mse: 14.6231 - val_loss: 35.2454 - val_mae: 4.3112 - val_mse: 35.2454\n",
            "Epoch 100/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.5850 - mae: 2.7961 - mse: 14.5850 - val_loss: 33.6337 - val_mae: 4.0424 - val_mse: 33.6337\n",
            "Epoch 101/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.2901 - mae: 2.6275 - mse: 12.2901 - val_loss: 38.8443 - val_mae: 4.3060 - val_mse: 38.8443\n",
            "Epoch 102/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.4219 - mae: 2.7839 - mse: 14.4219 - val_loss: 25.7959 - val_mae: 3.7126 - val_mse: 25.7959\n",
            "Epoch 103/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2079 - mae: 2.5996 - mse: 13.2079 - val_loss: 30.5402 - val_mae: 3.8168 - val_mse: 30.5402\n",
            "Epoch 104/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.3521 - mae: 3.0124 - mse: 17.3521 - val_loss: 22.4282 - val_mae: 3.2674 - val_mse: 22.4282\n",
            "Epoch 105/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.7108 - mae: 2.6993 - mse: 15.7108 - val_loss: 39.8339 - val_mae: 4.2889 - val_mse: 39.8339\n",
            "Epoch 106/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.0204 - mae: 2.7927 - mse: 15.0204 - val_loss: 25.3230 - val_mae: 3.3237 - val_mse: 25.3230\n",
            "Epoch 107/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 17.0202 - mae: 2.8977 - mse: 17.0202 - val_loss: 30.7761 - val_mae: 3.7243 - val_mse: 30.7761\n",
            "Epoch 108/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3459 - mae: 2.5851 - mse: 12.3459 - val_loss: 29.7088 - val_mae: 3.8271 - val_mse: 29.7088\n",
            "Epoch 109/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0138 - mae: 2.6906 - mse: 13.0138 - val_loss: 35.1531 - val_mae: 4.0111 - val_mse: 35.1531\n",
            "Epoch 110/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5905 - mae: 2.6897 - mse: 13.5905 - val_loss: 29.1869 - val_mae: 3.5255 - val_mse: 29.1869\n",
            "Epoch 111/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2005 - mae: 2.7039 - mse: 13.2005 - val_loss: 31.9266 - val_mae: 3.9426 - val_mse: 31.9266\n",
            "Epoch 112/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.8040 - mae: 2.8882 - mse: 14.8040 - val_loss: 30.1075 - val_mae: 3.8141 - val_mse: 30.1075\n",
            "Epoch 113/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.8246 - mae: 2.7855 - mse: 14.8246 - val_loss: 26.8245 - val_mae: 3.4323 - val_mse: 26.8245\n",
            "Epoch 114/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.5983 - mae: 2.7034 - mse: 13.5983 - val_loss: 24.5739 - val_mae: 3.4372 - val_mse: 24.5739\n",
            "Epoch 115/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.0374 - mae: 2.7538 - mse: 14.0374 - val_loss: 23.5229 - val_mae: 3.2685 - val_mse: 23.5229\n",
            "Epoch 116/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.4013 - mae: 2.7208 - mse: 14.4013 - val_loss: 37.4666 - val_mae: 4.1425 - val_mse: 37.4666\n",
            "Epoch 117/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.9171 - mae: 2.7283 - mse: 14.9171 - val_loss: 29.9481 - val_mae: 3.7136 - val_mse: 29.9481\n",
            "Epoch 118/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.6905 - mae: 2.6065 - mse: 12.6905 - val_loss: 43.9716 - val_mae: 4.4344 - val_mse: 43.9716\n",
            "Epoch 119/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.9722 - mae: 2.8024 - mse: 14.9722 - val_loss: 39.7257 - val_mae: 4.1200 - val_mse: 39.7257\n",
            "Epoch 120/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.0553 - mae: 2.4914 - mse: 11.0553 - val_loss: 29.9546 - val_mae: 4.0270 - val_mse: 29.9546\n",
            "Epoch 121/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 18.3311 - mae: 3.0703 - mse: 18.3311 - val_loss: 24.5675 - val_mae: 3.5016 - val_mse: 24.5675\n",
            "Epoch 122/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.8466 - mae: 2.7827 - mse: 14.8466 - val_loss: 31.5482 - val_mae: 3.8727 - val_mse: 31.5482\n",
            "Epoch 123/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.1511 - mae: 2.7828 - mse: 14.1511 - val_loss: 22.9590 - val_mae: 3.2437 - val_mse: 22.9590\n",
            "Epoch 124/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.5801 - mae: 2.7177 - mse: 14.5801 - val_loss: 22.9701 - val_mae: 3.4666 - val_mse: 22.9701\n",
            "Epoch 125/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.4102 - mae: 2.9175 - mse: 15.4102 - val_loss: 35.8114 - val_mae: 4.2053 - val_mse: 35.8114\n",
            "Epoch 126/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.2950 - mae: 2.5362 - mse: 12.2950 - val_loss: 24.1334 - val_mae: 3.3830 - val_mse: 24.1334\n",
            "Epoch 127/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.0725 - mae: 2.7200 - mse: 15.0725 - val_loss: 27.2845 - val_mae: 3.7632 - val_mse: 27.2845\n",
            "Epoch 128/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.4205 - mae: 2.7651 - mse: 14.4205 - val_loss: 43.1068 - val_mae: 5.0609 - val_mse: 43.1068\n",
            "Epoch 129/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.5448 - mae: 2.7231 - mse: 14.5448 - val_loss: 57.2050 - val_mae: 5.6107 - val_mse: 57.2050\n",
            "Epoch 130/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.6644 - mae: 2.6569 - mse: 14.6644 - val_loss: 22.9468 - val_mae: 3.5163 - val_mse: 22.9468\n",
            "Epoch 131/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.8447 - mae: 2.8083 - mse: 15.8447 - val_loss: 27.1761 - val_mae: 3.6248 - val_mse: 27.1761\n",
            "Epoch 132/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6266 - mae: 2.7525 - mse: 14.6266 - val_loss: 22.7777 - val_mae: 3.1872 - val_mse: 22.7777\n",
            "Epoch 133/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.6218 - mae: 2.6112 - mse: 12.6218 - val_loss: 29.0660 - val_mae: 3.4675 - val_mse: 29.0660\n",
            "Epoch 134/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 16.5562 - mae: 2.9421 - mse: 16.5562 - val_loss: 31.0711 - val_mae: 3.9564 - val_mse: 31.0711\n",
            "Epoch 135/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.2911 - mae: 2.4288 - mse: 11.2911 - val_loss: 35.7603 - val_mae: 3.9501 - val_mse: 35.7603\n",
            "Epoch 136/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4248 - mae: 2.5225 - mse: 11.4248 - val_loss: 31.4044 - val_mae: 3.5660 - val_mse: 31.4044\n",
            "Epoch 137/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7478 - mae: 2.6240 - mse: 12.7478 - val_loss: 29.9439 - val_mae: 3.5389 - val_mse: 29.9439\n",
            "Epoch 138/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.1493 - mae: 2.7403 - mse: 13.1493 - val_loss: 39.7023 - val_mae: 4.0893 - val_mse: 39.7023\n",
            "Epoch 139/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.0261 - mae: 2.6936 - mse: 14.0261 - val_loss: 31.4395 - val_mae: 3.6521 - val_mse: 31.4395\n",
            "Epoch 140/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.4886 - mae: 2.5002 - mse: 12.4886 - val_loss: 71.3006 - val_mae: 5.8134 - val_mse: 71.3006\n",
            "Epoch 141/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.3218 - mae: 2.6195 - mse: 13.3218 - val_loss: 29.9960 - val_mae: 3.4905 - val_mse: 29.9960\n",
            "Epoch 142/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.0279 - mae: 2.6027 - mse: 12.0279 - val_loss: 26.5623 - val_mae: 3.3944 - val_mse: 26.5623\n",
            "Epoch 143/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.6453 - mae: 2.8017 - mse: 14.6453 - val_loss: 29.7710 - val_mae: 3.3950 - val_mse: 29.7710\n",
            "Epoch 144/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.4828 - mae: 2.9140 - mse: 16.4828 - val_loss: 26.8878 - val_mae: 3.2026 - val_mse: 26.8878\n",
            "Epoch 145/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3063 - mae: 2.6034 - mse: 12.3063 - val_loss: 40.1482 - val_mae: 4.6379 - val_mse: 40.1482\n",
            "Epoch 146/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.9872 - mae: 2.6567 - mse: 12.9872 - val_loss: 33.7200 - val_mae: 3.8119 - val_mse: 33.7200\n",
            "Epoch 147/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.1017 - mae: 2.7096 - mse: 15.1017 - val_loss: 24.9319 - val_mae: 3.2995 - val_mse: 24.9319\n",
            "Epoch 148/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.7414 - mae: 2.6347 - mse: 13.7414 - val_loss: 26.8045 - val_mae: 3.2720 - val_mse: 26.8045\n",
            "Epoch 149/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3455 - mae: 2.5683 - mse: 12.3455 - val_loss: 33.2725 - val_mae: 3.6585 - val_mse: 33.2725\n",
            "Epoch 150/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.4624 - mae: 2.7866 - mse: 16.4624 - val_loss: 28.3114 - val_mae: 3.4460 - val_mse: 28.3114\n",
            "Epoch 151/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.5594 - mae: 2.8321 - mse: 14.5594 - val_loss: 40.8451 - val_mae: 4.0528 - val_mse: 40.8451\n",
            "Epoch 152/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 13.4902 - mae: 2.6054 - mse: 13.4902 - val_loss: 47.6217 - val_mae: 4.5409 - val_mse: 47.6217\n",
            "Epoch 153/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.4303 - mae: 2.5973 - mse: 12.4303 - val_loss: 46.0690 - val_mae: 4.5256 - val_mse: 46.0690\n",
            "Epoch 154/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3327 - mae: 2.6548 - mse: 13.3327 - val_loss: 28.7738 - val_mae: 3.2376 - val_mse: 28.7738\n",
            "Epoch 155/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.0431 - mae: 2.5290 - mse: 12.0431 - val_loss: 29.6987 - val_mae: 3.4511 - val_mse: 29.6987\n",
            "Epoch 156/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.7596 - mae: 2.4886 - mse: 11.7596 - val_loss: 35.5046 - val_mae: 3.8697 - val_mse: 35.5046\n",
            "Epoch 157/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.4681 - mae: 2.5546 - mse: 12.4681 - val_loss: 23.5385 - val_mae: 3.4167 - val_mse: 23.5385\n",
            "Epoch 158/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3590 - mae: 2.5946 - mse: 13.3590 - val_loss: 23.7135 - val_mae: 3.1293 - val_mse: 23.7135\n",
            "Epoch 159/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.4171 - mae: 2.6416 - mse: 13.4171 - val_loss: 27.8867 - val_mae: 3.2632 - val_mse: 27.8867\n",
            "Epoch 160/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.9896 - mae: 2.8929 - mse: 16.9896 - val_loss: 30.2146 - val_mae: 3.3594 - val_mse: 30.2146\n",
            "Epoch 161/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.2805 - mae: 2.6332 - mse: 13.2805 - val_loss: 25.6057 - val_mae: 3.3617 - val_mse: 25.6057\n",
            "Epoch 162/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.8658 - mae: 2.4226 - mse: 10.8658 - val_loss: 24.3458 - val_mae: 3.5301 - val_mse: 24.3458\n",
            "Epoch 163/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.6049 - mae: 2.8937 - mse: 14.6049 - val_loss: 37.2240 - val_mae: 4.0866 - val_mse: 37.2240\n",
            "Epoch 164/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.6842 - mae: 2.7107 - mse: 14.6842 - val_loss: 23.1163 - val_mae: 3.3006 - val_mse: 23.1163\n",
            "Epoch 165/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7865 - mae: 2.5847 - mse: 12.7865 - val_loss: 25.0306 - val_mae: 3.3579 - val_mse: 25.0306\n",
            "Epoch 166/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.9917 - mae: 2.4686 - mse: 11.9917 - val_loss: 29.7594 - val_mae: 3.7694 - val_mse: 29.7594\n",
            "Epoch 167/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 13.9584 - mae: 2.7020 - mse: 13.9584 - val_loss: 29.0289 - val_mae: 3.3643 - val_mse: 29.0289\n",
            "Epoch 168/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.5410 - mae: 2.6762 - mse: 14.5410 - val_loss: 24.5210 - val_mae: 3.1700 - val_mse: 24.5210\n",
            "Epoch 169/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.5475 - mae: 2.6068 - mse: 12.5475 - val_loss: 57.7005 - val_mae: 4.9987 - val_mse: 57.7005\n",
            "Epoch 170/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.9109 - mae: 2.7588 - mse: 14.9109 - val_loss: 28.0661 - val_mae: 3.6290 - val_mse: 28.0661\n",
            "Epoch 171/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.5182 - mae: 2.6173 - mse: 13.5182 - val_loss: 25.3929 - val_mae: 3.3615 - val_mse: 25.3929\n",
            "Epoch 172/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.3520 - mae: 2.9354 - mse: 15.3520 - val_loss: 30.8823 - val_mae: 3.9392 - val_mse: 30.8823\n",
            "Epoch 173/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.0081 - mae: 2.6607 - mse: 15.0081 - val_loss: 32.0945 - val_mae: 3.4556 - val_mse: 32.0945\n",
            "Epoch 174/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.1748 - mae: 2.4754 - mse: 12.1748 - val_loss: 28.3867 - val_mae: 3.4051 - val_mse: 28.3867\n",
            "Epoch 175/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.6195 - mae: 2.5760 - mse: 11.6195 - val_loss: 32.0238 - val_mae: 3.8829 - val_mse: 32.0238\n",
            "Epoch 176/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.3417 - mae: 2.5466 - mse: 11.3417 - val_loss: 38.8568 - val_mae: 3.7048 - val_mse: 38.8568\n",
            "Epoch 177/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.7075 - mae: 2.6390 - mse: 12.7075 - val_loss: 28.8423 - val_mae: 3.6788 - val_mse: 28.8423\n",
            "Epoch 178/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 15.3611 - mae: 2.8813 - mse: 15.3611 - val_loss: 24.6051 - val_mae: 3.2848 - val_mse: 24.6051\n",
            "Epoch 179/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.4978 - mae: 2.5308 - mse: 12.4978 - val_loss: 29.7036 - val_mae: 3.2468 - val_mse: 29.7036\n",
            "Epoch 180/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.9323 - mae: 2.6795 - mse: 13.9323 - val_loss: 43.9465 - val_mae: 4.0414 - val_mse: 43.9465\n",
            "Epoch 181/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.1850 - mae: 2.5450 - mse: 12.1850 - val_loss: 28.3373 - val_mae: 3.2726 - val_mse: 28.3373\n",
            "Epoch 182/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.0027 - mae: 2.6430 - mse: 14.0027 - val_loss: 68.4683 - val_mae: 5.3114 - val_mse: 68.4683\n",
            "Epoch 183/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9833 - mae: 2.6189 - mse: 13.9833 - val_loss: 29.8833 - val_mae: 3.5422 - val_mse: 29.8833\n",
            "Epoch 184/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.6775 - mae: 2.5084 - mse: 11.6775 - val_loss: 34.6151 - val_mae: 3.6788 - val_mse: 34.6151\n",
            "Epoch 185/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.9734 - mae: 2.5711 - mse: 12.9734 - val_loss: 57.0904 - val_mae: 4.8746 - val_mse: 57.0904\n",
            "Epoch 186/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4107 - mae: 2.5277 - mse: 11.4107 - val_loss: 27.5505 - val_mae: 3.2448 - val_mse: 27.5505\n",
            "Epoch 187/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9523 - mae: 2.5837 - mse: 11.9523 - val_loss: 28.7921 - val_mae: 3.5179 - val_mse: 28.7921\n",
            "Epoch 188/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3479 - mae: 2.5854 - mse: 12.3479 - val_loss: 24.1880 - val_mae: 3.2885 - val_mse: 24.1880\n",
            "Epoch 189/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6836 - mae: 2.6326 - mse: 13.6836 - val_loss: 26.9594 - val_mae: 3.2900 - val_mse: 26.9594\n",
            "Epoch 190/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7494 - mae: 2.6631 - mse: 12.7494 - val_loss: 24.1782 - val_mae: 3.2673 - val_mse: 24.1782\n",
            "Epoch 191/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3519 - mae: 2.4380 - mse: 10.3519 - val_loss: 24.8383 - val_mae: 3.2890 - val_mse: 24.8383\n",
            "Epoch 192/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.8860 - mae: 2.7952 - mse: 14.8860 - val_loss: 24.3834 - val_mae: 3.4062 - val_mse: 24.3834\n",
            "Epoch 193/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2862 - mae: 2.6076 - mse: 13.2862 - val_loss: 24.6752 - val_mae: 3.2652 - val_mse: 24.6752\n",
            "Epoch 194/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5089 - mae: 2.5517 - mse: 12.5089 - val_loss: 36.4637 - val_mae: 3.8801 - val_mse: 36.4637\n",
            "Epoch 195/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.5820 - mae: 2.6143 - mse: 12.5820 - val_loss: 32.3453 - val_mae: 3.5018 - val_mse: 32.3453\n",
            "Epoch 196/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.6510 - mae: 2.5327 - mse: 11.6510 - val_loss: 50.3901 - val_mae: 4.4515 - val_mse: 50.3901\n",
            "Epoch 197/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7809 - mae: 2.5982 - mse: 11.7809 - val_loss: 24.0598 - val_mae: 3.2315 - val_mse: 24.0598\n",
            "Epoch 198/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 18.1135 - mae: 2.9140 - mse: 18.1135 - val_loss: 53.4041 - val_mae: 4.9806 - val_mse: 53.4041\n",
            "Epoch 199/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.4623 - mae: 2.5416 - mse: 11.4623 - val_loss: 26.1447 - val_mae: 3.3513 - val_mse: 26.1447\n",
            "Epoch 200/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.8864 - mae: 2.8928 - mse: 15.8864 - val_loss: 27.1553 - val_mae: 3.8066 - val_mse: 27.1553\n",
            "Epoch 201/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.4753 - mae: 2.5197 - mse: 11.4753 - val_loss: 56.1507 - val_mae: 5.1682 - val_mse: 56.1507\n",
            "Epoch 202/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.3578 - mae: 2.9030 - mse: 15.3578 - val_loss: 39.3838 - val_mae: 3.9154 - val_mse: 39.3838\n",
            "Epoch 203/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.5046 - mae: 2.8191 - mse: 14.5046 - val_loss: 29.4489 - val_mae: 3.6951 - val_mse: 29.4489\n",
            "Epoch 204/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.1142 - mae: 2.4402 - mse: 11.1142 - val_loss: 32.3544 - val_mae: 3.8744 - val_mse: 32.3544\n",
            "Epoch 205/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8973 - mae: 2.5826 - mse: 12.8973 - val_loss: 26.1045 - val_mae: 3.3863 - val_mse: 26.1045\n",
            "Epoch 206/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.5409 - mae: 2.7778 - mse: 14.5409 - val_loss: 26.5044 - val_mae: 3.2955 - val_mse: 26.5044\n",
            "Epoch 207/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.0677 - mae: 2.4919 - mse: 12.0677 - val_loss: 27.4096 - val_mae: 3.2665 - val_mse: 27.4096\n",
            "Epoch 208/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.1386 - mae: 2.8782 - mse: 15.1386 - val_loss: 33.8598 - val_mae: 3.7001 - val_mse: 33.8598\n",
            "Epoch 209/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7898 - mae: 2.4853 - mse: 11.7898 - val_loss: 47.3161 - val_mae: 4.6634 - val_mse: 47.3161\n",
            "Epoch 210/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.4702 - mae: 2.5401 - mse: 13.4702 - val_loss: 23.0203 - val_mae: 3.0717 - val_mse: 23.0203\n",
            "Epoch 211/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9063 - mae: 2.4981 - mse: 10.9063 - val_loss: 30.1561 - val_mae: 3.6768 - val_mse: 30.1561\n",
            "Epoch 212/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.9338 - mae: 2.6006 - mse: 12.9338 - val_loss: 45.1006 - val_mae: 4.8688 - val_mse: 45.1006\n",
            "Epoch 213/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.0895 - mae: 2.4152 - mse: 11.0895 - val_loss: 26.4452 - val_mae: 3.2679 - val_mse: 26.4452\n",
            "Epoch 214/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4179 - mae: 2.3950 - mse: 10.4179 - val_loss: 29.7726 - val_mae: 3.3526 - val_mse: 29.7726\n",
            "Epoch 215/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.8137 - mae: 2.5802 - mse: 11.8137 - val_loss: 28.1823 - val_mae: 3.7276 - val_mse: 28.1823\n",
            "Epoch 216/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2262 - mae: 2.6190 - mse: 13.2262 - val_loss: 23.8471 - val_mae: 3.1637 - val_mse: 23.8471\n",
            "Epoch 217/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.7036 - mae: 2.8077 - mse: 14.7036 - val_loss: 23.9001 - val_mae: 3.2143 - val_mse: 23.9001\n",
            "Epoch 218/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.0136 - mae: 2.5478 - mse: 13.0136 - val_loss: 26.1869 - val_mae: 3.3753 - val_mse: 26.1869\n",
            "Epoch 219/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1052 - mae: 2.5697 - mse: 13.1052 - val_loss: 28.5601 - val_mae: 3.2330 - val_mse: 28.5601\n",
            "Epoch 220/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2205 - mae: 2.5562 - mse: 12.2205 - val_loss: 26.7511 - val_mae: 3.4700 - val_mse: 26.7511\n",
            "Epoch 221/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5489 - mae: 2.6036 - mse: 13.5489 - val_loss: 25.5293 - val_mae: 3.2049 - val_mse: 25.5293\n",
            "Epoch 222/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.1660 - mae: 2.4615 - mse: 11.1660 - val_loss: 49.8828 - val_mae: 4.6287 - val_mse: 49.8828\n",
            "Epoch 223/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.6192 - mae: 2.4995 - mse: 11.6192 - val_loss: 24.2648 - val_mae: 3.4032 - val_mse: 24.2648\n",
            "Epoch 224/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.7218 - mae: 2.6583 - mse: 12.7218 - val_loss: 33.9986 - val_mae: 3.6264 - val_mse: 33.9986\n",
            "Epoch 225/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.7798 - mae: 2.7328 - mse: 14.7798 - val_loss: 23.3110 - val_mae: 3.0947 - val_mse: 23.3110\n",
            "Epoch 226/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.7254 - mae: 2.7347 - mse: 13.7254 - val_loss: 27.6214 - val_mae: 3.3293 - val_mse: 27.6214\n",
            "Epoch 227/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.7035 - mae: 2.6157 - mse: 13.7035 - val_loss: 40.7907 - val_mae: 4.1688 - val_mse: 40.7907\n",
            "Epoch 228/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.7765 - mae: 2.7535 - mse: 13.7765 - val_loss: 25.5917 - val_mae: 3.2324 - val_mse: 25.5917\n",
            "Epoch 229/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2596 - mae: 2.4393 - mse: 10.2596 - val_loss: 53.4107 - val_mae: 4.3604 - val_mse: 53.4107\n",
            "Epoch 230/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2355 - mae: 2.7012 - mse: 12.2355 - val_loss: 29.2859 - val_mae: 3.2786 - val_mse: 29.2859\n",
            "Epoch 231/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3429 - mae: 2.4005 - mse: 10.3429 - val_loss: 28.9461 - val_mae: 3.6195 - val_mse: 28.9461\n",
            "Epoch 232/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.3928 - mae: 2.7861 - mse: 14.3928 - val_loss: 27.4278 - val_mae: 3.3538 - val_mse: 27.4278\n",
            "Epoch 233/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.5595 - mae: 3.0576 - mse: 17.5595 - val_loss: 23.5527 - val_mae: 3.2073 - val_mse: 23.5527\n",
            "Epoch 234/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.1629 - mae: 2.6334 - mse: 13.1629 - val_loss: 28.6168 - val_mae: 3.4811 - val_mse: 28.6168\n",
            "Epoch 235/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1339 - mae: 2.6588 - mse: 13.1339 - val_loss: 24.4721 - val_mae: 3.1580 - val_mse: 24.4721\n",
            "Epoch 236/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9905 - mae: 2.4484 - mse: 10.9905 - val_loss: 29.6296 - val_mae: 3.4871 - val_mse: 29.6296\n",
            "Epoch 237/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.0560 - mae: 2.5449 - mse: 13.0560 - val_loss: 45.2345 - val_mae: 4.3064 - val_mse: 45.2345\n",
            "Epoch 238/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2717 - mae: 2.5940 - mse: 12.2717 - val_loss: 28.3247 - val_mae: 3.3970 - val_mse: 28.3247\n",
            "Epoch 239/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.3306 - mae: 2.4406 - mse: 11.3306 - val_loss: 30.2627 - val_mae: 3.6628 - val_mse: 30.2627\n",
            "Epoch 240/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.5331 - mae: 2.5586 - mse: 12.5331 - val_loss: 47.6240 - val_mae: 5.0671 - val_mse: 47.6240\n",
            "Epoch 241/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5292 - mae: 2.4195 - mse: 10.5292 - val_loss: 43.3170 - val_mae: 4.8046 - val_mse: 43.3170\n",
            "Epoch 242/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.0187 - mae: 2.5938 - mse: 13.0187 - val_loss: 23.6835 - val_mae: 3.5004 - val_mse: 23.6835\n",
            "Epoch 243/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.6693 - mae: 2.5635 - mse: 11.6693 - val_loss: 22.1755 - val_mae: 3.3478 - val_mse: 22.1755\n",
            "Epoch 244/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.1457 - mae: 2.6873 - mse: 13.1457 - val_loss: 35.3930 - val_mae: 4.1534 - val_mse: 35.3930\n",
            "Epoch 245/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5031 - mae: 2.6183 - mse: 11.5031 - val_loss: 24.2626 - val_mae: 3.1646 - val_mse: 24.2626\n",
            "Epoch 246/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9695 - mae: 2.3375 - mse: 9.9695 - val_loss: 27.5404 - val_mae: 3.7172 - val_mse: 27.5404\n",
            "Epoch 247/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6443 - mae: 2.5695 - mse: 11.6443 - val_loss: 30.1120 - val_mae: 3.6978 - val_mse: 30.1120\n",
            "Epoch 248/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3266 - mae: 2.4475 - mse: 12.3266 - val_loss: 38.0883 - val_mae: 3.8022 - val_mse: 38.0883\n",
            "Epoch 249/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4653 - mae: 2.3940 - mse: 10.4653 - val_loss: 30.9847 - val_mae: 3.3118 - val_mse: 30.9847\n",
            "Epoch 250/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.0712 - mae: 2.3891 - mse: 11.0712 - val_loss: 28.6618 - val_mae: 3.1211 - val_mse: 28.6618\n",
            "Epoch 251/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3608 - mae: 2.7087 - mse: 13.3608 - val_loss: 22.9141 - val_mae: 2.9682 - val_mse: 22.9141\n",
            "Epoch 252/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2620 - mae: 2.5202 - mse: 12.2620 - val_loss: 22.7703 - val_mae: 3.1596 - val_mse: 22.7703\n",
            "Epoch 253/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.0657 - mae: 2.5436 - mse: 12.0657 - val_loss: 26.8261 - val_mae: 3.0600 - val_mse: 26.8261\n",
            "Epoch 254/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2754 - mae: 2.5126 - mse: 12.2754 - val_loss: 31.4901 - val_mae: 3.5990 - val_mse: 31.4901\n",
            "Epoch 255/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.5322 - mae: 2.5457 - mse: 11.5322 - val_loss: 22.8400 - val_mae: 2.9614 - val_mse: 22.8400\n",
            "Epoch 256/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.1297 - mae: 2.7536 - mse: 14.1297 - val_loss: 23.5619 - val_mae: 2.9441 - val_mse: 23.5619\n",
            "Epoch 257/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.9723 - mae: 2.6471 - mse: 11.9723 - val_loss: 23.5523 - val_mae: 3.1147 - val_mse: 23.5523\n",
            "Epoch 258/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9719 - mae: 2.7224 - mse: 12.9719 - val_loss: 22.7146 - val_mae: 2.8946 - val_mse: 22.7146\n",
            "Epoch 259/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.5401 - mae: 2.9120 - mse: 14.5401 - val_loss: 27.8172 - val_mae: 3.2650 - val_mse: 27.8172\n",
            "Epoch 260/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9320 - mae: 2.5421 - mse: 10.9320 - val_loss: 24.6183 - val_mae: 3.0357 - val_mse: 24.6183\n",
            "Epoch 261/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.5946 - mae: 2.3295 - mse: 10.5946 - val_loss: 37.4538 - val_mae: 4.6530 - val_mse: 37.4538\n",
            "Epoch 262/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.2154 - mae: 2.5158 - mse: 12.2154 - val_loss: 28.0674 - val_mae: 3.5634 - val_mse: 28.0674\n",
            "Epoch 263/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.5069 - mae: 2.3143 - mse: 11.5069 - val_loss: 23.8560 - val_mae: 3.3867 - val_mse: 23.8560\n",
            "Epoch 264/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6793 - mae: 2.4607 - mse: 10.6793 - val_loss: 20.9134 - val_mae: 3.0784 - val_mse: 20.9134\n",
            "Epoch 265/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.4367 - mae: 2.3231 - mse: 10.4367 - val_loss: 31.9833 - val_mae: 3.7382 - val_mse: 31.9833\n",
            "Epoch 266/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0952 - mae: 2.5351 - mse: 11.0952 - val_loss: 26.7771 - val_mae: 3.2139 - val_mse: 26.7771\n",
            "Epoch 267/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1285 - mae: 2.4688 - mse: 11.1285 - val_loss: 24.3745 - val_mae: 3.4293 - val_mse: 24.3745\n",
            "Epoch 268/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.4809 - mae: 2.4605 - mse: 11.4809 - val_loss: 27.9714 - val_mae: 3.3595 - val_mse: 27.9714\n",
            "Epoch 269/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2072 - mae: 2.4174 - mse: 11.2072 - val_loss: 29.9928 - val_mae: 3.2732 - val_mse: 29.9928\n",
            "Epoch 270/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2739 - mae: 2.4442 - mse: 12.2739 - val_loss: 101.2001 - val_mae: 6.5773 - val_mse: 101.2001\n",
            "Epoch 271/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5284 - mae: 2.4937 - mse: 12.5284 - val_loss: 42.6643 - val_mae: 4.0142 - val_mse: 42.6643\n",
            "Epoch 272/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.3755 - mae: 2.6041 - mse: 12.3755 - val_loss: 33.2109 - val_mae: 3.4972 - val_mse: 33.2109\n",
            "Epoch 273/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4181 - mae: 2.4043 - mse: 10.4181 - val_loss: 27.4793 - val_mae: 3.1839 - val_mse: 27.4793\n",
            "Epoch 274/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.8628 - mae: 2.8127 - mse: 14.8628 - val_loss: 29.8721 - val_mae: 3.2100 - val_mse: 29.8721\n",
            "Epoch 275/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7874 - mae: 2.1980 - mse: 8.7874 - val_loss: 62.8907 - val_mae: 5.0598 - val_mse: 62.8907\n",
            "Epoch 276/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.3347 - mae: 2.5305 - mse: 12.3347 - val_loss: 29.3914 - val_mae: 3.2181 - val_mse: 29.3914\n",
            "Epoch 277/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6263 - mae: 2.4245 - mse: 11.6263 - val_loss: 31.2554 - val_mae: 3.2317 - val_mse: 31.2554\n",
            "Epoch 278/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2936 - mae: 2.3477 - mse: 10.2936 - val_loss: 37.4501 - val_mae: 3.6961 - val_mse: 37.4501\n",
            "Epoch 279/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.8464 - mae: 2.6691 - mse: 13.8464 - val_loss: 24.4809 - val_mae: 3.2459 - val_mse: 24.4809\n",
            "Epoch 280/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.8391 - mae: 2.5052 - mse: 12.8391 - val_loss: 35.7736 - val_mae: 4.4549 - val_mse: 35.7736\n",
            "Epoch 281/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7071 - mae: 2.3529 - mse: 9.7071 - val_loss: 32.6587 - val_mae: 3.6601 - val_mse: 32.6587\n",
            "Epoch 282/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.7828 - mae: 2.6384 - mse: 12.7828 - val_loss: 39.4206 - val_mae: 4.8132 - val_mse: 39.4206\n",
            "Epoch 283/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6526 - mae: 2.4154 - mse: 10.6526 - val_loss: 30.2613 - val_mae: 3.1937 - val_mse: 30.2613\n",
            "Epoch 284/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 14.6154 - mae: 2.7733 - mse: 14.6154 - val_loss: 31.5877 - val_mae: 3.9861 - val_mse: 31.5877\n",
            "Epoch 285/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7502 - mae: 2.4033 - mse: 10.7502 - val_loss: 26.8059 - val_mae: 3.1046 - val_mse: 26.8059\n",
            "Epoch 286/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8148 - mae: 2.3321 - mse: 9.8148 - val_loss: 26.9553 - val_mae: 3.3050 - val_mse: 26.9553\n",
            "Epoch 287/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1659 - mae: 2.4598 - mse: 11.1659 - val_loss: 23.3483 - val_mae: 3.1600 - val_mse: 23.3483\n",
            "Epoch 288/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.4384 - mae: 2.4159 - mse: 11.4384 - val_loss: 40.9960 - val_mae: 4.0791 - val_mse: 40.9960\n",
            "Epoch 289/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.8911 - mae: 2.6524 - mse: 13.8911 - val_loss: 25.7212 - val_mae: 3.0497 - val_mse: 25.7212\n",
            "Epoch 290/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.2561 - mae: 2.1774 - mse: 8.2561 - val_loss: 28.3904 - val_mae: 3.1322 - val_mse: 28.3904\n",
            "Epoch 291/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.6384 - mae: 2.6445 - mse: 13.6384 - val_loss: 29.8588 - val_mae: 3.3331 - val_mse: 29.8588\n",
            "Epoch 292/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5978 - mae: 2.4793 - mse: 11.5978 - val_loss: 28.1988 - val_mae: 3.0271 - val_mse: 28.1988\n",
            "Epoch 293/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.2725 - mae: 2.5455 - mse: 13.2725 - val_loss: 43.0947 - val_mae: 4.2543 - val_mse: 43.0947\n",
            "Epoch 294/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6958 - mae: 2.4222 - mse: 10.6958 - val_loss: 30.6206 - val_mae: 3.2135 - val_mse: 30.6206\n",
            "Epoch 295/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2908 - mae: 2.4352 - mse: 10.2908 - val_loss: 44.4856 - val_mae: 4.2186 - val_mse: 44.4856\n",
            "Epoch 296/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4520 - mae: 2.4796 - mse: 11.4520 - val_loss: 29.2644 - val_mae: 3.8043 - val_mse: 29.2644\n",
            "Epoch 297/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.5585 - mae: 2.4434 - mse: 11.5585 - val_loss: 27.4111 - val_mae: 3.1319 - val_mse: 27.4111\n",
            "Epoch 298/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8776 - mae: 2.4327 - mse: 10.8776 - val_loss: 30.5494 - val_mae: 3.3016 - val_mse: 30.5494\n",
            "Epoch 299/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2393 - mae: 2.2748 - mse: 9.2393 - val_loss: 30.5801 - val_mae: 3.6172 - val_mse: 30.5801\n",
            "Epoch 300/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7126 - mae: 2.2786 - mse: 10.7126 - val_loss: 25.6458 - val_mae: 3.0618 - val_mse: 25.6458\n",
            "Epoch 301/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.7338 - mae: 2.3345 - mse: 9.7338 - val_loss: 35.0870 - val_mae: 4.4075 - val_mse: 35.0870\n",
            "Epoch 302/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1438 - mae: 2.3966 - mse: 11.1438 - val_loss: 27.0181 - val_mae: 3.0918 - val_mse: 27.0181\n",
            "Epoch 303/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.4420 - mae: 2.6846 - mse: 15.4420 - val_loss: 30.8238 - val_mae: 3.4636 - val_mse: 30.8238\n",
            "Epoch 304/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.0524 - mae: 2.6028 - mse: 12.0524 - val_loss: 39.2621 - val_mae: 3.9096 - val_mse: 39.2621\n",
            "Epoch 305/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.7613 - mae: 2.4128 - mse: 10.7613 - val_loss: 25.6300 - val_mae: 3.0576 - val_mse: 25.6300\n",
            "Epoch 306/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2067 - mae: 2.4687 - mse: 11.2067 - val_loss: 29.9279 - val_mae: 3.3828 - val_mse: 29.9279\n",
            "Epoch 307/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 13.5033 - mae: 2.6617 - mse: 13.5033 - val_loss: 25.5252 - val_mae: 3.0488 - val_mse: 25.5252\n",
            "Epoch 308/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.5204 - mae: 2.4272 - mse: 11.5204 - val_loss: 27.1017 - val_mae: 3.1388 - val_mse: 27.1017\n",
            "Epoch 309/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.2719 - mae: 2.4775 - mse: 11.2719 - val_loss: 27.6970 - val_mae: 3.4915 - val_mse: 27.6970\n",
            "Epoch 310/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 12.5038 - mae: 2.4926 - mse: 12.5038 - val_loss: 30.0545 - val_mae: 3.2402 - val_mse: 30.0545\n",
            "Epoch 311/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.7300 - mae: 2.3298 - mse: 9.7300 - val_loss: 27.4334 - val_mae: 3.1253 - val_mse: 27.4334\n",
            "Epoch 312/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.6618 - mae: 2.5819 - mse: 12.6618 - val_loss: 31.6660 - val_mae: 3.3949 - val_mse: 31.6660\n",
            "Epoch 313/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.8458 - mae: 2.5318 - mse: 12.8458 - val_loss: 31.1364 - val_mae: 3.8627 - val_mse: 31.1364\n",
            "Epoch 314/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.8514 - mae: 2.3781 - mse: 10.8514 - val_loss: 23.5161 - val_mae: 3.1701 - val_mse: 23.5161\n",
            "Epoch 315/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.5228 - mae: 2.3761 - mse: 10.5228 - val_loss: 28.4205 - val_mae: 3.6334 - val_mse: 28.4205\n",
            "Epoch 316/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.6022 - mae: 2.3175 - mse: 9.6022 - val_loss: 28.1391 - val_mae: 3.1751 - val_mse: 28.1391\n",
            "Epoch 317/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.1993 - mae: 2.4458 - mse: 11.1993 - val_loss: 30.1835 - val_mae: 3.6448 - val_mse: 30.1835\n",
            "Epoch 318/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.0208 - mae: 2.2633 - mse: 9.0208 - val_loss: 29.2999 - val_mae: 3.4872 - val_mse: 29.2999\n",
            "Epoch 319/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3394 - mae: 2.5318 - mse: 11.3394 - val_loss: 22.6000 - val_mae: 2.9849 - val_mse: 22.6000\n",
            "Epoch 320/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.2680 - mae: 2.5446 - mse: 14.2680 - val_loss: 29.6251 - val_mae: 3.8215 - val_mse: 29.6251\n",
            "Epoch 321/900\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 8.3662 - mae: 2.1764 - mse: 8.3662 - val_loss: 26.6661 - val_mae: 3.0363 - val_mse: 26.6661\n",
            "Epoch 322/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.7456 - mae: 2.0422 - mse: 7.7456 - val_loss: 27.5920 - val_mae: 3.0996 - val_mse: 27.5920\n",
            "Epoch 323/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.3896 - mae: 2.3097 - mse: 9.3896 - val_loss: 32.4106 - val_mae: 4.1303 - val_mse: 32.4106\n",
            "Epoch 324/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.2538 - mae: 2.5142 - mse: 12.2538 - val_loss: 27.8168 - val_mae: 3.4722 - val_mse: 27.8168\n",
            "Epoch 325/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 15.1655 - mae: 2.6416 - mse: 15.1655 - val_loss: 25.6383 - val_mae: 3.4011 - val_mse: 25.6383\n",
            "Epoch 326/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5761 - mae: 2.2179 - mse: 8.5761 - val_loss: 23.1405 - val_mae: 3.0551 - val_mse: 23.1405\n",
            "Epoch 327/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.8521 - mae: 2.5708 - mse: 11.8521 - val_loss: 22.3316 - val_mae: 3.2292 - val_mse: 22.3316\n",
            "Epoch 328/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 13.5232 - mae: 2.5552 - mse: 13.5232 - val_loss: 28.8146 - val_mae: 3.8258 - val_mse: 28.8146\n",
            "Epoch 329/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.5749 - mae: 2.6787 - mse: 12.5749 - val_loss: 26.7565 - val_mae: 3.0079 - val_mse: 26.7565\n",
            "Epoch 330/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.7703 - mae: 2.2808 - mse: 8.7703 - val_loss: 23.7805 - val_mae: 3.3707 - val_mse: 23.7805\n",
            "Epoch 331/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.0543 - mae: 2.2487 - mse: 9.0543 - val_loss: 25.6041 - val_mae: 3.3393 - val_mse: 25.6041\n",
            "Epoch 332/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.9716 - mae: 2.4652 - mse: 10.9716 - val_loss: 24.6449 - val_mae: 3.1608 - val_mse: 24.6449\n",
            "Epoch 333/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.2327 - mae: 2.6618 - mse: 12.2327 - val_loss: 23.6511 - val_mae: 3.0446 - val_mse: 23.6511\n",
            "Epoch 334/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.8911 - mae: 2.2352 - mse: 8.8911 - val_loss: 25.8083 - val_mae: 3.1289 - val_mse: 25.8083\n",
            "Epoch 335/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 15.4300 - mae: 2.9068 - mse: 15.4300 - val_loss: 37.3092 - val_mae: 3.7547 - val_mse: 37.3092\n",
            "Epoch 336/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4445 - mae: 2.4453 - mse: 10.4445 - val_loss: 45.8216 - val_mae: 4.5308 - val_mse: 45.8216\n",
            "Epoch 337/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6541 - mae: 2.3517 - mse: 10.6541 - val_loss: 23.3947 - val_mae: 3.2787 - val_mse: 23.3947\n",
            "Epoch 338/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2522 - mae: 2.3237 - mse: 10.2522 - val_loss: 33.5757 - val_mae: 4.0878 - val_mse: 33.5757\n",
            "Epoch 339/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7018 - mae: 2.3717 - mse: 10.7018 - val_loss: 28.9200 - val_mae: 3.6057 - val_mse: 28.9200\n",
            "Epoch 340/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7607 - mae: 2.7919 - mse: 13.7607 - val_loss: 21.7978 - val_mae: 3.3498 - val_mse: 21.7978\n",
            "Epoch 341/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7998 - mae: 2.3713 - mse: 10.7998 - val_loss: 22.4808 - val_mae: 3.0296 - val_mse: 22.4808\n",
            "Epoch 342/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3011 - mae: 2.4233 - mse: 11.3011 - val_loss: 37.5247 - val_mae: 3.5447 - val_mse: 37.5247\n",
            "Epoch 343/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6453 - mae: 2.3705 - mse: 10.6453 - val_loss: 24.7818 - val_mae: 3.1534 - val_mse: 24.7818\n",
            "Epoch 344/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.7029 - mae: 2.4417 - mse: 10.7029 - val_loss: 28.3151 - val_mae: 3.5253 - val_mse: 28.3151\n",
            "Epoch 345/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.1318 - mae: 2.5009 - mse: 12.1318 - val_loss: 26.8413 - val_mae: 3.5854 - val_mse: 26.8413\n",
            "Epoch 346/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4529 - mae: 2.2356 - mse: 8.4529 - val_loss: 28.9884 - val_mae: 3.1363 - val_mse: 28.9884\n",
            "Epoch 347/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.9555 - mae: 2.3636 - mse: 9.9555 - val_loss: 29.4031 - val_mae: 3.0622 - val_mse: 29.4031\n",
            "Epoch 348/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.6222 - mae: 2.5761 - mse: 13.6222 - val_loss: 26.7976 - val_mae: 2.9356 - val_mse: 26.7976\n",
            "Epoch 349/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6886 - mae: 2.3071 - mse: 9.6886 - val_loss: 34.1166 - val_mae: 3.2291 - val_mse: 34.1166\n",
            "Epoch 350/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.1242 - mae: 2.4768 - mse: 11.1242 - val_loss: 32.3992 - val_mae: 3.4690 - val_mse: 32.3992\n",
            "Epoch 351/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6677 - mae: 2.2689 - mse: 9.6677 - val_loss: 27.3570 - val_mae: 3.1598 - val_mse: 27.3570\n",
            "Epoch 352/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6862 - mae: 2.3070 - mse: 9.6862 - val_loss: 65.4974 - val_mae: 5.1561 - val_mse: 65.4974\n",
            "Epoch 353/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7138 - mae: 2.3310 - mse: 9.7138 - val_loss: 25.1307 - val_mae: 3.0806 - val_mse: 25.1307\n",
            "Epoch 354/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.4282 - mae: 2.2933 - mse: 10.4282 - val_loss: 29.7277 - val_mae: 3.0850 - val_mse: 29.7277\n",
            "Epoch 355/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 15.1534 - mae: 2.6348 - mse: 15.1534 - val_loss: 25.8306 - val_mae: 2.9901 - val_mse: 25.8306\n",
            "Epoch 356/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9698 - mae: 2.3336 - mse: 9.9698 - val_loss: 33.4719 - val_mae: 3.7712 - val_mse: 33.4719\n",
            "Epoch 357/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.3832 - mae: 2.6066 - mse: 12.3832 - val_loss: 40.3022 - val_mae: 4.2808 - val_mse: 40.3022\n",
            "Epoch 358/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9512 - mae: 2.2617 - mse: 8.9512 - val_loss: 27.6487 - val_mae: 3.5763 - val_mse: 27.6487\n",
            "Epoch 359/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.2269 - mae: 2.3819 - mse: 10.2269 - val_loss: 43.6095 - val_mae: 4.1427 - val_mse: 43.6095\n",
            "Epoch 360/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4232 - mae: 2.2423 - mse: 9.4232 - val_loss: 29.2720 - val_mae: 3.1246 - val_mse: 29.2720\n",
            "Epoch 361/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.5525 - mae: 2.4209 - mse: 11.5525 - val_loss: 26.2245 - val_mae: 2.9297 - val_mse: 26.2245\n",
            "Epoch 362/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.3718 - mae: 2.3838 - mse: 11.3718 - val_loss: 27.1516 - val_mae: 2.9338 - val_mse: 27.1516\n",
            "Epoch 363/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.0898 - mae: 2.2936 - mse: 10.0898 - val_loss: 26.9333 - val_mae: 3.1710 - val_mse: 26.9333\n",
            "Epoch 364/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0637 - mae: 2.2554 - mse: 11.0637 - val_loss: 31.3403 - val_mae: 4.0886 - val_mse: 31.3403\n",
            "Epoch 365/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7367 - mae: 2.3586 - mse: 9.7367 - val_loss: 23.5657 - val_mae: 3.1315 - val_mse: 23.5657\n",
            "Epoch 366/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7371 - mae: 2.2976 - mse: 9.7371 - val_loss: 23.9268 - val_mae: 3.0504 - val_mse: 23.9268\n",
            "Epoch 367/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.8640 - mae: 2.3666 - mse: 11.8640 - val_loss: 21.8968 - val_mae: 3.1178 - val_mse: 21.8968\n",
            "Epoch 368/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.6731 - mae: 2.4198 - mse: 11.6731 - val_loss: 30.0902 - val_mae: 3.5268 - val_mse: 30.0902\n",
            "Epoch 369/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4187 - mae: 2.4718 - mse: 11.4187 - val_loss: 26.8165 - val_mae: 3.4222 - val_mse: 26.8165\n",
            "Epoch 370/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1362 - mae: 2.2253 - mse: 10.1362 - val_loss: 28.4785 - val_mae: 3.5186 - val_mse: 28.4785\n",
            "Epoch 371/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.1133 - mae: 2.4595 - mse: 11.1133 - val_loss: 28.5939 - val_mae: 3.4538 - val_mse: 28.5939\n",
            "Epoch 372/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.0236 - mae: 2.7430 - mse: 13.0236 - val_loss: 25.1247 - val_mae: 3.2838 - val_mse: 25.1247\n",
            "Epoch 373/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0998 - mae: 2.0968 - mse: 8.0998 - val_loss: 46.5933 - val_mae: 4.4023 - val_mse: 46.5933\n",
            "Epoch 374/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.2810 - mae: 2.5661 - mse: 12.2810 - val_loss: 22.0848 - val_mae: 3.0173 - val_mse: 22.0848\n",
            "Epoch 375/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5200 - mae: 2.4281 - mse: 10.5200 - val_loss: 24.7425 - val_mae: 3.1000 - val_mse: 24.7425\n",
            "Epoch 376/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5502 - mae: 2.2890 - mse: 9.5502 - val_loss: 29.5430 - val_mae: 3.2140 - val_mse: 29.5430\n",
            "Epoch 377/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9655 - mae: 2.3211 - mse: 9.9655 - val_loss: 25.9403 - val_mae: 3.6357 - val_mse: 25.9403\n",
            "Epoch 378/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.5670 - mae: 2.4545 - mse: 11.5670 - val_loss: 26.8378 - val_mae: 3.0677 - val_mse: 26.8378\n",
            "Epoch 379/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6321 - mae: 2.4458 - mse: 10.6321 - val_loss: 29.3601 - val_mae: 3.4230 - val_mse: 29.3601\n",
            "Epoch 380/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 16.3183 - mae: 2.9370 - mse: 16.3183 - val_loss: 23.3067 - val_mae: 3.2114 - val_mse: 23.3067\n",
            "Epoch 381/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.7494 - mae: 2.4544 - mse: 11.7494 - val_loss: 30.3549 - val_mae: 4.0007 - val_mse: 30.3549\n",
            "Epoch 382/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6306 - mae: 2.4586 - mse: 10.6306 - val_loss: 47.1832 - val_mae: 3.9201 - val_mse: 47.1832\n",
            "Epoch 383/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3911 - mae: 2.2865 - mse: 9.3911 - val_loss: 30.7290 - val_mae: 3.1283 - val_mse: 30.7290\n",
            "Epoch 384/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.8630 - mae: 2.5330 - mse: 10.8630 - val_loss: 42.6525 - val_mae: 3.8646 - val_mse: 42.6525\n",
            "Epoch 385/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9233 - mae: 2.2626 - mse: 8.9233 - val_loss: 24.2048 - val_mae: 3.1865 - val_mse: 24.2048\n",
            "Epoch 386/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7647 - mae: 2.4189 - mse: 9.7647 - val_loss: 25.3627 - val_mae: 2.9615 - val_mse: 25.3627\n",
            "Epoch 387/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.9688 - mae: 2.3850 - mse: 10.9688 - val_loss: 25.9040 - val_mae: 3.0438 - val_mse: 25.9040\n",
            "Epoch 388/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9729 - mae: 2.1233 - mse: 7.9729 - val_loss: 40.1137 - val_mae: 3.6347 - val_mse: 40.1137\n",
            "Epoch 389/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.1188 - mae: 2.2937 - mse: 9.1188 - val_loss: 25.6045 - val_mae: 3.4798 - val_mse: 25.6045\n",
            "Epoch 390/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.8479 - mae: 2.3635 - mse: 10.8479 - val_loss: 25.6322 - val_mae: 3.0892 - val_mse: 25.6322\n",
            "Epoch 391/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9585 - mae: 2.5533 - mse: 12.9585 - val_loss: 30.6413 - val_mae: 3.2149 - val_mse: 30.6413\n",
            "Epoch 392/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.0182 - mae: 2.3382 - mse: 10.0182 - val_loss: 28.3670 - val_mae: 3.2158 - val_mse: 28.3670\n",
            "Epoch 393/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.0242 - mae: 2.3286 - mse: 11.0242 - val_loss: 24.4926 - val_mae: 2.9207 - val_mse: 24.4926\n",
            "Epoch 394/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1498 - mae: 2.2065 - mse: 9.1498 - val_loss: 40.1072 - val_mae: 3.6794 - val_mse: 40.1072\n",
            "Epoch 395/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1578 - mae: 2.3553 - mse: 11.1578 - val_loss: 32.4488 - val_mae: 3.2438 - val_mse: 32.4488\n",
            "Epoch 396/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0044 - mae: 2.3791 - mse: 11.0044 - val_loss: 24.9708 - val_mae: 2.9107 - val_mse: 24.9708\n",
            "Epoch 397/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3495 - mae: 2.2808 - mse: 9.3495 - val_loss: 22.4772 - val_mae: 2.8399 - val_mse: 22.4772\n",
            "Epoch 398/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2983 - mae: 2.1437 - mse: 8.2983 - val_loss: 23.9496 - val_mae: 2.9123 - val_mse: 23.9496\n",
            "Epoch 399/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9239 - mae: 2.0718 - mse: 7.9239 - val_loss: 25.2969 - val_mae: 2.9866 - val_mse: 25.2969\n",
            "Epoch 400/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5180 - mae: 2.3601 - mse: 10.5180 - val_loss: 23.8252 - val_mae: 3.0009 - val_mse: 23.8252\n",
            "Epoch 401/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.2442 - mae: 2.4072 - mse: 11.2442 - val_loss: 24.4378 - val_mae: 2.9861 - val_mse: 24.4378\n",
            "Epoch 402/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8564 - mae: 2.3802 - mse: 10.8564 - val_loss: 35.8671 - val_mae: 3.4916 - val_mse: 35.8671\n",
            "Epoch 403/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8098 - mae: 2.3572 - mse: 9.8098 - val_loss: 27.7906 - val_mae: 3.0102 - val_mse: 27.7906\n",
            "Epoch 404/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.5482 - mae: 2.5667 - mse: 12.5482 - val_loss: 29.6503 - val_mae: 3.2326 - val_mse: 29.6503\n",
            "Epoch 405/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.5643 - mae: 2.5128 - mse: 12.5643 - val_loss: 25.6301 - val_mae: 3.1028 - val_mse: 25.6301\n",
            "Epoch 406/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.0860 - mae: 2.3480 - mse: 10.0860 - val_loss: 27.6604 - val_mae: 3.0891 - val_mse: 27.6604\n",
            "Epoch 407/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.4806 - mae: 2.3997 - mse: 10.4806 - val_loss: 21.9907 - val_mae: 2.8995 - val_mse: 21.9907\n",
            "Epoch 408/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6205 - mae: 2.4345 - mse: 11.6205 - val_loss: 31.6242 - val_mae: 3.2065 - val_mse: 31.6242\n",
            "Epoch 409/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0022 - mae: 2.2997 - mse: 10.0022 - val_loss: 28.7501 - val_mae: 3.8812 - val_mse: 28.7501\n",
            "Epoch 410/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1235 - mae: 2.3458 - mse: 10.1235 - val_loss: 41.5264 - val_mae: 4.0539 - val_mse: 41.5264\n",
            "Epoch 411/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.2441 - mae: 2.7142 - mse: 15.2441 - val_loss: 62.6854 - val_mae: 5.2725 - val_mse: 62.6854\n",
            "Epoch 412/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.5197 - mae: 2.4789 - mse: 11.5197 - val_loss: 20.1514 - val_mae: 2.7766 - val_mse: 20.1514\n",
            "Epoch 413/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.2517 - mae: 2.5673 - mse: 11.2517 - val_loss: 23.4690 - val_mae: 3.1419 - val_mse: 23.4690\n",
            "Epoch 414/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3995 - mae: 2.3268 - mse: 9.3995 - val_loss: 32.3257 - val_mae: 3.7159 - val_mse: 32.3257\n",
            "Epoch 415/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1298 - mae: 2.2846 - mse: 9.1298 - val_loss: 27.5557 - val_mae: 3.1875 - val_mse: 27.5557\n",
            "Epoch 416/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.6132 - mae: 2.5401 - mse: 11.6132 - val_loss: 29.6930 - val_mae: 3.5336 - val_mse: 29.6930\n",
            "Epoch 417/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3829 - mae: 2.3585 - mse: 10.3829 - val_loss: 24.6295 - val_mae: 2.9652 - val_mse: 24.6295\n",
            "Epoch 418/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.6677 - mae: 2.3523 - mse: 9.6677 - val_loss: 23.8925 - val_mae: 3.4882 - val_mse: 23.8925\n",
            "Epoch 419/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7991 - mae: 2.3688 - mse: 10.7991 - val_loss: 30.6190 - val_mae: 3.3885 - val_mse: 30.6190\n",
            "Epoch 420/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6182 - mae: 2.1536 - mse: 8.6182 - val_loss: 27.5737 - val_mae: 3.5831 - val_mse: 27.5737\n",
            "Epoch 421/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2195 - mae: 2.2378 - mse: 9.2195 - val_loss: 25.4404 - val_mae: 3.4419 - val_mse: 25.4404\n",
            "Epoch 422/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.0743 - mae: 2.3482 - mse: 10.0743 - val_loss: 33.3345 - val_mae: 3.2209 - val_mse: 33.3345\n",
            "Epoch 423/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.9882 - mae: 2.2164 - mse: 8.9882 - val_loss: 24.0156 - val_mae: 2.9947 - val_mse: 24.0156\n",
            "Epoch 424/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.7766 - mae: 2.2707 - mse: 9.7766 - val_loss: 27.2998 - val_mae: 2.9821 - val_mse: 27.2998\n",
            "Epoch 425/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.6073 - mae: 2.6454 - mse: 13.6073 - val_loss: 29.6137 - val_mae: 3.5530 - val_mse: 29.6137\n",
            "Epoch 426/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.5266 - mae: 2.3832 - mse: 10.5266 - val_loss: 23.9547 - val_mae: 3.0378 - val_mse: 23.9547\n",
            "Epoch 427/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6981 - mae: 2.6253 - mse: 12.6981 - val_loss: 32.8905 - val_mae: 3.7309 - val_mse: 32.8905\n",
            "Epoch 428/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7313 - mae: 2.4383 - mse: 10.7313 - val_loss: 23.1547 - val_mae: 3.1057 - val_mse: 23.1547\n",
            "Epoch 429/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.8852 - mae: 2.2908 - mse: 8.8852 - val_loss: 34.8980 - val_mae: 3.4548 - val_mse: 34.8980\n",
            "Epoch 430/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5883 - mae: 2.4053 - mse: 10.5883 - val_loss: 33.3505 - val_mae: 3.3140 - val_mse: 33.3505\n",
            "Epoch 431/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.1242 - mae: 2.4742 - mse: 11.1242 - val_loss: 48.7416 - val_mae: 4.5954 - val_mse: 48.7415\n",
            "Epoch 432/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4342 - mae: 2.2082 - mse: 9.4342 - val_loss: 25.2890 - val_mae: 2.9137 - val_mse: 25.2890\n",
            "Epoch 433/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7881 - mae: 2.2671 - mse: 8.7881 - val_loss: 21.8884 - val_mae: 2.8074 - val_mse: 21.8884\n",
            "Epoch 434/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.8937 - mae: 2.5806 - mse: 12.8937 - val_loss: 27.2733 - val_mae: 2.9322 - val_mse: 27.2733\n",
            "Epoch 435/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7070 - mae: 2.2342 - mse: 8.7070 - val_loss: 26.6274 - val_mae: 2.8367 - val_mse: 26.6274\n",
            "Epoch 436/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4881 - mae: 2.2117 - mse: 9.4881 - val_loss: 33.4599 - val_mae: 3.1824 - val_mse: 33.4599\n",
            "Epoch 437/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4494 - mae: 2.2192 - mse: 9.4494 - val_loss: 31.3179 - val_mae: 3.2595 - val_mse: 31.3179\n",
            "Epoch 438/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0163 - mae: 2.1426 - mse: 9.0163 - val_loss: 28.6605 - val_mae: 3.1917 - val_mse: 28.6605\n",
            "Epoch 439/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4283 - mae: 2.4116 - mse: 12.4283 - val_loss: 31.6734 - val_mae: 3.6980 - val_mse: 31.6734\n",
            "Epoch 440/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.8692 - mae: 2.3663 - mse: 9.8692 - val_loss: 25.7264 - val_mae: 3.4691 - val_mse: 25.7264\n",
            "Epoch 441/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9419 - mae: 2.6098 - mse: 11.9419 - val_loss: 24.8222 - val_mae: 2.9117 - val_mse: 24.8222\n",
            "Epoch 442/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3318 - mae: 2.2955 - mse: 9.3318 - val_loss: 33.1023 - val_mae: 3.1497 - val_mse: 33.1023\n",
            "Epoch 443/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.9469 - mae: 2.1134 - mse: 7.9469 - val_loss: 29.4746 - val_mae: 3.3502 - val_mse: 29.4746\n",
            "Epoch 444/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.6027 - mae: 2.3177 - mse: 9.6027 - val_loss: 26.0798 - val_mae: 3.0141 - val_mse: 26.0798\n",
            "Epoch 445/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.7353 - mae: 2.4271 - mse: 11.7353 - val_loss: 23.2950 - val_mae: 2.8576 - val_mse: 23.2950\n",
            "Epoch 446/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.2203 - mae: 2.4021 - mse: 11.2203 - val_loss: 28.5210 - val_mae: 3.0352 - val_mse: 28.5210\n",
            "Epoch 447/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3612 - mae: 2.1929 - mse: 8.3612 - val_loss: 24.5611 - val_mae: 2.9409 - val_mse: 24.5611\n",
            "Epoch 448/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7983 - mae: 2.2768 - mse: 9.7983 - val_loss: 29.2827 - val_mae: 3.4869 - val_mse: 29.2827\n",
            "Epoch 449/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8969 - mae: 2.2802 - mse: 9.8969 - val_loss: 21.9558 - val_mae: 2.9555 - val_mse: 21.9558\n",
            "Epoch 450/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.9289 - mae: 2.6487 - mse: 12.9289 - val_loss: 30.2415 - val_mae: 3.0696 - val_mse: 30.2415\n",
            "Epoch 451/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.9179 - mae: 2.1537 - mse: 7.9179 - val_loss: 34.7233 - val_mae: 3.4609 - val_mse: 34.7233\n",
            "Epoch 452/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.7180 - mae: 2.1347 - mse: 7.7180 - val_loss: 31.0067 - val_mae: 3.8243 - val_mse: 31.0067\n",
            "Epoch 453/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.2249 - mae: 2.3712 - mse: 10.2249 - val_loss: 25.5024 - val_mae: 3.4417 - val_mse: 25.5024\n",
            "Epoch 454/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.8472 - mae: 2.4831 - mse: 10.8472 - val_loss: 26.6054 - val_mae: 3.5081 - val_mse: 26.6054\n",
            "Epoch 455/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.7327 - mae: 2.6298 - mse: 11.7327 - val_loss: 23.3611 - val_mae: 2.8685 - val_mse: 23.3611\n",
            "Epoch 456/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.8125 - mae: 2.2886 - mse: 9.8125 - val_loss: 26.7907 - val_mae: 2.8358 - val_mse: 26.7907\n",
            "Epoch 457/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 13.9964 - mae: 2.7159 - mse: 13.9964 - val_loss: 37.5167 - val_mae: 3.7390 - val_mse: 37.5167\n",
            "Epoch 458/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 11.1223 - mae: 2.5057 - mse: 11.1223 - val_loss: 27.2765 - val_mae: 2.9488 - val_mse: 27.2765\n",
            "Epoch 459/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.8928 - mae: 2.2795 - mse: 9.8928 - val_loss: 25.4657 - val_mae: 3.0444 - val_mse: 25.4657\n",
            "Epoch 460/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.4309 - mae: 2.3361 - mse: 9.4309 - val_loss: 30.9405 - val_mae: 3.4820 - val_mse: 30.9405\n",
            "Epoch 461/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 8.7515 - mae: 2.2408 - mse: 8.7515 - val_loss: 23.8389 - val_mae: 3.0068 - val_mse: 23.8389\n",
            "Epoch 462/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.1595 - mae: 2.3320 - mse: 10.1595 - val_loss: 27.8215 - val_mae: 3.0918 - val_mse: 27.8215\n",
            "Epoch 463/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.1409 - mae: 2.4018 - mse: 10.1409 - val_loss: 26.6635 - val_mae: 3.5723 - val_mse: 26.6635\n",
            "Epoch 464/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6653 - mae: 2.4703 - mse: 11.6653 - val_loss: 21.8327 - val_mae: 2.7763 - val_mse: 21.8327\n",
            "Epoch 465/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5169 - mae: 2.2551 - mse: 9.5169 - val_loss: 33.2316 - val_mae: 3.2607 - val_mse: 33.2316\n",
            "Epoch 466/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 11.6394 - mae: 2.4265 - mse: 11.6394 - val_loss: 49.1141 - val_mae: 4.2189 - val_mse: 49.1141\n",
            "Epoch 467/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.8343 - mae: 2.0715 - mse: 7.8343 - val_loss: 25.9839 - val_mae: 2.9520 - val_mse: 25.9839\n",
            "Epoch 468/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.4877 - mae: 2.2561 - mse: 9.4877 - val_loss: 26.4315 - val_mae: 2.8754 - val_mse: 26.4315\n",
            "Epoch 469/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.6983 - mae: 2.2203 - mse: 8.6983 - val_loss: 35.7317 - val_mae: 4.0461 - val_mse: 35.7317\n",
            "Epoch 470/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 10.0601 - mae: 2.4463 - mse: 10.0601 - val_loss: 22.6256 - val_mae: 3.0057 - val_mse: 22.6256\n",
            "Epoch 471/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.0445 - mae: 2.3009 - mse: 10.0445 - val_loss: 22.6324 - val_mae: 2.8709 - val_mse: 22.6324\n",
            "Epoch 472/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1077 - mae: 2.3214 - mse: 10.1077 - val_loss: 25.0555 - val_mae: 3.0864 - val_mse: 25.0555\n",
            "Epoch 473/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.2086 - mae: 2.1261 - mse: 9.2086 - val_loss: 37.4672 - val_mae: 3.6426 - val_mse: 37.4672\n",
            "Epoch 474/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.4136 - mae: 2.3417 - mse: 11.4136 - val_loss: 28.1247 - val_mae: 2.9590 - val_mse: 28.1247\n",
            "Epoch 475/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.1445 - mae: 2.0617 - mse: 8.1445 - val_loss: 28.8855 - val_mae: 3.4052 - val_mse: 28.8855\n",
            "Epoch 476/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.2180 - mae: 2.1557 - mse: 8.2180 - val_loss: 25.8729 - val_mae: 2.8599 - val_mse: 25.8729\n",
            "Epoch 477/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6393 - mae: 2.1246 - mse: 7.6393 - val_loss: 22.7560 - val_mae: 2.8674 - val_mse: 22.7560\n",
            "Epoch 478/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9351 - mae: 2.1492 - mse: 8.9351 - val_loss: 23.8581 - val_mae: 2.7805 - val_mse: 23.8581\n",
            "Epoch 479/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.8238 - mae: 2.4893 - mse: 10.8238 - val_loss: 27.8851 - val_mae: 2.7578 - val_mse: 27.8851\n",
            "Epoch 480/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.9747 - mae: 2.4398 - mse: 12.9747 - val_loss: 25.2076 - val_mae: 2.8726 - val_mse: 25.2076\n",
            "Epoch 481/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.1884 - mae: 2.3314 - mse: 9.1884 - val_loss: 23.6097 - val_mae: 2.8821 - val_mse: 23.6097\n",
            "Epoch 482/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.3523 - mae: 2.2769 - mse: 9.3523 - val_loss: 24.2469 - val_mae: 2.8967 - val_mse: 24.2469\n",
            "Epoch 483/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.6341 - mae: 2.3048 - mse: 9.6341 - val_loss: 29.3362 - val_mae: 3.3920 - val_mse: 29.3362\n",
            "Epoch 484/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.2154 - mae: 2.2208 - mse: 9.2154 - val_loss: 26.5148 - val_mae: 3.1437 - val_mse: 26.5148\n",
            "Epoch 485/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.3990 - mae: 2.0356 - mse: 7.3990 - val_loss: 27.6600 - val_mae: 3.4060 - val_mse: 27.6600\n",
            "Epoch 486/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.0379 - mae: 2.2909 - mse: 9.0379 - val_loss: 21.6271 - val_mae: 2.9791 - val_mse: 21.6271\n",
            "Epoch 487/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5527 - mae: 2.1695 - mse: 8.5527 - val_loss: 23.2048 - val_mae: 3.3314 - val_mse: 23.2048\n",
            "Epoch 488/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3400 - mae: 2.1788 - mse: 9.3400 - val_loss: 21.4278 - val_mae: 3.0913 - val_mse: 21.4278\n",
            "Epoch 489/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.2185 - mae: 2.3106 - mse: 10.2185 - val_loss: 31.9063 - val_mae: 3.5945 - val_mse: 31.9063\n",
            "Epoch 490/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3298 - mae: 2.3183 - mse: 10.3298 - val_loss: 31.5257 - val_mae: 3.4442 - val_mse: 31.5257\n",
            "Epoch 491/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6550 - mae: 2.3200 - mse: 9.6550 - val_loss: 27.6904 - val_mae: 3.3682 - val_mse: 27.6904\n",
            "Epoch 492/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.2453 - mae: 2.2737 - mse: 10.2453 - val_loss: 24.7822 - val_mae: 2.9107 - val_mse: 24.7822\n",
            "Epoch 493/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9239 - mae: 2.3875 - mse: 9.9239 - val_loss: 23.6826 - val_mae: 2.8352 - val_mse: 23.6826\n",
            "Epoch 494/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6636 - mae: 2.1721 - mse: 7.6636 - val_loss: 23.4696 - val_mae: 2.7929 - val_mse: 23.4696\n",
            "Epoch 495/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.9859 - mae: 2.2627 - mse: 9.9859 - val_loss: 23.9010 - val_mae: 2.8379 - val_mse: 23.9010\n",
            "Epoch 496/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6204 - mae: 2.2555 - mse: 8.6204 - val_loss: 25.6479 - val_mae: 2.9386 - val_mse: 25.6479\n",
            "Epoch 497/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.9972 - mae: 2.2837 - mse: 9.9972 - val_loss: 23.3562 - val_mae: 2.8555 - val_mse: 23.3562\n",
            "Epoch 498/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.7066 - mae: 2.6116 - mse: 11.7066 - val_loss: 22.9087 - val_mae: 3.1201 - val_mse: 22.9087\n",
            "Epoch 499/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.7971 - mae: 2.4720 - mse: 11.7971 - val_loss: 25.8242 - val_mae: 3.6938 - val_mse: 25.8242\n",
            "Epoch 500/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6539 - mae: 2.2344 - mse: 10.6539 - val_loss: 23.7066 - val_mae: 2.8008 - val_mse: 23.7066\n",
            "Epoch 501/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1864 - mae: 2.2212 - mse: 9.1864 - val_loss: 23.8946 - val_mae: 2.6512 - val_mse: 23.8946\n",
            "Epoch 502/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1534 - mae: 2.2417 - mse: 9.1534 - val_loss: 27.4844 - val_mae: 3.7034 - val_mse: 27.4844\n",
            "Epoch 503/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.4604 - mae: 2.2036 - mse: 8.4604 - val_loss: 22.9866 - val_mae: 2.6260 - val_mse: 22.9866\n",
            "Epoch 504/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.3619 - mae: 2.1831 - mse: 8.3619 - val_loss: 33.2599 - val_mae: 3.2078 - val_mse: 33.2599\n",
            "Epoch 505/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.0500 - mae: 2.3393 - mse: 10.0500 - val_loss: 22.6576 - val_mae: 2.8711 - val_mse: 22.6576\n",
            "Epoch 506/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.4910 - mae: 2.6555 - mse: 12.4910 - val_loss: 20.0316 - val_mae: 2.7687 - val_mse: 20.0316\n",
            "Epoch 507/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.7186 - mae: 2.2687 - mse: 10.7186 - val_loss: 37.9534 - val_mae: 3.9376 - val_mse: 37.9534\n",
            "Epoch 508/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.2456 - mae: 2.4833 - mse: 11.2456 - val_loss: 28.1068 - val_mae: 3.8426 - val_mse: 28.1068\n",
            "Epoch 509/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.1800 - mae: 2.1701 - mse: 8.1800 - val_loss: 28.2046 - val_mae: 2.9124 - val_mse: 28.2046\n",
            "Epoch 510/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9326 - mae: 2.1878 - mse: 8.9326 - val_loss: 61.0318 - val_mae: 5.4609 - val_mse: 61.0318\n",
            "Epoch 511/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6300 - mae: 2.0762 - mse: 7.6300 - val_loss: 24.6765 - val_mae: 2.8095 - val_mse: 24.6765\n",
            "Epoch 512/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.2805 - mae: 2.2291 - mse: 9.2805 - val_loss: 24.4508 - val_mae: 2.7001 - val_mse: 24.4508\n",
            "Epoch 513/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.1823 - mae: 2.4645 - mse: 10.1823 - val_loss: 24.8894 - val_mae: 3.1712 - val_mse: 24.8894\n",
            "Epoch 514/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6005 - mae: 2.2751 - mse: 9.6005 - val_loss: 33.6690 - val_mae: 3.1586 - val_mse: 33.6690\n",
            "Epoch 515/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.9176 - mae: 2.3911 - mse: 10.9176 - val_loss: 37.2434 - val_mae: 3.4673 - val_mse: 37.2434\n",
            "Epoch 516/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.4314 - mae: 2.4929 - mse: 12.4314 - val_loss: 24.8680 - val_mae: 2.7191 - val_mse: 24.8680\n",
            "Epoch 517/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.4434 - mae: 2.6151 - mse: 13.4434 - val_loss: 22.3007 - val_mae: 2.7652 - val_mse: 22.3007\n",
            "Epoch 518/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.5933 - mae: 2.4517 - mse: 11.5933 - val_loss: 31.2496 - val_mae: 3.2907 - val_mse: 31.2496\n",
            "Epoch 519/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.8938 - mae: 2.2243 - mse: 8.8938 - val_loss: 22.1074 - val_mae: 2.8137 - val_mse: 22.1074\n",
            "Epoch 520/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.4420 - mae: 2.1984 - mse: 8.4420 - val_loss: 23.2883 - val_mae: 3.0649 - val_mse: 23.2883\n",
            "Epoch 521/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.2948 - mae: 2.0957 - mse: 8.2948 - val_loss: 24.2254 - val_mae: 2.9857 - val_mse: 24.2254\n",
            "Epoch 522/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.4922 - mae: 2.1059 - mse: 8.4922 - val_loss: 21.2599 - val_mae: 2.8960 - val_mse: 21.2599\n",
            "Epoch 523/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.0243 - mae: 2.4562 - mse: 11.0243 - val_loss: 21.9978 - val_mae: 2.7880 - val_mse: 21.9978\n",
            "Epoch 524/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8429 - mae: 2.0847 - mse: 7.8429 - val_loss: 20.8234 - val_mae: 2.9330 - val_mse: 20.8234\n",
            "Epoch 525/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.2469 - mae: 2.1195 - mse: 9.2469 - val_loss: 27.3863 - val_mae: 3.4127 - val_mse: 27.3863\n",
            "Epoch 526/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6940 - mae: 2.2440 - mse: 8.6940 - val_loss: 25.9284 - val_mae: 2.7723 - val_mse: 25.9284\n",
            "Epoch 527/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.9467 - mae: 2.6389 - mse: 14.9467 - val_loss: 46.3346 - val_mae: 4.4417 - val_mse: 46.3346\n",
            "Epoch 528/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.2436 - mae: 2.5794 - mse: 13.2436 - val_loss: 23.3595 - val_mae: 2.7912 - val_mse: 23.3595\n",
            "Epoch 529/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.8178 - mae: 2.0634 - mse: 7.8178 - val_loss: 41.2352 - val_mae: 3.7226 - val_mse: 41.2352\n",
            "Epoch 530/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.1410 - mae: 2.1977 - mse: 9.1410 - val_loss: 23.3779 - val_mae: 2.7292 - val_mse: 23.3779\n",
            "Epoch 531/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7416 - mae: 2.2988 - mse: 9.7416 - val_loss: 21.7051 - val_mae: 3.0484 - val_mse: 21.7051\n",
            "Epoch 532/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3108 - mae: 2.3033 - mse: 9.3108 - val_loss: 42.2718 - val_mae: 4.3209 - val_mse: 42.2718\n",
            "Epoch 533/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3669 - mae: 2.2097 - mse: 9.3669 - val_loss: 30.3504 - val_mae: 3.4497 - val_mse: 30.3504\n",
            "Epoch 534/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4419 - mae: 2.2636 - mse: 9.4419 - val_loss: 25.8272 - val_mae: 2.8901 - val_mse: 25.8272\n",
            "Epoch 535/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.6582 - mae: 2.2454 - mse: 9.6582 - val_loss: 20.2528 - val_mae: 2.6899 - val_mse: 20.2528\n",
            "Epoch 536/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.0817 - mae: 2.2795 - mse: 10.0817 - val_loss: 28.6397 - val_mae: 2.8385 - val_mse: 28.6397\n",
            "Epoch 537/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3916 - mae: 2.3529 - mse: 10.3916 - val_loss: 22.0432 - val_mae: 2.7494 - val_mse: 22.0432\n",
            "Epoch 538/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1123 - mae: 2.1162 - mse: 8.1123 - val_loss: 23.7955 - val_mae: 2.7882 - val_mse: 23.7955\n",
            "Epoch 539/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3106 - mae: 2.1117 - mse: 9.3106 - val_loss: 21.2741 - val_mae: 3.0040 - val_mse: 21.2741\n",
            "Epoch 540/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5228 - mae: 2.1885 - mse: 8.5228 - val_loss: 23.8132 - val_mae: 2.9814 - val_mse: 23.8132\n",
            "Epoch 541/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3365 - mae: 2.2790 - mse: 9.3365 - val_loss: 19.5236 - val_mae: 2.7848 - val_mse: 19.5236\n",
            "Epoch 542/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1227 - mae: 2.3130 - mse: 10.1227 - val_loss: 27.2488 - val_mae: 3.2555 - val_mse: 27.2488\n",
            "Epoch 543/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6825 - mae: 2.4904 - mse: 11.6825 - val_loss: 21.8305 - val_mae: 3.4690 - val_mse: 21.8305\n",
            "Epoch 544/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2105 - mae: 2.2342 - mse: 9.2105 - val_loss: 21.1133 - val_mae: 3.1213 - val_mse: 21.1133\n",
            "Epoch 545/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5525 - mae: 2.2341 - mse: 8.5525 - val_loss: 23.3796 - val_mae: 2.8678 - val_mse: 23.3796\n",
            "Epoch 546/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.6505 - mae: 2.3528 - mse: 10.6505 - val_loss: 20.2206 - val_mae: 2.7777 - val_mse: 20.2206\n",
            "Epoch 547/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3147 - mae: 2.2537 - mse: 9.3147 - val_loss: 36.2723 - val_mae: 3.7436 - val_mse: 36.2723\n",
            "Epoch 548/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7692 - mae: 2.3290 - mse: 9.7692 - val_loss: 22.1227 - val_mae: 2.9386 - val_mse: 22.1227\n",
            "Epoch 549/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.0999 - mae: 2.3734 - mse: 11.0999 - val_loss: 24.7418 - val_mae: 3.3791 - val_mse: 24.7418\n",
            "Epoch 550/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.0810 - mae: 2.1698 - mse: 9.0810 - val_loss: 22.5199 - val_mae: 2.5851 - val_mse: 22.5199\n",
            "Epoch 551/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.8359 - mae: 2.2696 - mse: 9.8359 - val_loss: 20.2698 - val_mae: 2.8315 - val_mse: 20.2698\n",
            "Epoch 552/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5013 - mae: 2.3206 - mse: 9.5013 - val_loss: 32.8892 - val_mae: 3.1401 - val_mse: 32.8892\n",
            "Epoch 553/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0442 - mae: 2.1283 - mse: 8.0442 - val_loss: 31.9689 - val_mae: 3.1025 - val_mse: 31.9689\n",
            "Epoch 554/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3753 - mae: 2.1080 - mse: 8.3753 - val_loss: 27.4490 - val_mae: 2.8511 - val_mse: 27.4490\n",
            "Epoch 555/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.1392 - mae: 2.2793 - mse: 10.1392 - val_loss: 23.8783 - val_mae: 2.8186 - val_mse: 23.8783\n",
            "Epoch 556/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2410 - mae: 2.2375 - mse: 9.2410 - val_loss: 46.9746 - val_mae: 4.4174 - val_mse: 46.9746\n",
            "Epoch 557/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7556 - mae: 2.2058 - mse: 8.7556 - val_loss: 20.1657 - val_mae: 2.6480 - val_mse: 20.1657\n",
            "Epoch 558/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2692 - mae: 2.1021 - mse: 9.2692 - val_loss: 34.6773 - val_mae: 3.8574 - val_mse: 34.6773\n",
            "Epoch 559/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.3965 - mae: 2.2732 - mse: 10.3965 - val_loss: 24.7404 - val_mae: 3.0158 - val_mse: 24.7404\n",
            "Epoch 560/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 11.4076 - mae: 2.5919 - mse: 11.4076 - val_loss: 17.5839 - val_mae: 2.8406 - val_mse: 17.5839\n",
            "Epoch 561/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2465 - mae: 2.1636 - mse: 8.2465 - val_loss: 22.0630 - val_mae: 2.9946 - val_mse: 22.0630\n",
            "Epoch 562/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.5166 - mae: 2.4508 - mse: 10.5166 - val_loss: 23.5872 - val_mae: 2.8542 - val_mse: 23.5872\n",
            "Epoch 563/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8139 - mae: 1.9054 - mse: 6.8139 - val_loss: 27.6810 - val_mae: 3.0850 - val_mse: 27.6810\n",
            "Epoch 564/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.5214 - mae: 2.2809 - mse: 11.5214 - val_loss: 21.3039 - val_mae: 2.6399 - val_mse: 21.3039\n",
            "Epoch 565/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.2808 - mae: 2.1501 - mse: 8.2808 - val_loss: 27.1064 - val_mae: 2.8126 - val_mse: 27.1064\n",
            "Epoch 566/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5925 - mae: 2.1229 - mse: 8.5925 - val_loss: 25.1595 - val_mae: 3.1507 - val_mse: 25.1595\n",
            "Epoch 567/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4928 - mae: 2.1389 - mse: 8.4928 - val_loss: 26.5893 - val_mae: 3.1325 - val_mse: 26.5893\n",
            "Epoch 568/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0088 - mae: 2.2499 - mse: 9.0088 - val_loss: 24.0772 - val_mae: 2.8927 - val_mse: 24.0772\n",
            "Epoch 569/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.3275 - mae: 2.2925 - mse: 10.3275 - val_loss: 27.0054 - val_mae: 3.0018 - val_mse: 27.0054\n",
            "Epoch 570/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.4488 - mae: 2.1597 - mse: 9.4488 - val_loss: 32.1983 - val_mae: 3.1341 - val_mse: 32.1983\n",
            "Epoch 571/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6345 - mae: 2.1791 - mse: 8.6345 - val_loss: 24.5625 - val_mae: 2.9660 - val_mse: 24.5625\n",
            "Epoch 572/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.4740 - mae: 2.4075 - mse: 10.4740 - val_loss: 22.1628 - val_mae: 3.0279 - val_mse: 22.1628\n",
            "Epoch 573/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4281 - mae: 2.5274 - mse: 11.4281 - val_loss: 30.4362 - val_mae: 2.8869 - val_mse: 30.4362\n",
            "Epoch 574/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.8277 - mae: 2.2076 - mse: 9.8277 - val_loss: 50.1497 - val_mae: 3.8571 - val_mse: 50.1497\n",
            "Epoch 575/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.2156 - mae: 2.5665 - mse: 12.2156 - val_loss: 42.5749 - val_mae: 3.7027 - val_mse: 42.5749\n",
            "Epoch 576/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3766 - mae: 2.1551 - mse: 9.3766 - val_loss: 23.1310 - val_mae: 3.0645 - val_mse: 23.1310\n",
            "Epoch 577/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.8498 - mae: 2.4168 - mse: 10.8498 - val_loss: 27.7240 - val_mae: 3.0002 - val_mse: 27.7240\n",
            "Epoch 578/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.2662 - mae: 2.2907 - mse: 10.2662 - val_loss: 22.5301 - val_mae: 2.8463 - val_mse: 22.5301\n",
            "Epoch 579/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.0965 - mae: 2.2026 - mse: 9.0965 - val_loss: 23.9727 - val_mae: 3.0047 - val_mse: 23.9727\n",
            "Epoch 580/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2441 - mae: 2.1095 - mse: 8.2441 - val_loss: 26.1960 - val_mae: 2.9040 - val_mse: 26.1960\n",
            "Epoch 581/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6776 - mae: 2.1488 - mse: 8.6776 - val_loss: 29.3054 - val_mae: 2.8747 - val_mse: 29.3054\n",
            "Epoch 582/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.6762 - mae: 2.5159 - mse: 11.6762 - val_loss: 24.8282 - val_mae: 3.3586 - val_mse: 24.8282\n",
            "Epoch 583/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.9976 - mae: 2.3140 - mse: 9.9976 - val_loss: 23.4065 - val_mae: 3.2363 - val_mse: 23.4065\n",
            "Epoch 584/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.8509 - mae: 2.3533 - mse: 10.8509 - val_loss: 36.7126 - val_mae: 3.7797 - val_mse: 36.7126\n",
            "Epoch 585/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5178 - mae: 2.2639 - mse: 10.5178 - val_loss: 37.7623 - val_mae: 3.9636 - val_mse: 37.7623\n",
            "Epoch 586/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4824 - mae: 1.9994 - mse: 7.4824 - val_loss: 23.0820 - val_mae: 3.1224 - val_mse: 23.0820\n",
            "Epoch 587/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.0233 - mae: 2.3657 - mse: 10.0233 - val_loss: 25.4697 - val_mae: 2.8769 - val_mse: 25.4697\n",
            "Epoch 588/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5852 - mae: 2.1174 - mse: 8.5852 - val_loss: 23.4484 - val_mae: 2.8463 - val_mse: 23.4484\n",
            "Epoch 589/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3267 - mae: 2.0946 - mse: 7.3267 - val_loss: 23.0829 - val_mae: 2.7778 - val_mse: 23.0829\n",
            "Epoch 590/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.1366 - mae: 2.3476 - mse: 10.1366 - val_loss: 28.4872 - val_mae: 3.5943 - val_mse: 28.4872\n",
            "Epoch 591/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1137 - mae: 2.0902 - mse: 8.1137 - val_loss: 35.7467 - val_mae: 3.7871 - val_mse: 35.7467\n",
            "Epoch 592/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3602 - mae: 2.2880 - mse: 9.3602 - val_loss: 20.9418 - val_mae: 2.8094 - val_mse: 20.9418\n",
            "Epoch 593/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3097 - mae: 2.3054 - mse: 11.3097 - val_loss: 25.2104 - val_mae: 3.0000 - val_mse: 25.2104\n",
            "Epoch 594/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5297 - mae: 2.1586 - mse: 8.5297 - val_loss: 23.9695 - val_mae: 3.1512 - val_mse: 23.9695\n",
            "Epoch 595/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.3114 - mae: 2.2554 - mse: 9.3114 - val_loss: 20.1701 - val_mae: 2.7632 - val_mse: 20.1701\n",
            "Epoch 596/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.5515 - mae: 2.2710 - mse: 9.5515 - val_loss: 26.5720 - val_mae: 3.3810 - val_mse: 26.5720\n",
            "Epoch 597/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.9421 - mae: 2.1858 - mse: 8.9421 - val_loss: 27.1463 - val_mae: 3.6653 - val_mse: 27.1463\n",
            "Epoch 598/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.7013 - mae: 2.2817 - mse: 8.7013 - val_loss: 22.9630 - val_mae: 2.6680 - val_mse: 22.9630\n",
            "Epoch 599/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.8002 - mae: 2.0955 - mse: 7.8002 - val_loss: 22.9795 - val_mae: 2.8685 - val_mse: 22.9795\n",
            "Epoch 600/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.6759 - mae: 2.1411 - mse: 8.6759 - val_loss: 27.9136 - val_mae: 3.6667 - val_mse: 27.9136\n",
            "Epoch 601/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.8012 - mae: 2.1353 - mse: 8.8012 - val_loss: 20.1874 - val_mae: 2.7785 - val_mse: 20.1874\n",
            "Epoch 602/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.7874 - mae: 2.0982 - mse: 8.7874 - val_loss: 49.1128 - val_mae: 4.3477 - val_mse: 49.1128\n",
            "Epoch 603/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.0583 - mae: 2.2437 - mse: 9.0583 - val_loss: 20.7459 - val_mae: 3.2274 - val_mse: 20.7459\n",
            "Epoch 604/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5801 - mae: 2.2456 - mse: 9.5801 - val_loss: 17.5031 - val_mae: 2.7595 - val_mse: 17.5031\n",
            "Epoch 605/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.6446 - mae: 2.2584 - mse: 9.6446 - val_loss: 22.8643 - val_mae: 3.3449 - val_mse: 22.8643\n",
            "Epoch 606/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.2677 - mae: 2.1443 - mse: 8.2677 - val_loss: 22.3585 - val_mae: 2.6907 - val_mse: 22.3585\n",
            "Epoch 607/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.7482 - mae: 2.3202 - mse: 9.7482 - val_loss: 36.9577 - val_mae: 3.8220 - val_mse: 36.9577\n",
            "Epoch 608/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.6848 - mae: 2.0802 - mse: 7.6848 - val_loss: 24.4570 - val_mae: 3.2350 - val_mse: 24.4570\n",
            "Epoch 609/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9140 - mae: 2.1240 - mse: 8.9140 - val_loss: 24.0731 - val_mae: 2.9157 - val_mse: 24.0731\n",
            "Epoch 610/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6296 - mae: 2.2059 - mse: 8.6296 - val_loss: 22.5913 - val_mae: 2.8989 - val_mse: 22.5913\n",
            "Epoch 611/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.7449 - mae: 2.1502 - mse: 8.7449 - val_loss: 18.8253 - val_mae: 2.7419 - val_mse: 18.8253\n",
            "Epoch 612/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.4443 - mae: 2.1728 - mse: 8.4443 - val_loss: 21.8826 - val_mae: 2.7546 - val_mse: 21.8826\n",
            "Epoch 613/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.8759 - mae: 2.2477 - mse: 8.8759 - val_loss: 25.4242 - val_mae: 2.6291 - val_mse: 25.4242\n",
            "Epoch 614/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 11.9552 - mae: 2.6646 - mse: 11.9552 - val_loss: 27.2540 - val_mae: 3.0081 - val_mse: 27.2540\n",
            "Epoch 615/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 8.5724 - mae: 2.0957 - mse: 8.5724 - val_loss: 29.6727 - val_mae: 2.9761 - val_mse: 29.6727\n",
            "Epoch 616/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.9117 - mae: 2.0996 - mse: 7.9117 - val_loss: 50.3679 - val_mae: 4.7009 - val_mse: 50.3679\n",
            "Epoch 617/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 12.2558 - mae: 2.6328 - mse: 12.2558 - val_loss: 29.4190 - val_mae: 3.4952 - val_mse: 29.4190\n",
            "Epoch 618/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.5898 - mae: 2.0557 - mse: 7.5898 - val_loss: 19.8832 - val_mae: 2.8426 - val_mse: 19.8832\n",
            "Epoch 619/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.9395 - mae: 2.1059 - mse: 8.9395 - val_loss: 25.6859 - val_mae: 3.4840 - val_mse: 25.6859\n",
            "Epoch 620/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.8967 - mae: 2.3807 - mse: 9.8967 - val_loss: 19.1241 - val_mae: 2.8074 - val_mse: 19.1241\n",
            "Epoch 621/900\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 10.1969 - mae: 2.3761 - mse: 10.1969 - val_loss: 17.3083 - val_mae: 2.7149 - val_mse: 17.3083\n",
            "Epoch 622/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.5819 - mae: 2.0636 - mse: 8.5819 - val_loss: 21.5871 - val_mae: 3.1251 - val_mse: 21.5871\n",
            "Epoch 623/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.7597 - mae: 2.3297 - mse: 9.7597 - val_loss: 30.0446 - val_mae: 3.1520 - val_mse: 30.0446\n",
            "Epoch 624/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.7415 - mae: 2.3335 - mse: 10.7415 - val_loss: 24.4643 - val_mae: 3.0216 - val_mse: 24.4643\n",
            "Epoch 625/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.9194 - mae: 2.3161 - mse: 9.9194 - val_loss: 32.8282 - val_mae: 3.1861 - val_mse: 32.8282\n",
            "Epoch 626/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.6892 - mae: 2.2243 - mse: 9.6892 - val_loss: 22.1575 - val_mae: 2.7040 - val_mse: 22.1575\n",
            "Epoch 627/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.2452 - mae: 2.2343 - mse: 9.2452 - val_loss: 24.5836 - val_mae: 3.0444 - val_mse: 24.5836\n",
            "Epoch 628/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.9886 - mae: 2.2567 - mse: 9.9886 - val_loss: 22.7972 - val_mae: 3.0955 - val_mse: 22.7972\n",
            "Epoch 629/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.0031 - mae: 2.1058 - mse: 9.0031 - val_loss: 24.2347 - val_mae: 2.7871 - val_mse: 24.2348\n",
            "Epoch 630/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6141 - mae: 2.2865 - mse: 8.6141 - val_loss: 19.6648 - val_mae: 2.8589 - val_mse: 19.6648\n",
            "Epoch 631/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.4454 - mae: 2.1916 - mse: 9.4454 - val_loss: 25.6688 - val_mae: 3.0405 - val_mse: 25.6688\n",
            "Epoch 632/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3486 - mae: 2.0387 - mse: 7.3486 - val_loss: 19.6730 - val_mae: 2.6641 - val_mse: 19.6730\n",
            "Epoch 633/900\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.4784 - mae: 2.3384 - mse: 10.4784 - val_loss: 21.4372 - val_mae: 2.8449 - val_mse: 21.4372\n",
            "Epoch 634/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.3055 - mae: 2.3037 - mse: 10.3055 - val_loss: 23.8214 - val_mae: 2.9018 - val_mse: 23.8214\n",
            "Epoch 635/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9560 - mae: 2.1870 - mse: 8.9560 - val_loss: 25.4450 - val_mae: 3.0046 - val_mse: 25.4450\n",
            "Epoch 636/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1980 - mae: 2.0789 - mse: 8.1980 - val_loss: 23.0946 - val_mae: 2.9020 - val_mse: 23.0946\n",
            "Epoch 637/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.7883 - mae: 2.0950 - mse: 8.7883 - val_loss: 23.5854 - val_mae: 2.8382 - val_mse: 23.5854\n",
            "Epoch 638/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.4880 - mae: 2.3556 - mse: 10.4880 - val_loss: 23.8626 - val_mae: 2.6707 - val_mse: 23.8626\n",
            "Epoch 639/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2512 - mae: 1.8649 - mse: 6.2512 - val_loss: 30.3036 - val_mae: 3.4071 - val_mse: 30.3036\n",
            "Epoch 640/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2660 - mae: 2.0984 - mse: 8.2660 - val_loss: 28.2987 - val_mae: 3.3842 - val_mse: 28.2987\n",
            "Epoch 641/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.7324 - mae: 2.1436 - mse: 8.7324 - val_loss: 26.1131 - val_mae: 2.8302 - val_mse: 26.1131\n",
            "Epoch 642/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.2127 - mae: 2.5919 - mse: 13.2127 - val_loss: 21.9344 - val_mae: 2.6922 - val_mse: 21.9344\n",
            "Epoch 643/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9651 - mae: 2.0966 - mse: 7.9651 - val_loss: 22.3890 - val_mae: 2.7970 - val_mse: 22.3890\n",
            "Epoch 644/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6079 - mae: 2.5114 - mse: 10.6079 - val_loss: 27.2009 - val_mae: 2.8836 - val_mse: 27.2009\n",
            "Epoch 645/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7957 - mae: 2.3121 - mse: 9.7957 - val_loss: 31.7320 - val_mae: 2.9377 - val_mse: 31.7320\n",
            "Epoch 646/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2023 - mae: 2.5832 - mse: 12.2023 - val_loss: 26.2067 - val_mae: 3.6330 - val_mse: 26.2067\n",
            "Epoch 647/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.1220 - mae: 2.1037 - mse: 8.1220 - val_loss: 30.9480 - val_mae: 2.9659 - val_mse: 30.9480\n",
            "Epoch 648/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0543 - mae: 2.1221 - mse: 9.0543 - val_loss: 35.9070 - val_mae: 3.3283 - val_mse: 35.9070\n",
            "Epoch 649/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.7150 - mae: 2.6664 - mse: 13.7150 - val_loss: 21.8626 - val_mae: 3.0786 - val_mse: 21.8626\n",
            "Epoch 650/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.7568 - mae: 1.9150 - mse: 6.7568 - val_loss: 21.8495 - val_mae: 2.7003 - val_mse: 21.8495\n",
            "Epoch 651/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.4050 - mae: 2.2175 - mse: 8.4050 - val_loss: 31.0873 - val_mae: 3.2536 - val_mse: 31.0873\n",
            "Epoch 652/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7889 - mae: 2.4103 - mse: 9.7889 - val_loss: 30.2132 - val_mae: 3.3372 - val_mse: 30.2132\n",
            "Epoch 653/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.8792 - mae: 2.0943 - mse: 7.8792 - val_loss: 24.6009 - val_mae: 3.3282 - val_mse: 24.6009\n",
            "Epoch 654/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.4606 - mae: 2.2432 - mse: 8.4606 - val_loss: 22.0582 - val_mae: 3.2399 - val_mse: 22.0582\n",
            "Epoch 655/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5461 - mae: 2.1884 - mse: 8.5461 - val_loss: 26.6816 - val_mae: 3.0556 - val_mse: 26.6816\n",
            "Epoch 656/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.3616 - mae: 2.3090 - mse: 10.3616 - val_loss: 39.5666 - val_mae: 3.9788 - val_mse: 39.5666\n",
            "Epoch 657/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6441 - mae: 2.2856 - mse: 9.6441 - val_loss: 22.4980 - val_mae: 2.8709 - val_mse: 22.4980\n",
            "Epoch 658/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.0365 - mae: 2.2140 - mse: 10.0365 - val_loss: 21.2613 - val_mae: 2.7107 - val_mse: 21.2613\n",
            "Epoch 659/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.1126 - mae: 2.2769 - mse: 10.1126 - val_loss: 28.5715 - val_mae: 2.9634 - val_mse: 28.5715\n",
            "Epoch 660/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1962 - mae: 2.0194 - mse: 7.1962 - val_loss: 20.0326 - val_mae: 2.6949 - val_mse: 20.0326\n",
            "Epoch 661/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.8892 - mae: 2.3636 - mse: 11.8892 - val_loss: 69.9014 - val_mae: 5.5490 - val_mse: 69.9014\n",
            "Epoch 662/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9810 - mae: 2.2465 - mse: 8.9810 - val_loss: 25.1420 - val_mae: 2.8088 - val_mse: 25.1420\n",
            "Epoch 663/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.5065 - mae: 2.1828 - mse: 8.5065 - val_loss: 25.8505 - val_mae: 3.0344 - val_mse: 25.8505\n",
            "Epoch 664/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.7606 - mae: 2.0716 - mse: 7.7606 - val_loss: 23.8744 - val_mae: 2.8891 - val_mse: 23.8744\n",
            "Epoch 665/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0695 - mae: 2.0627 - mse: 9.0695 - val_loss: 35.4944 - val_mae: 3.3724 - val_mse: 35.4944\n",
            "Epoch 666/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3350 - mae: 2.0464 - mse: 7.3350 - val_loss: 25.9421 - val_mae: 3.2765 - val_mse: 25.9421\n",
            "Epoch 667/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6165 - mae: 2.1529 - mse: 8.6165 - val_loss: 22.2754 - val_mae: 2.6720 - val_mse: 22.2754\n",
            "Epoch 668/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.4699 - mae: 2.3752 - mse: 9.4699 - val_loss: 22.4234 - val_mae: 2.9026 - val_mse: 22.4234\n",
            "Epoch 669/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.9420 - mae: 2.1927 - mse: 8.9420 - val_loss: 24.2072 - val_mae: 2.8811 - val_mse: 24.2072\n",
            "Epoch 670/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2207 - mae: 2.0253 - mse: 7.2207 - val_loss: 24.1679 - val_mae: 3.0287 - val_mse: 24.1679\n",
            "Epoch 671/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7924 - mae: 2.1017 - mse: 8.7924 - val_loss: 24.2667 - val_mae: 3.2714 - val_mse: 24.2667\n",
            "Epoch 672/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.4025 - mae: 2.4369 - mse: 10.4025 - val_loss: 21.5118 - val_mae: 3.3935 - val_mse: 21.5118\n",
            "Epoch 673/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3513 - mae: 2.4452 - mse: 11.3513 - val_loss: 22.8620 - val_mae: 2.9983 - val_mse: 22.8620\n",
            "Epoch 674/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.7377 - mae: 2.0482 - mse: 7.7377 - val_loss: 24.5169 - val_mae: 3.4992 - val_mse: 24.5169\n",
            "Epoch 675/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2165 - mae: 2.0822 - mse: 8.2165 - val_loss: 21.3365 - val_mae: 2.8659 - val_mse: 21.3365\n",
            "Epoch 676/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.6474 - mae: 2.2418 - mse: 10.6474 - val_loss: 22.5242 - val_mae: 2.9687 - val_mse: 22.5242\n",
            "Epoch 677/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4230 - mae: 2.0903 - mse: 8.4230 - val_loss: 22.2391 - val_mae: 2.7264 - val_mse: 22.2391\n",
            "Epoch 678/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7445 - mae: 2.1289 - mse: 8.7445 - val_loss: 18.9343 - val_mae: 2.8185 - val_mse: 18.9343\n",
            "Epoch 679/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3875 - mae: 2.0121 - mse: 7.3875 - val_loss: 22.6774 - val_mae: 2.9978 - val_mse: 22.6774\n",
            "Epoch 680/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4361 - mae: 2.1170 - mse: 8.4361 - val_loss: 27.3248 - val_mae: 3.5828 - val_mse: 27.3248\n",
            "Epoch 681/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7811 - mae: 2.1859 - mse: 8.7811 - val_loss: 25.7472 - val_mae: 3.5514 - val_mse: 25.7472\n",
            "Epoch 682/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.7477 - mae: 2.3179 - mse: 10.7477 - val_loss: 20.9372 - val_mae: 2.9758 - val_mse: 20.9372\n",
            "Epoch 683/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.8167 - mae: 2.2353 - mse: 8.8167 - val_loss: 25.2095 - val_mae: 2.8941 - val_mse: 25.2095\n",
            "Epoch 684/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.0355 - mae: 2.3607 - mse: 11.0355 - val_loss: 19.0477 - val_mae: 2.9448 - val_mse: 19.0477\n",
            "Epoch 685/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.1160 - mae: 2.1646 - mse: 9.1160 - val_loss: 128.6398 - val_mae: 8.0533 - val_mse: 128.6398\n",
            "Epoch 686/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.8679 - mae: 2.2849 - mse: 8.8679 - val_loss: 22.2409 - val_mae: 2.5942 - val_mse: 22.2409\n",
            "Epoch 687/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.2160 - mae: 2.3403 - mse: 11.2160 - val_loss: 32.9832 - val_mae: 3.2663 - val_mse: 32.9832\n",
            "Epoch 688/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6595 - mae: 2.1378 - mse: 8.6595 - val_loss: 22.3294 - val_mae: 2.7506 - val_mse: 22.3294\n",
            "Epoch 689/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0201 - mae: 2.1357 - mse: 8.0201 - val_loss: 20.7886 - val_mae: 2.8755 - val_mse: 20.7886\n",
            "Epoch 690/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.9557 - mae: 2.1942 - mse: 8.9557 - val_loss: 25.3283 - val_mae: 3.4801 - val_mse: 25.3283\n",
            "Epoch 691/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2339 - mae: 2.0888 - mse: 7.2339 - val_loss: 23.1221 - val_mae: 3.4258 - val_mse: 23.1221\n",
            "Epoch 692/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7893 - mae: 2.2559 - mse: 8.7893 - val_loss: 20.3654 - val_mae: 3.0895 - val_mse: 20.3654\n",
            "Epoch 693/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.2991 - mae: 2.2984 - mse: 9.2991 - val_loss: 20.1319 - val_mae: 2.5475 - val_mse: 20.1319\n",
            "Epoch 694/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9620 - mae: 2.0709 - mse: 7.9620 - val_loss: 24.6804 - val_mae: 2.9055 - val_mse: 24.6804\n",
            "Epoch 695/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.8161 - mae: 2.0118 - mse: 6.8161 - val_loss: 23.5265 - val_mae: 3.2371 - val_mse: 23.5265\n",
            "Epoch 696/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2791 - mae: 2.0607 - mse: 8.2791 - val_loss: 24.2681 - val_mae: 3.5429 - val_mse: 24.2681\n",
            "Epoch 697/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8336 - mae: 1.9373 - mse: 6.8336 - val_loss: 28.1069 - val_mae: 3.8566 - val_mse: 28.1069\n",
            "Epoch 698/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.0438 - mae: 2.2986 - mse: 10.0438 - val_loss: 41.9570 - val_mae: 3.5358 - val_mse: 41.9570\n",
            "Epoch 699/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.2605 - mae: 2.2158 - mse: 9.2605 - val_loss: 20.9849 - val_mae: 2.9793 - val_mse: 20.9849\n",
            "Epoch 700/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6804 - mae: 2.0653 - mse: 7.6804 - val_loss: 23.0021 - val_mae: 3.1674 - val_mse: 23.0021\n",
            "Epoch 701/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6250 - mae: 2.1662 - mse: 8.6250 - val_loss: 43.8908 - val_mae: 4.0763 - val_mse: 43.8908\n",
            "Epoch 702/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3862 - mae: 2.0943 - mse: 8.3862 - val_loss: 19.9148 - val_mae: 2.8884 - val_mse: 19.9148\n",
            "Epoch 703/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6240 - mae: 2.1382 - mse: 8.6240 - val_loss: 26.1066 - val_mae: 2.8553 - val_mse: 26.1066\n",
            "Epoch 704/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8896 - mae: 2.0898 - mse: 7.8896 - val_loss: 28.2695 - val_mae: 3.0113 - val_mse: 28.2695\n",
            "Epoch 705/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6330 - mae: 2.0170 - mse: 7.6330 - val_loss: 22.8751 - val_mae: 3.1641 - val_mse: 22.8751\n",
            "Epoch 706/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.8010 - mae: 1.9800 - mse: 6.8010 - val_loss: 71.8666 - val_mae: 5.6012 - val_mse: 71.8666\n",
            "Epoch 707/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.8621 - mae: 2.0426 - mse: 7.8621 - val_loss: 43.8826 - val_mae: 4.4228 - val_mse: 43.8826\n",
            "Epoch 708/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.1602 - mae: 2.2433 - mse: 9.1602 - val_loss: 27.7945 - val_mae: 2.9380 - val_mse: 27.7945\n",
            "Epoch 709/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.3705 - mae: 2.1826 - mse: 8.3705 - val_loss: 23.5223 - val_mae: 2.7149 - val_mse: 23.5223\n",
            "Epoch 710/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1666 - mae: 1.9604 - mse: 7.1666 - val_loss: 22.4840 - val_mae: 2.5907 - val_mse: 22.4840\n",
            "Epoch 711/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 14.5301 - mae: 2.3160 - mse: 14.5301 - val_loss: 30.4703 - val_mae: 2.8870 - val_mse: 30.4702\n",
            "Epoch 712/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6253 - mae: 2.0579 - mse: 7.6253 - val_loss: 20.4571 - val_mae: 2.6528 - val_mse: 20.4571\n",
            "Epoch 713/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8858 - mae: 2.2435 - mse: 8.8858 - val_loss: 24.4814 - val_mae: 2.6934 - val_mse: 24.4814\n",
            "Epoch 714/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.0163 - mae: 2.1459 - mse: 8.0163 - val_loss: 19.9631 - val_mae: 2.8639 - val_mse: 19.9631\n",
            "Epoch 715/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.3122 - mae: 2.1072 - mse: 8.3122 - val_loss: 19.4956 - val_mae: 2.5375 - val_mse: 19.4956\n",
            "Epoch 716/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.7222 - mae: 2.0728 - mse: 7.7222 - val_loss: 22.4915 - val_mae: 2.9423 - val_mse: 22.4915\n",
            "Epoch 717/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.3384 - mae: 2.0351 - mse: 7.3384 - val_loss: 25.7635 - val_mae: 2.6231 - val_mse: 25.7635\n",
            "Epoch 718/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.3335 - mae: 2.3179 - mse: 11.3335 - val_loss: 30.1603 - val_mae: 3.4906 - val_mse: 30.1603\n",
            "Epoch 719/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1562 - mae: 2.1168 - mse: 8.1562 - val_loss: 22.1079 - val_mae: 2.6689 - val_mse: 22.1079\n",
            "Epoch 720/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.6428 - mae: 2.5067 - mse: 10.6428 - val_loss: 18.4852 - val_mae: 2.7331 - val_mse: 18.4852\n",
            "Epoch 721/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6896 - mae: 1.9843 - mse: 7.6896 - val_loss: 39.3416 - val_mae: 4.1537 - val_mse: 39.3416\n",
            "Epoch 722/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8635 - mae: 2.1405 - mse: 7.8635 - val_loss: 28.6035 - val_mae: 3.4396 - val_mse: 28.6035\n",
            "Epoch 723/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.4019 - mae: 2.0358 - mse: 8.4019 - val_loss: 33.3157 - val_mae: 3.8011 - val_mse: 33.3157\n",
            "Epoch 724/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3005 - mae: 2.3644 - mse: 9.3005 - val_loss: 18.8614 - val_mae: 2.8531 - val_mse: 18.8614\n",
            "Epoch 725/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.1765 - mae: 2.4060 - mse: 11.1765 - val_loss: 17.3861 - val_mae: 2.6734 - val_mse: 17.3861\n",
            "Epoch 726/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.8701 - mae: 2.0501 - mse: 7.8701 - val_loss: 36.5616 - val_mae: 4.8277 - val_mse: 36.5616\n",
            "Epoch 727/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.7372 - mae: 2.0879 - mse: 7.7372 - val_loss: 23.8089 - val_mae: 2.8810 - val_mse: 23.8089\n",
            "Epoch 728/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6413 - mae: 2.1136 - mse: 8.6413 - val_loss: 19.7096 - val_mae: 2.5389 - val_mse: 19.7096\n",
            "Epoch 729/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7643 - mae: 1.9880 - mse: 6.7643 - val_loss: 28.0672 - val_mae: 3.5346 - val_mse: 28.0672\n",
            "Epoch 730/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.0083 - mae: 2.4169 - mse: 11.0083 - val_loss: 23.2398 - val_mae: 3.0926 - val_mse: 23.2398\n",
            "Epoch 731/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5637 - mae: 2.3602 - mse: 9.5637 - val_loss: 23.5223 - val_mae: 2.6657 - val_mse: 23.5223\n",
            "Epoch 732/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.6414 - mae: 2.2270 - mse: 8.6414 - val_loss: 33.2916 - val_mae: 3.2286 - val_mse: 33.2916\n",
            "Epoch 733/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.9085 - mae: 2.3744 - mse: 10.9085 - val_loss: 20.3078 - val_mae: 2.5690 - val_mse: 20.3078\n",
            "Epoch 734/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7567 - mae: 2.5024 - mse: 10.7567 - val_loss: 29.9372 - val_mae: 4.2346 - val_mse: 29.9372\n",
            "Epoch 735/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6375 - mae: 2.1489 - mse: 9.6375 - val_loss: 22.8107 - val_mae: 3.0424 - val_mse: 22.8107\n",
            "Epoch 736/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.2638 - mae: 2.3458 - mse: 9.2638 - val_loss: 21.9299 - val_mae: 2.5812 - val_mse: 21.9299\n",
            "Epoch 737/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.7408 - mae: 2.3145 - mse: 9.7408 - val_loss: 21.3349 - val_mae: 2.6549 - val_mse: 21.3349\n",
            "Epoch 738/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0532 - mae: 2.1550 - mse: 8.0532 - val_loss: 35.2316 - val_mae: 3.3964 - val_mse: 35.2316\n",
            "Epoch 739/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.0038 - mae: 1.8712 - mse: 6.0038 - val_loss: 21.1969 - val_mae: 2.5377 - val_mse: 21.1969\n",
            "Epoch 740/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.4310 - mae: 2.2568 - mse: 11.4310 - val_loss: 34.5261 - val_mae: 4.7268 - val_mse: 34.5261\n",
            "Epoch 741/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.9486 - mae: 2.0517 - mse: 7.9486 - val_loss: 28.9033 - val_mae: 4.1382 - val_mse: 28.9033\n",
            "Epoch 742/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.7371 - mae: 2.4244 - mse: 10.7371 - val_loss: 17.0947 - val_mae: 2.6896 - val_mse: 17.0947\n",
            "Epoch 743/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.4745 - mae: 2.2225 - mse: 9.4745 - val_loss: 19.3921 - val_mae: 2.7374 - val_mse: 19.3921\n",
            "Epoch 744/900\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 7.9866 - mae: 2.1017 - mse: 7.9866 - val_loss: 26.1276 - val_mae: 3.8245 - val_mse: 26.1276\n",
            "Epoch 745/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.4089 - mae: 2.2177 - mse: 9.4089 - val_loss: 21.5713 - val_mae: 2.5235 - val_mse: 21.5713\n",
            "Epoch 746/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.8801 - mae: 2.2642 - mse: 9.8801 - val_loss: 81.3914 - val_mae: 6.1981 - val_mse: 81.3914\n",
            "Epoch 747/900\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 9.5582 - mae: 2.1660 - mse: 9.5582 - val_loss: 42.9949 - val_mae: 4.6147 - val_mse: 42.9949\n",
            "Epoch 748/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.6226 - mae: 2.2439 - mse: 9.6226 - val_loss: 22.3966 - val_mae: 2.7095 - val_mse: 22.3966\n",
            "Epoch 749/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.9537 - mae: 1.9715 - mse: 6.9537 - val_loss: 19.3857 - val_mae: 2.7401 - val_mse: 19.3857\n",
            "Epoch 750/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.6607 - mae: 1.9522 - mse: 6.6607 - val_loss: 24.1379 - val_mae: 2.6822 - val_mse: 24.1379\n",
            "Epoch 751/900\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 8.2777 - mae: 2.1485 - mse: 8.2777 - val_loss: 20.7659 - val_mae: 2.6736 - val_mse: 20.7659\n",
            "Epoch 752/900\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.1451 - mae: 2.4266 - mse: 10.1451 - val_loss: 23.4618 - val_mae: 2.5808 - val_mse: 23.4618\n",
            "Epoch 753/900\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 7.0995 - mae: 1.9875 - mse: 7.0995 - val_loss: 34.9616 - val_mae: 4.7291 - val_mse: 34.9616\n",
            "Epoch 754/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.0645 - mae: 2.4881 - mse: 12.0645 - val_loss: 25.4233 - val_mae: 3.1836 - val_mse: 25.4233\n",
            "Epoch 755/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7.8368 - mae: 1.9861 - mse: 7.8368 - val_loss: 26.6748 - val_mae: 3.0078 - val_mse: 26.6748\n",
            "Epoch 756/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.6795 - mae: 2.0373 - mse: 7.6795 - val_loss: 30.5769 - val_mae: 4.0300 - val_mse: 30.5769\n",
            "Epoch 757/900\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 8.3399 - mae: 2.0539 - mse: 8.3399 - val_loss: 28.3139 - val_mae: 3.3890 - val_mse: 28.3139\n",
            "Epoch 758/900\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 8.1785 - mae: 2.0473 - mse: 8.1785 - val_loss: 20.4784 - val_mae: 2.4303 - val_mse: 20.4784\n",
            "Epoch 759/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 10.1741 - mae: 2.3744 - mse: 10.1741 - val_loss: 24.2555 - val_mae: 3.6184 - val_mse: 24.2555\n",
            "Epoch 760/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.3067 - mae: 2.2953 - mse: 9.3067 - val_loss: 21.0306 - val_mae: 2.5979 - val_mse: 21.0306\n",
            "Epoch 761/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.7835 - mae: 2.0399 - mse: 7.7835 - val_loss: 18.9331 - val_mae: 2.6261 - val_mse: 18.9331\n",
            "Epoch 762/900\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 8.1801 - mae: 2.1299 - mse: 8.1801 - val_loss: 23.9306 - val_mae: 2.9457 - val_mse: 23.9306\n",
            "Epoch 763/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.9159 - mae: 2.2173 - mse: 8.9159 - val_loss: 22.5187 - val_mae: 2.8746 - val_mse: 22.5187\n",
            "Epoch 764/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.3144 - mae: 2.2002 - mse: 9.3144 - val_loss: 30.1163 - val_mae: 3.2919 - val_mse: 30.1163\n",
            "Epoch 765/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 10.5726 - mae: 2.3519 - mse: 10.5726 - val_loss: 24.5088 - val_mae: 3.5245 - val_mse: 24.5088\n",
            "Epoch 766/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.4735 - mae: 1.9220 - mse: 6.4735 - val_loss: 23.5177 - val_mae: 3.1061 - val_mse: 23.5177\n",
            "Epoch 767/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.3455 - mae: 2.0822 - mse: 8.3455 - val_loss: 28.6316 - val_mae: 3.4192 - val_mse: 28.6316\n",
            "Epoch 768/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.0173 - mae: 2.0977 - mse: 8.0173 - val_loss: 19.7539 - val_mae: 2.9375 - val_mse: 19.7539\n",
            "Epoch 769/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9797 - mae: 2.2985 - mse: 8.9797 - val_loss: 26.5280 - val_mae: 3.4623 - val_mse: 26.5280\n",
            "Epoch 770/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.7306 - mae: 2.1033 - mse: 7.7306 - val_loss: 27.9123 - val_mae: 3.5369 - val_mse: 27.9123\n",
            "Epoch 771/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.1623 - mae: 2.2247 - mse: 9.1623 - val_loss: 19.3251 - val_mae: 2.9424 - val_mse: 19.3251\n",
            "Epoch 772/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 10.2554 - mae: 2.2259 - mse: 10.2554 - val_loss: 31.1929 - val_mae: 4.3258 - val_mse: 31.1929\n",
            "Epoch 773/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.8941 - mae: 2.2866 - mse: 9.8941 - val_loss: 21.6391 - val_mae: 3.0534 - val_mse: 21.6391\n",
            "Epoch 774/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.7279 - mae: 2.2785 - mse: 8.7279 - val_loss: 22.9001 - val_mae: 3.4096 - val_mse: 22.9001\n",
            "Epoch 775/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2584 - mae: 2.1172 - mse: 8.2584 - val_loss: 21.8474 - val_mae: 3.1660 - val_mse: 21.8474\n",
            "Epoch 776/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.0484 - mae: 2.2962 - mse: 9.0484 - val_loss: 23.8669 - val_mae: 3.2711 - val_mse: 23.8669\n",
            "Epoch 777/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8650 - mae: 1.9276 - mse: 6.8650 - val_loss: 28.7166 - val_mae: 3.1244 - val_mse: 28.7166\n",
            "Epoch 778/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.5892 - mae: 2.3094 - mse: 10.5892 - val_loss: 25.4600 - val_mae: 2.9080 - val_mse: 25.4600\n",
            "Epoch 779/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.1416 - mae: 2.1759 - mse: 8.1416 - val_loss: 22.0322 - val_mae: 2.9973 - val_mse: 22.0322\n",
            "Epoch 780/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.9220 - mae: 2.1186 - mse: 7.9220 - val_loss: 36.1262 - val_mae: 4.2327 - val_mse: 36.1262\n",
            "Epoch 781/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2144 - mae: 2.0061 - mse: 8.2144 - val_loss: 29.2923 - val_mae: 4.0489 - val_mse: 29.2923\n",
            "Epoch 782/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.2404 - mae: 2.2965 - mse: 10.2404 - val_loss: 24.3548 - val_mae: 3.0322 - val_mse: 24.3548\n",
            "Epoch 783/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7450 - mae: 2.1586 - mse: 8.7450 - val_loss: 36.1638 - val_mae: 3.8028 - val_mse: 36.1638\n",
            "Epoch 784/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.0413 - mae: 2.2191 - mse: 12.0413 - val_loss: 29.1039 - val_mae: 3.6451 - val_mse: 29.1039\n",
            "Epoch 785/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.3942 - mae: 1.8500 - mse: 6.3942 - val_loss: 25.9326 - val_mae: 3.1864 - val_mse: 25.9326\n",
            "Epoch 786/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2707 - mae: 2.3719 - mse: 9.2707 - val_loss: 21.6474 - val_mae: 2.9802 - val_mse: 21.6474\n",
            "Epoch 787/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.2031 - mae: 2.2858 - mse: 10.2031 - val_loss: 22.1345 - val_mae: 3.0579 - val_mse: 22.1345\n",
            "Epoch 788/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5443 - mae: 2.2907 - mse: 9.5443 - val_loss: 25.2275 - val_mae: 3.6056 - val_mse: 25.2275\n",
            "Epoch 789/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5362 - mae: 2.2277 - mse: 9.5362 - val_loss: 19.1469 - val_mae: 3.0302 - val_mse: 19.1469\n",
            "Epoch 790/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.7650 - mae: 1.9648 - mse: 6.7650 - val_loss: 20.5196 - val_mae: 2.8296 - val_mse: 20.5196\n",
            "Epoch 791/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.4435 - mae: 2.5241 - mse: 11.4435 - val_loss: 20.8326 - val_mae: 3.2535 - val_mse: 20.8326\n",
            "Epoch 792/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.9953 - mae: 1.9876 - mse: 7.9953 - val_loss: 19.2233 - val_mae: 2.8638 - val_mse: 19.2233\n",
            "Epoch 793/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7128 - mae: 2.0532 - mse: 8.7128 - val_loss: 26.8810 - val_mae: 2.9335 - val_mse: 26.8810\n",
            "Epoch 794/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.6338 - mae: 1.9259 - mse: 6.6338 - val_loss: 22.6095 - val_mae: 2.8291 - val_mse: 22.6095\n",
            "Epoch 795/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.7529 - mae: 2.1850 - mse: 8.7529 - val_loss: 21.9914 - val_mae: 2.8391 - val_mse: 21.9914\n",
            "Epoch 796/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.1982 - mae: 2.1302 - mse: 8.1982 - val_loss: 18.0501 - val_mae: 2.8676 - val_mse: 18.0501\n",
            "Epoch 797/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3318 - mae: 2.0703 - mse: 7.3318 - val_loss: 29.0853 - val_mae: 3.5341 - val_mse: 29.0853\n",
            "Epoch 798/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5726 - mae: 2.3088 - mse: 9.5726 - val_loss: 37.2788 - val_mae: 4.1386 - val_mse: 37.2788\n",
            "Epoch 799/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1861 - mae: 2.3250 - mse: 10.1861 - val_loss: 15.5890 - val_mae: 2.5157 - val_mse: 15.5890\n",
            "Epoch 800/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.3805 - mae: 2.2746 - mse: 9.3805 - val_loss: 26.3110 - val_mae: 3.4187 - val_mse: 26.3110\n",
            "Epoch 801/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.5498 - mae: 2.1270 - mse: 9.5498 - val_loss: 21.0601 - val_mae: 2.7697 - val_mse: 21.0601\n",
            "Epoch 802/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.2095 - mae: 1.8562 - mse: 6.2095 - val_loss: 31.2612 - val_mae: 3.5897 - val_mse: 31.2612\n",
            "Epoch 803/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6331 - mae: 2.1021 - mse: 7.6331 - val_loss: 20.9813 - val_mae: 2.6703 - val_mse: 20.9813\n",
            "Epoch 804/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0732 - mae: 1.9160 - mse: 7.0732 - val_loss: 29.6149 - val_mae: 3.2037 - val_mse: 29.6149\n",
            "Epoch 805/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 10.8132 - mae: 2.3729 - mse: 10.8132 - val_loss: 22.7045 - val_mae: 2.6906 - val_mse: 22.7045\n",
            "Epoch 806/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5065 - mae: 2.3330 - mse: 9.5065 - val_loss: 21.9059 - val_mae: 2.5616 - val_mse: 21.9059\n",
            "Epoch 807/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.2460 - mae: 2.2530 - mse: 9.2460 - val_loss: 21.5142 - val_mae: 2.7920 - val_mse: 21.5142\n",
            "Epoch 808/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.2096 - mae: 2.3187 - mse: 9.2096 - val_loss: 25.6509 - val_mae: 2.6055 - val_mse: 25.6509\n",
            "Epoch 809/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2163 - mae: 2.1999 - mse: 8.2163 - val_loss: 21.2202 - val_mae: 2.6219 - val_mse: 21.2202\n",
            "Epoch 810/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5756 - mae: 2.2378 - mse: 8.5756 - val_loss: 19.2727 - val_mae: 2.8630 - val_mse: 19.2727\n",
            "Epoch 811/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.5832 - mae: 2.2203 - mse: 9.5832 - val_loss: 18.3759 - val_mae: 2.8156 - val_mse: 18.3759\n",
            "Epoch 812/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7627 - mae: 2.1043 - mse: 8.7627 - val_loss: 23.1827 - val_mae: 3.5706 - val_mse: 23.1827\n",
            "Epoch 813/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5880 - mae: 2.2274 - mse: 8.5880 - val_loss: 17.8102 - val_mae: 2.6196 - val_mse: 17.8102\n",
            "Epoch 814/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.6494 - mae: 2.3906 - mse: 10.6494 - val_loss: 23.7343 - val_mae: 2.5591 - val_mse: 23.7343\n",
            "Epoch 815/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7027 - mae: 2.1939 - mse: 8.7027 - val_loss: 23.0415 - val_mae: 2.5704 - val_mse: 23.0415\n",
            "Epoch 816/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2103 - mae: 1.9690 - mse: 7.2103 - val_loss: 20.8523 - val_mae: 2.7612 - val_mse: 20.8523\n",
            "Epoch 817/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6886 - mae: 2.0706 - mse: 7.6886 - val_loss: 22.0942 - val_mae: 3.2648 - val_mse: 22.0942\n",
            "Epoch 818/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.6120 - mae: 2.2158 - mse: 8.6120 - val_loss: 22.8025 - val_mae: 3.1519 - val_mse: 22.8025\n",
            "Epoch 819/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.6193 - mae: 2.1060 - mse: 7.6193 - val_loss: 23.4912 - val_mae: 2.7807 - val_mse: 23.4912\n",
            "Epoch 820/900\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.5413 - mae: 2.1848 - mse: 8.5413 - val_loss: 21.4964 - val_mae: 2.6816 - val_mse: 21.4964\n",
            "Epoch 821/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2679 - mae: 1.9955 - mse: 7.2679 - val_loss: 22.0534 - val_mae: 2.6392 - val_mse: 22.0534\n",
            "Epoch 822/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9137 - mae: 2.1300 - mse: 8.9137 - val_loss: 18.8834 - val_mae: 2.3783 - val_mse: 18.8834\n",
            "Epoch 823/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.8162 - mae: 2.0553 - mse: 8.8162 - val_loss: 37.4522 - val_mae: 3.6710 - val_mse: 37.4522\n",
            "Epoch 824/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.3113 - mae: 2.2223 - mse: 9.3113 - val_loss: 19.8565 - val_mae: 2.3927 - val_mse: 19.8565\n",
            "Epoch 825/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9319 - mae: 2.0309 - mse: 6.9319 - val_loss: 20.1958 - val_mae: 3.1711 - val_mse: 20.1958\n",
            "Epoch 826/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.7158 - mae: 2.1861 - mse: 8.7158 - val_loss: 21.0097 - val_mae: 2.8006 - val_mse: 21.0097\n",
            "Epoch 827/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.2501 - mae: 2.1043 - mse: 8.2501 - val_loss: 19.5645 - val_mae: 3.0145 - val_mse: 19.5645\n",
            "Epoch 828/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.3278 - mae: 2.3713 - mse: 9.3278 - val_loss: 18.8830 - val_mae: 2.7849 - val_mse: 18.8830\n",
            "Epoch 829/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.7445 - mae: 2.1621 - mse: 8.7445 - val_loss: 50.2967 - val_mae: 4.9212 - val_mse: 50.2967\n",
            "Epoch 830/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.9766 - mae: 2.5089 - mse: 11.9766 - val_loss: 20.1238 - val_mae: 3.1447 - val_mse: 20.1238\n",
            "Epoch 831/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.9181 - mae: 2.1007 - mse: 7.9181 - val_loss: 49.7239 - val_mae: 5.3084 - val_mse: 49.7239\n",
            "Epoch 832/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.4830 - mae: 2.1089 - mse: 7.4830 - val_loss: 25.4358 - val_mae: 3.3040 - val_mse: 25.4358\n",
            "Epoch 833/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.1378 - mae: 2.3872 - mse: 11.1378 - val_loss: 19.1094 - val_mae: 2.9861 - val_mse: 19.1094\n",
            "Epoch 834/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5583 - mae: 2.1955 - mse: 8.5583 - val_loss: 21.4647 - val_mae: 3.4299 - val_mse: 21.4647\n",
            "Epoch 835/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.1966 - mae: 2.3724 - mse: 10.1966 - val_loss: 20.1758 - val_mae: 2.7340 - val_mse: 20.1758\n",
            "Epoch 836/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.1443 - mae: 2.1549 - mse: 9.1443 - val_loss: 20.1138 - val_mae: 2.3773 - val_mse: 20.1138\n",
            "Epoch 837/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7128 - mae: 2.2650 - mse: 8.7128 - val_loss: 19.8721 - val_mae: 2.3856 - val_mse: 19.8721\n",
            "Epoch 838/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.3954 - mae: 2.2483 - mse: 9.3954 - val_loss: 18.2804 - val_mae: 2.4770 - val_mse: 18.2804\n",
            "Epoch 839/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.1911 - mae: 1.9895 - mse: 7.1911 - val_loss: 38.9782 - val_mae: 3.8024 - val_mse: 38.9782\n",
            "Epoch 840/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 11.4774 - mae: 2.2513 - mse: 11.4774 - val_loss: 30.2514 - val_mae: 3.1389 - val_mse: 30.2514\n",
            "Epoch 841/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.4890 - mae: 2.2127 - mse: 9.4890 - val_loss: 31.0714 - val_mae: 3.1269 - val_mse: 31.0714\n",
            "Epoch 842/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.7023 - mae: 2.1302 - mse: 7.7023 - val_loss: 18.1392 - val_mae: 2.6180 - val_mse: 18.1392\n",
            "Epoch 843/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6863 - mae: 2.2174 - mse: 8.6863 - val_loss: 22.3368 - val_mae: 2.9468 - val_mse: 22.3368\n",
            "Epoch 844/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.7932 - mae: 2.2276 - mse: 8.7932 - val_loss: 23.2589 - val_mae: 2.7722 - val_mse: 23.2589\n",
            "Epoch 845/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.0762 - mae: 2.1445 - mse: 8.0762 - val_loss: 24.3659 - val_mae: 2.8386 - val_mse: 24.3659\n",
            "Epoch 846/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8269 - mae: 1.9640 - mse: 6.8269 - val_loss: 16.8311 - val_mae: 2.5365 - val_mse: 16.8311\n",
            "Epoch 847/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.9446 - mae: 2.1468 - mse: 8.9446 - val_loss: 23.3274 - val_mae: 2.6114 - val_mse: 23.3274\n",
            "Epoch 848/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.1490 - mae: 1.9642 - mse: 7.1490 - val_loss: 19.7332 - val_mae: 2.8040 - val_mse: 19.7332\n",
            "Epoch 849/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.1319 - mae: 2.3903 - mse: 11.1319 - val_loss: 25.3127 - val_mae: 3.4482 - val_mse: 25.3127\n",
            "Epoch 850/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.0726 - mae: 2.1182 - mse: 10.0726 - val_loss: 32.7985 - val_mae: 3.5038 - val_mse: 32.7985\n",
            "Epoch 851/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.4993 - mae: 2.0909 - mse: 8.4993 - val_loss: 18.0647 - val_mae: 2.7239 - val_mse: 18.0647\n",
            "Epoch 852/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5015 - mae: 2.1194 - mse: 8.5015 - val_loss: 31.3602 - val_mae: 3.6779 - val_mse: 31.3602\n",
            "Epoch 853/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.0407 - mae: 2.0429 - mse: 8.0407 - val_loss: 57.1146 - val_mae: 5.4950 - val_mse: 57.1146\n",
            "Epoch 854/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1874 - mae: 1.9241 - mse: 7.1874 - val_loss: 26.8044 - val_mae: 3.0174 - val_mse: 26.8044\n",
            "Epoch 855/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.3307 - mae: 2.1737 - mse: 8.3307 - val_loss: 17.8436 - val_mae: 2.5215 - val_mse: 17.8436\n",
            "Epoch 856/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.6200 - mae: 2.2563 - mse: 9.6200 - val_loss: 32.1012 - val_mae: 3.2458 - val_mse: 32.1012\n",
            "Epoch 857/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.2880 - mae: 2.0411 - mse: 8.2880 - val_loss: 22.6132 - val_mae: 3.0753 - val_mse: 22.6133\n",
            "Epoch 858/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.0441 - mae: 1.9725 - mse: 7.0441 - val_loss: 17.7039 - val_mae: 2.6281 - val_mse: 17.7039\n",
            "Epoch 859/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.8041 - mae: 2.2107 - mse: 9.8041 - val_loss: 20.5160 - val_mae: 2.9488 - val_mse: 20.5160\n",
            "Epoch 860/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.2141 - mae: 2.0614 - mse: 7.2141 - val_loss: 21.9178 - val_mae: 3.4835 - val_mse: 21.9178\n",
            "Epoch 861/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.6022 - mae: 2.3645 - mse: 9.6022 - val_loss: 25.4769 - val_mae: 3.0460 - val_mse: 25.4769\n",
            "Epoch 862/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.8376 - mae: 2.0940 - mse: 7.8376 - val_loss: 19.3686 - val_mae: 3.0163 - val_mse: 19.3686\n",
            "Epoch 863/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.4064 - mae: 1.9967 - mse: 7.4064 - val_loss: 21.2878 - val_mae: 2.5458 - val_mse: 21.2878\n",
            "Epoch 864/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 12.9910 - mae: 2.4682 - mse: 12.9910 - val_loss: 20.1167 - val_mae: 3.2182 - val_mse: 20.1167\n",
            "Epoch 865/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.4333 - mae: 2.0858 - mse: 8.4333 - val_loss: 17.8642 - val_mae: 2.5152 - val_mse: 17.8642\n",
            "Epoch 866/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 9.7469 - mae: 2.2685 - mse: 9.7469 - val_loss: 25.6948 - val_mae: 2.9798 - val_mse: 25.6948\n",
            "Epoch 867/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3536 - mae: 2.0101 - mse: 7.3536 - val_loss: 20.8263 - val_mae: 2.6000 - val_mse: 20.8263\n",
            "Epoch 868/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.5065 - mae: 2.1388 - mse: 8.5065 - val_loss: 19.6624 - val_mae: 2.9966 - val_mse: 19.6624\n",
            "Epoch 869/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1405 - mae: 2.0060 - mse: 8.1405 - val_loss: 54.7574 - val_mae: 4.5665 - val_mse: 54.7574\n",
            "Epoch 870/900\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 10.7214 - mae: 2.3565 - mse: 10.7214 - val_loss: 28.1146 - val_mae: 3.9454 - val_mse: 28.1146\n",
            "Epoch 871/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.6801 - mae: 1.9326 - mse: 6.6801 - val_loss: 19.1400 - val_mae: 2.6764 - val_mse: 19.1400\n",
            "Epoch 872/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.8490 - mae: 2.1492 - mse: 7.8490 - val_loss: 26.8213 - val_mae: 3.1149 - val_mse: 26.8213\n",
            "Epoch 873/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.7620 - mae: 2.1361 - mse: 8.7620 - val_loss: 25.8580 - val_mae: 2.9954 - val_mse: 25.8580\n",
            "Epoch 874/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.2723 - mae: 1.9856 - mse: 7.2723 - val_loss: 20.0278 - val_mae: 2.4061 - val_mse: 20.0278\n",
            "Epoch 875/900\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.6583 - mae: 1.9802 - mse: 6.6583 - val_loss: 17.9645 - val_mae: 2.4867 - val_mse: 17.9645\n",
            "Epoch 876/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.2742 - mae: 2.1144 - mse: 9.2742 - val_loss: 21.6970 - val_mae: 2.7156 - val_mse: 21.6970\n",
            "Epoch 877/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.0301 - mae: 2.2150 - mse: 9.0301 - val_loss: 30.9922 - val_mae: 4.4888 - val_mse: 30.9922\n",
            "Epoch 878/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.4729 - mae: 2.2991 - mse: 9.4729 - val_loss: 25.0814 - val_mae: 2.9322 - val_mse: 25.0814\n",
            "Epoch 879/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.4105 - mae: 1.9082 - mse: 6.4105 - val_loss: 28.0872 - val_mae: 3.5968 - val_mse: 28.0872\n",
            "Epoch 880/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.2928 - mae: 2.0460 - mse: 7.2928 - val_loss: 18.0906 - val_mae: 2.4719 - val_mse: 18.0906\n",
            "Epoch 881/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 10.1862 - mae: 2.3998 - mse: 10.1862 - val_loss: 28.1174 - val_mae: 3.3207 - val_mse: 28.1174\n",
            "Epoch 882/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.2590 - mae: 2.0061 - mse: 7.2590 - val_loss: 25.2356 - val_mae: 2.8581 - val_mse: 25.2356\n",
            "Epoch 883/900\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.4798 - mae: 2.0001 - mse: 7.4798 - val_loss: 20.8609 - val_mae: 3.1030 - val_mse: 20.8609\n",
            "Epoch 884/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.1182 - mae: 1.9632 - mse: 7.1182 - val_loss: 27.3625 - val_mae: 3.8129 - val_mse: 27.3625\n",
            "Epoch 885/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.4497 - mae: 2.2799 - mse: 9.4497 - val_loss: 27.0962 - val_mae: 3.1004 - val_mse: 27.0962\n",
            "Epoch 886/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.7695 - mae: 2.2553 - mse: 9.7695 - val_loss: 19.1564 - val_mae: 2.6157 - val_mse: 19.1564\n",
            "Epoch 887/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7.2224 - mae: 2.0547 - mse: 7.2224 - val_loss: 18.8839 - val_mae: 2.6958 - val_mse: 18.8839\n",
            "Epoch 888/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.5159 - mae: 2.1545 - mse: 8.5159 - val_loss: 21.4769 - val_mae: 3.3470 - val_mse: 21.4769\n",
            "Epoch 889/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.1329 - mae: 2.1885 - mse: 8.1329 - val_loss: 21.3139 - val_mae: 3.3605 - val_mse: 21.3139\n",
            "Epoch 890/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.1919 - mae: 2.1078 - mse: 8.1919 - val_loss: 25.0267 - val_mae: 3.5552 - val_mse: 25.0267\n",
            "Epoch 891/900\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 10.5447 - mae: 2.4812 - mse: 10.5447 - val_loss: 24.2579 - val_mae: 3.3879 - val_mse: 24.2579\n",
            "Epoch 892/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.7754 - mae: 1.9610 - mse: 6.7754 - val_loss: 36.0940 - val_mae: 3.5717 - val_mse: 36.0940\n",
            "Epoch 893/900\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 10.1731 - mae: 2.3083 - mse: 10.1731 - val_loss: 19.3212 - val_mae: 2.4952 - val_mse: 19.3212\n",
            "Epoch 894/900\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 9.8649 - mae: 2.1677 - mse: 9.8649 - val_loss: 26.5826 - val_mae: 4.0662 - val_mse: 26.5826\n",
            "Epoch 895/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.5868 - mae: 2.1814 - mse: 9.5868 - val_loss: 24.5561 - val_mae: 3.2732 - val_mse: 24.5561\n",
            "Epoch 896/900\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 5.7843 - mae: 1.8484 - mse: 5.7843 - val_loss: 14.5105 - val_mae: 2.5727 - val_mse: 14.5105\n",
            "Epoch 897/900\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 8.1585 - mae: 2.1458 - mse: 8.1585 - val_loss: 16.8629 - val_mae: 2.4619 - val_mse: 16.8629\n",
            "Epoch 898/900\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.0551 - mae: 2.0125 - mse: 7.0551 - val_loss: 17.6396 - val_mae: 2.9193 - val_mse: 17.6396\n",
            "Epoch 899/900\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 9.0920 - mae: 2.1489 - mse: 9.0920 - val_loss: 57.6334 - val_mae: 5.4372 - val_mse: 57.6334\n",
            "Epoch 900/900\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.9476 - mae: 2.1381 - mse: 7.9476 - val_loss: 20.8076 - val_mae: 2.7426 - val_mse: 20.8076\n",
            "loss — -> 20.807579040527344\n",
            "mae — -> 2.742576837539673\n",
            "mse — -> 20.807579040527344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"bh1\",)\n",
        "# l1\n",
        "model.add(Dense( 39, activation='relu', input_shape=(13,),use_bias=True, bias_initializer='zeros'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# l2\n",
        "model.add(Dense(39, activation='relu',use_bias=True, bias_initializer='zeros'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "# model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n",
        "# model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# out\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=RMSprop(),\n",
        "    metrics=['mae','mse']\n",
        "    )\n",
        "\n",
        "learning_rate = 0.1\n",
        "batch_size = 50\n",
        "display_step = 5\n",
        "epochs = 100\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n",
        "# Model Eval\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "for i in range(len(score)):\n",
        "    print(f'{model.metrics_names[i]} — -> {score[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MvkgfrIlfKM",
        "outputId": "0b1bed15-dcf8-46ae-b45e-6b12e87f9693"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bh1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_185 (Dense)           (None, 39)                546       \n",
            "                                                                 \n",
            " batch_normalization_77 (Bat  (None, 39)               156       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 39)                1560      \n",
            "                                                                 \n",
            " batch_normalization_78 (Bat  (None, 39)               156       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 1)                 40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,458\n",
            "Trainable params: 2,302\n",
            "Non-trainable params: 156\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - 2s 33ms/step - loss: 577.6913 - mae: 22.3350 - mse: 577.6913 - val_loss: 1140.4037 - val_mae: 32.6882 - val_mse: 1140.4037\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 562.9901 - mae: 22.2344 - mse: 562.9901 - val_loss: 1030.1047 - val_mae: 31.0155 - val_mse: 1030.1047\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 555.3312 - mae: 22.1524 - mse: 555.3312 - val_loss: 934.0289 - val_mae: 29.4427 - val_mse: 934.0289\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 548.7581 - mae: 22.0689 - mse: 548.7581 - val_loss: 912.9036 - val_mae: 29.1535 - val_mse: 912.9036\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 542.7578 - mae: 21.9785 - mse: 542.7579 - val_loss: 868.5258 - val_mae: 28.3810 - val_mse: 868.5258\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 536.6193 - mae: 21.8858 - mse: 536.6193 - val_loss: 846.6923 - val_mae: 28.0272 - val_mse: 846.6923\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 530.9719 - mae: 21.7855 - mse: 530.9719 - val_loss: 818.0063 - val_mae: 27.5322 - val_mse: 818.0063\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 523.3654 - mae: 21.6745 - mse: 523.3654 - val_loss: 781.6827 - val_mae: 26.8724 - val_mse: 781.6827\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 516.8259 - mae: 21.5599 - mse: 516.8259 - val_loss: 749.7785 - val_mae: 26.2841 - val_mse: 749.7785\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 510.1108 - mae: 21.4380 - mse: 510.1108 - val_loss: 715.7424 - val_mae: 25.6376 - val_mse: 715.7424\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 502.8912 - mae: 21.3153 - mse: 502.8912 - val_loss: 708.4828 - val_mae: 25.5403 - val_mse: 708.4828\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 494.5573 - mae: 21.1803 - mse: 494.5573 - val_loss: 683.6375 - val_mae: 25.0693 - val_mse: 683.6375\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 489.1095 - mae: 21.0423 - mse: 489.1095 - val_loss: 668.3760 - val_mae: 24.7791 - val_mse: 668.3760\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 480.0544 - mae: 20.8928 - mse: 480.0544 - val_loss: 598.9325 - val_mae: 23.2834 - val_mse: 598.9325\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 473.3745 - mae: 20.7416 - mse: 473.3745 - val_loss: 610.5731 - val_mae: 23.6307 - val_mse: 610.5731\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 463.5962 - mae: 20.5866 - mse: 463.5962 - val_loss: 585.7394 - val_mae: 23.0880 - val_mse: 585.7394\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 458.2340 - mae: 20.4286 - mse: 458.2340 - val_loss: 558.4940 - val_mae: 22.5239 - val_mse: 558.4940\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 448.3872 - mae: 20.2630 - mse: 448.3872 - val_loss: 542.0313 - val_mae: 22.1816 - val_mse: 542.0313\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 439.6973 - mae: 20.0938 - mse: 439.6973 - val_loss: 542.0840 - val_mae: 22.2573 - val_mse: 542.0840\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 432.1485 - mae: 19.9116 - mse: 432.1485 - val_loss: 514.0407 - val_mae: 21.5981 - val_mse: 514.0407\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 422.5155 - mae: 19.7274 - mse: 422.5155 - val_loss: 476.4947 - val_mae: 20.6441 - val_mse: 476.4947\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 414.5829 - mae: 19.5382 - mse: 414.5829 - val_loss: 485.3248 - val_mae: 20.9683 - val_mse: 485.3248\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 406.2449 - mae: 19.3497 - mse: 406.2449 - val_loss: 496.9049 - val_mae: 21.2788 - val_mse: 496.9049\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 398.5662 - mae: 19.1444 - mse: 398.5662 - val_loss: 491.7535 - val_mae: 21.2230 - val_mse: 491.7535\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 388.4732 - mae: 18.9317 - mse: 388.4732 - val_loss: 504.8469 - val_mae: 21.5628 - val_mse: 504.8469\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 379.2370 - mae: 18.7248 - mse: 379.2370 - val_loss: 481.9397 - val_mae: 20.9971 - val_mse: 481.9397\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 369.0833 - mae: 18.4977 - mse: 369.0833 - val_loss: 517.6530 - val_mae: 21.8640 - val_mse: 517.6530\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 362.1927 - mae: 18.2734 - mse: 362.1927 - val_loss: 492.2030 - val_mae: 21.2458 - val_mse: 492.2030\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 350.7911 - mae: 18.0496 - mse: 350.7911 - val_loss: 442.8677 - val_mae: 19.9684 - val_mse: 442.8677\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 346.4261 - mae: 17.8176 - mse: 346.4261 - val_loss: 462.7913 - val_mae: 20.6750 - val_mse: 462.7913\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 334.0883 - mae: 17.5684 - mse: 334.0883 - val_loss: 428.5663 - val_mae: 19.8335 - val_mse: 428.5663\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 323.2135 - mae: 17.3141 - mse: 323.2135 - val_loss: 423.2270 - val_mae: 19.5832 - val_mse: 423.2270\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 313.3754 - mae: 17.0545 - mse: 313.3754 - val_loss: 408.4324 - val_mae: 19.2559 - val_mse: 408.4324\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 304.9110 - mae: 16.8212 - mse: 304.9110 - val_loss: 395.4209 - val_mae: 18.9855 - val_mse: 395.4209\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 298.9223 - mae: 16.5406 - mse: 298.9223 - val_loss: 365.4647 - val_mae: 18.2195 - val_mse: 365.4647\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 284.9577 - mae: 16.2579 - mse: 284.9577 - val_loss: 350.0580 - val_mae: 17.8218 - val_mse: 350.0580\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 278.3185 - mae: 15.9876 - mse: 278.3185 - val_loss: 358.9314 - val_mae: 18.1213 - val_mse: 358.9314\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 264.5700 - mae: 15.6861 - mse: 264.5701 - val_loss: 344.8727 - val_mae: 17.6691 - val_mse: 344.8727\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 257.7927 - mae: 15.4078 - mse: 257.7927 - val_loss: 327.6051 - val_mae: 17.2447 - val_mse: 327.6051\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 247.0885 - mae: 15.1035 - mse: 247.0885 - val_loss: 361.4744 - val_mae: 18.1096 - val_mse: 361.4744\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 239.5379 - mae: 14.8116 - mse: 239.5379 - val_loss: 347.1629 - val_mae: 17.7564 - val_mse: 347.1629\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 227.5683 - mae: 14.4992 - mse: 227.5683 - val_loss: 337.6463 - val_mae: 17.5435 - val_mse: 337.6463\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 218.1056 - mae: 14.1849 - mse: 218.1056 - val_loss: 349.4671 - val_mae: 17.9344 - val_mse: 349.4671\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 210.7315 - mae: 13.8630 - mse: 210.7315 - val_loss: 322.8061 - val_mae: 17.1929 - val_mse: 322.8061\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 202.3154 - mae: 13.5429 - mse: 202.3154 - val_loss: 330.7883 - val_mae: 17.4086 - val_mse: 330.7883\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 190.1660 - mae: 13.1953 - mse: 190.1660 - val_loss: 299.8577 - val_mae: 16.5332 - val_mse: 299.8577\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 183.3292 - mae: 12.8691 - mse: 183.3292 - val_loss: 269.9745 - val_mae: 15.6447 - val_mse: 269.9745\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 174.1692 - mae: 12.5278 - mse: 174.1692 - val_loss: 285.4257 - val_mae: 16.1229 - val_mse: 285.4257\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 166.0541 - mae: 12.1910 - mse: 166.0541 - val_loss: 269.3300 - val_mae: 15.6001 - val_mse: 269.3300\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 157.4106 - mae: 11.8523 - mse: 157.4106 - val_loss: 257.8025 - val_mae: 15.2201 - val_mse: 257.8025\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 150.8123 - mae: 11.4946 - mse: 150.8123 - val_loss: 240.4125 - val_mae: 14.5999 - val_mse: 240.4125\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 139.7214 - mae: 11.1405 - mse: 139.7214 - val_loss: 206.5004 - val_mae: 13.5713 - val_mse: 206.5004\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 133.0930 - mae: 10.7664 - mse: 133.0930 - val_loss: 223.7037 - val_mae: 13.9513 - val_mse: 223.7037\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 125.2134 - mae: 10.3827 - mse: 125.2134 - val_loss: 197.0847 - val_mae: 13.0292 - val_mse: 197.0847\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 115.5083 - mae: 10.0377 - mse: 115.5083 - val_loss: 161.2665 - val_mae: 11.7620 - val_mse: 161.2665\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 110.6230 - mae: 9.6736 - mse: 110.6230 - val_loss: 154.4660 - val_mae: 11.6395 - val_mse: 154.4660\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 100.8138 - mae: 9.3504 - mse: 100.8138 - val_loss: 124.8909 - val_mae: 10.1775 - val_mse: 124.8909\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 93.8376 - mae: 8.9280 - mse: 93.8376 - val_loss: 142.6626 - val_mae: 11.0039 - val_mse: 142.6626\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 87.7342 - mae: 8.5192 - mse: 87.7342 - val_loss: 102.2325 - val_mae: 9.1476 - val_mse: 102.2325\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 78.6291 - mae: 8.1080 - mse: 78.6291 - val_loss: 113.3476 - val_mae: 9.6754 - val_mse: 113.3476\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 72.7453 - mae: 7.7236 - mse: 72.7453 - val_loss: 77.2396 - val_mae: 7.6572 - val_mse: 77.2396\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 68.1677 - mae: 7.4772 - mse: 68.1677 - val_loss: 89.3065 - val_mae: 8.3042 - val_mse: 89.3065\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 61.5854 - mae: 6.9879 - mse: 61.5854 - val_loss: 64.3296 - val_mae: 6.8550 - val_mse: 64.3296\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 57.5424 - mae: 6.6211 - mse: 57.5424 - val_loss: 97.3681 - val_mae: 8.5098 - val_mse: 97.3681\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 49.9196 - mae: 6.2254 - mse: 49.9196 - val_loss: 98.5332 - val_mae: 8.6141 - val_mse: 98.5332\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 50.4445 - mae: 5.8933 - mse: 50.4445 - val_loss: 70.2893 - val_mae: 7.0710 - val_mse: 70.2893\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 43.9359 - mae: 5.5797 - mse: 43.9359 - val_loss: 61.9143 - val_mae: 6.3664 - val_mse: 61.9143\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 38.3000 - mae: 5.1819 - mse: 38.3000 - val_loss: 71.0977 - val_mae: 7.3006 - val_mse: 71.0977\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 33.7160 - mae: 4.8662 - mse: 33.7160 - val_loss: 75.8069 - val_mae: 7.3579 - val_mse: 75.8069\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 30.6160 - mae: 4.5033 - mse: 30.6160 - val_loss: 69.0785 - val_mae: 7.0198 - val_mse: 69.0785\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 30.6806 - mae: 4.2602 - mse: 30.6806 - val_loss: 36.3433 - val_mae: 4.1581 - val_mse: 36.3433\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 28.7216 - mae: 4.1789 - mse: 28.7216 - val_loss: 35.7147 - val_mae: 4.4849 - val_mse: 35.7147\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 22.7674 - mae: 3.7574 - mse: 22.7674 - val_loss: 43.9734 - val_mae: 5.0626 - val_mse: 43.9734\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 21.2456 - mae: 3.4834 - mse: 21.2456 - val_loss: 43.8674 - val_mae: 5.2426 - val_mse: 43.8674\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.9154 - mae: 3.2661 - mse: 17.9154 - val_loss: 58.3983 - val_mae: 6.1900 - val_mse: 58.3983\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 21.1920 - mae: 3.3380 - mse: 21.1920 - val_loss: 37.4072 - val_mae: 4.3412 - val_mse: 37.4072\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 17.4923 - mae: 3.0061 - mse: 17.4923 - val_loss: 43.5694 - val_mae: 4.7949 - val_mse: 43.5694\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 15.4171 - mae: 2.8878 - mse: 15.4171 - val_loss: 61.0127 - val_mae: 6.2364 - val_mse: 61.0127\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 15.0375 - mae: 2.8432 - mse: 15.0375 - val_loss: 44.7908 - val_mae: 5.2183 - val_mse: 44.7908\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 15.9763 - mae: 2.9049 - mse: 15.9763 - val_loss: 30.4841 - val_mae: 3.4758 - val_mse: 30.4841\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 13.3567 - mae: 2.7042 - mse: 13.3567 - val_loss: 38.2549 - val_mae: 3.7176 - val_mse: 38.2549\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 12.8364 - mae: 2.6944 - mse: 12.8364 - val_loss: 34.3453 - val_mae: 3.7956 - val_mse: 34.3453\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.5480 - mae: 2.7684 - mse: 14.5480 - val_loss: 22.5946 - val_mae: 3.1522 - val_mse: 22.5946\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 14.9913 - mae: 2.8331 - mse: 14.9913 - val_loss: 63.6602 - val_mae: 4.9122 - val_mse: 63.6602\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.8790 - mae: 3.0290 - mse: 16.8790 - val_loss: 44.3250 - val_mae: 4.3337 - val_mse: 44.3250\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 13.3655 - mae: 2.7066 - mse: 13.3655 - val_loss: 37.2996 - val_mae: 3.9780 - val_mse: 37.2996\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 14.8862 - mae: 2.8258 - mse: 14.8862 - val_loss: 47.6583 - val_mae: 4.4191 - val_mse: 47.6583\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 15.6413 - mae: 2.8977 - mse: 15.6413 - val_loss: 23.1001 - val_mae: 3.0222 - val_mse: 23.1001\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 14.5811 - mae: 2.7352 - mse: 14.5811 - val_loss: 52.3821 - val_mae: 4.6892 - val_mse: 52.3821\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 14.7302 - mae: 2.8089 - mse: 14.7302 - val_loss: 100.5466 - val_mae: 6.4747 - val_mse: 100.5466\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 13.4007 - mae: 2.7675 - mse: 13.4007 - val_loss: 22.6234 - val_mae: 3.2243 - val_mse: 22.6234\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 14.4372 - mae: 2.7225 - mse: 14.4372 - val_loss: 25.1973 - val_mae: 3.4942 - val_mse: 25.1973\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.9765 - mae: 3.0930 - mse: 16.9765 - val_loss: 51.4522 - val_mae: 4.4092 - val_mse: 51.4522\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 11.0739 - mae: 2.5725 - mse: 11.0739 - val_loss: 25.1097 - val_mae: 3.0531 - val_mse: 25.1097\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.5320 - mae: 2.7212 - mse: 13.5320 - val_loss: 23.2193 - val_mae: 3.2923 - val_mse: 23.2193\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 13.1029 - mae: 2.7278 - mse: 13.1029 - val_loss: 31.8248 - val_mae: 3.8241 - val_mse: 31.8248\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.7319 - mae: 2.6267 - mse: 12.7319 - val_loss: 36.7626 - val_mae: 4.1097 - val_mse: 36.7626\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2417 - mae: 2.7313 - mse: 13.2417 - val_loss: 36.8855 - val_mae: 3.9733 - val_mse: 36.8855\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.9977 - mae: 2.7532 - mse: 13.9977 - val_loss: 29.3598 - val_mae: 3.1503 - val_mse: 29.3598\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 14.2581 - mae: 2.7292 - mse: 14.2581 - val_loss: 22.4928 - val_mae: 3.1138 - val_mse: 22.4928\n",
            "loss — -> 22.4928035736084\n",
            "mae — -> 3.113823175430298\n",
            "mse — -> 22.4928035736084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gzu6KPEoCkpQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "590a023392bfbd6bf25d040f547d42ca7bfa1d7d06eb05be9ee62c62a8e24a8d"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1vyheJPGeC2x"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}